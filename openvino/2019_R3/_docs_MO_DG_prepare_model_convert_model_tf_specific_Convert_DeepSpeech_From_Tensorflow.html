<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Convert TensorFlow* DeepSpeech Model to the Intermediate Representation - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Convert TensorFlow* DeepSpeech Model to the Intermediate Representation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a href="https://github.com/mozilla/DeepSpeech">DeepSpeech project</a> provides an engine to train speech-to-text models.</p>
<h2>Download the Pre-Trained DeepSpeech Model</h2>
<p><a href="https://github.com/mozilla/DeepSpeech#getting-the-pre-trained-model">Pre-trained English speech-to-text model</a> is publicly available. To download the model, please follow the instruction below:</p>
<ul>
<li>For UNIX*-like systems, run the following command: <div class="fragment"><div class="line">wget -O - https://github.com/mozilla/DeepSpeech/releases/download/v0.3.0/deepspeech-0.3.0-models.tar.gz | tar xvfz -</div></div><!-- fragment --></li>
<li>For Windows* systems:<ol type="1">
<li>Download the archive from the DeepSpeech project repository: <a href="https://github.com/mozilla/DeepSpeech/releases/download/v0.3.0/deepspeech-0.3.0-models.tar.gz">https://github.com/mozilla/DeepSpeech/releases/download/v0.3.0/deepspeech-0.3.0-models.tar.gz</a>.</li>
<li>Unpack it with a file archiver application.</li>
</ol>
</li>
</ul>
<p>After you unpack the archive with the pre-trained model, you will have the new <code>models</code> directory with the following files: </p><div class="fragment"><div class="line">alphabet.txt  </div><div class="line">lm.binary</div><div class="line">output_graph.pb  </div><div class="line">output_graph.pbmm  </div><div class="line">output_graph.rounded.pb  </div><div class="line">output_graph.rounded.pbmm  </div><div class="line">trie</div></div><!-- fragment --><p>Pre-trained frozen model file is <code>output_graph.pb</code>.</p>
<div class="image">
<img src="DeepSpeech.png" alt="DeepSpeech.png"/>
<div class="caption">
DeepSpeech model view</div></div>
<p> As you can see, the frozen model still has two variables: <code>previous_state_c</code> and <code>previous_state_h</code>. It means that the model keeps training those variables at each inference.</p>
<p>At the first inference of this graph, the variables are initialized by zero tensors. After executing the <code>lstm_fused_cell</code> nodes, cell state and hidden state, which are the results of the <code>BlockLSTM</code> execution, are assigned to these two variables.</p>
<p>With each inference of the DeepSpeech graph, initial cell state and hidden state data for <code>BlockLSTM</code> is taken from previous inference from variables. Outputs (cell state and hidden state) of <code>BlockLSTM</code> are reassigned to the same variables.</p>
<p>It helps the model to remember the context of the words that it takes as input.</p>
<h2>Convert the TensorFlow* DeepSpeech Model to IR</h2>
<p>The Model Optimizer assumes that the output model is for inference only. That is why you should cut those variables off and resolve keeping cell and hidden states on the application level.</p>
<p>There are certain limitations for the model conversion:</p><ul>
<li>Time length (<code>time_len</code>) and sequence length (<code>seq_len</code>) are equal.</li>
<li>Original model cannot be reshaped, so you should keep original shapes.</li>
</ul>
<p>To generate the DeepSpeech Intermediate Representation (IR), provide the TensorFlow DeepSpeech model to the Model Optimizer with the following parameters: </p><div class="fragment"><div class="line">python3 ./mo_tf.py</div><div class="line">--input_model path_to_model/output_graph.pb                         \</div><div class="line">--freeze_placeholder_with_value input_lengths-&gt;[16]                 \</div><div class="line">--input input_node,previous_state_h/read,previous_state_c/read      \</div><div class="line">--input_shape [1,16,19,26],[1,2048],[1,2048]                        \</div><div class="line">--output raw_logits,lstm_fused_cell/Gather,lstm_fused_cell/Gather_1 \</div><div class="line">--disable_nhwc_to_nchw</div></div><!-- fragment --><p>Where:</p><ul>
<li><code>--freeze_placeholder_with_value input_lengths-&gt;[16]</code> freezes sequence length</li>
<li><code>--input input_node,previous_state_h/read,previous_state_c/read</code> and <code>--input_shape [1,16,19,26],[1,2048],[1,2048]</code> replace the variables with a placeholder</li>
<li><code>--output raw_logits,lstm_fused_cell/Gather,lstm_fused_cell/Gather_1</code> gets data for the next model execution. </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>