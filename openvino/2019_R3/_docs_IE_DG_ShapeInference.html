<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Using Shape Inference - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Using Shape Inference </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Shape Inference feature enables resizing network before loading it to a plugin. It makes possible to specify differently-sized input upon reading the model by the Inference Engine without going back to the Model Optimizer. The feature is exposed to replace <code>InferenceEngine::ICNNNetwork::SetBatchSize</code> as well, as setting batch is a special case of setting the whole input shape.</p>
<h2>Usage</h2>
<p>The primary method of the feature is <code><a class="el" href="classInferenceEngine_1_1CNNNetwork.html#a3dc928cf3537cb0e19060c206d4328d8" title="Run shape inference with new input shapes for the network. ">InferenceEngine::CNNNetwork::reshape</a></code>. It gets new input shapes and propagates it from input to output for all intermediates layers of the given network. The method takes <code><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a8bcef7f638f6588a672a32080047ff1d" title="Map of pairs: name of corresponding data and its dimension. ">InferenceEngine::ICNNNetwork::InputShapes</a></code> - a map of pairs: name of input data and its dimension.</p>
<p>The algorithm for resizing network is the following:</p>
<p>1) <b>Collect the map of input names and shapes from Intermediate Representation (IR)</b> using helper method <code><a class="el" href="classInferenceEngine_1_1CNNNetwork.html#ab3d41a03cff8eb7b70a22622ab495bfe" title="Helper method to get collect all input shapes with names of corresponding Data objects ...">InferenceEngine::CNNNetwork::getInputShapes</a></code></p>
<p>2) <b>Set new input shapes</b></p>
<p>3) <b>Call reshape</b></p>
<p>Here is a code example: </p><div class="fragment"><div class="line"><span class="comment">// ------------- 0. Read IR and image ----------------------------------------------</span></div><div class="line">CNNNetReader network_reader;</div><div class="line">network_reader.ReadNetwork(<span class="stringliteral">&quot;path/to/IR/xml&quot;</span>);</div><div class="line">CNNNetwork network = network_reader.getNetwork();</div><div class="line">cv::Mat image = cv::imread(<span class="stringliteral">&quot;path/to/image&quot;</span>);</div><div class="line"><span class="comment">// ---------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="comment">// ------------- 1. Collect the map of input names and shapes from IR---------------</span></div><div class="line"><span class="keyword">auto</span> input_shapes = network.getInputShapes();</div><div class="line"><span class="comment">// ---------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="comment">// ------------- 2. Set new input shapes -------------------------------------------</span></div><div class="line">std::string input_name;</div><div class="line"><a class="code" href="namespaceInferenceEngine.html#a9400de686d3d0f48c30cd73d40e48576">SizeVector</a> input_shape;</div><div class="line">std::tie(input_name, input_shape) = *input_shapes.begin(); <span class="comment">// let&#39;s consider first input only</span></div><div class="line">input_shape[0] = batch_size; <span class="comment">// set batch size to the first input dimension</span></div><div class="line">input_shape[2] = image.rows; <span class="comment">// changes input height to the image one</span></div><div class="line">input_shape[3] = image.cols; <span class="comment">// changes input width to the image one</span></div><div class="line">input_shapes[input_name] = input_shape;</div><div class="line"><span class="comment">// ---------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line"><span class="comment">// ------------- 3. Call reshape ---------------------------------------------------</span></div><div class="line">network.reshape(input_shapes);</div><div class="line"><span class="comment">// ---------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line"><span class="comment">// ------------- 4. Loading model to the device ------------------------------------</span></div><div class="line">InferenceEngine::Core core;</div><div class="line">std::string device = <span class="stringliteral">&quot;CPU&quot;</span>;</div><div class="line">ExecutableNetwork executable_network = core.<a class="code" href="classInferenceEngine_1_1Core.html#afcd1cc386d0ef3d2d33c6bf7d447d5ff">LoadNetwork</a>(network, device);</div><div class="line"><span class="comment">// ---------------------------------------------------------------------------------</span></div></div><!-- fragment --><p> Shape Inference feature is used in <a class="el" href="_demos_smart_classroom_demo_README.html">Smart classroom sample</a>.</p>
<h2>Extensibility</h2>
<p>Custom Shape Inference functions are registered via calling <code><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a32c6e07a71a0570d7a44fa3b2ae7064c" title="Registers extension within the plugin. ">InferenceEngine::ICNNNetwork::AddExtension</a></code> with implemented <code><a class="el" href="classInferenceEngine_1_1IShapeInferExtension.html" title="This class is the reader extension interface to provide implementation for shape propagation. ">InferenceEngine::IShapeInferExtension</a></code> - holder of the custom implementations. Holder requires to implement 2 key methods:</p><ul>
<li><code><a class="el" href="classInferenceEngine_1_1IShapeInferExtension.html#a102d9dd7024829a7146692cd4a3b0130" title="Gets shape propagation implementation for the given string-type of cnn Layer. ">InferenceEngine::IShapeInferExtension::getShapeInferImpl</a></code> - to return custom shape infer implementation for the given type</li>
<li><code><a class="el" href="classInferenceEngine_1_1IShapeInferExtension.html#a31cf706767e0c321d1048f0bce2c0c7f" title="Fills passed array with types of layers which shape infer implementations are included in the extensi...">InferenceEngine::IShapeInferExtension::getShapeInferTypes</a></code> - to provide all custom types Custom shape infer implementation is represented by <code><a class="el" href="classInferenceEngine_1_1IShapeInferImpl.html#a2a50ceecd9eee8a66ea904ffde182abf" title="check that reshape can be applied, that parameters and shapes are valid ">InferenceEngine::IShapeInferImpl::inferShapes</a></code>. It's not possible to override built-in (see below Supported layer types) shape infer functions. Custom type must be different from supported once. Extensibility mechanism of Shape Inference feature is demonstrated in <a class="el" href="_inference_engine_samples_hello_reshape_ssd_README.html">Hello Shape Infer SSD sample</a>.</li>
</ul>
<h2>Supported Layer Types</h2>
<ul>
<li>Activation</li>
<li>ArgMax</li>
<li>BatchNormalization</li>
<li>CTCGreedyDecoder</li>
<li>Clamp</li>
<li>Concat</li>
<li>Const</li>
<li>Convolution</li>
<li>Copy</li>
<li>Crop</li>
<li>Deconvolution</li>
<li>DetectionOutput</li>
<li>ELU</li>
<li>Eltwise</li>
<li>Flatten</li>
<li>FullyConnected/InnerProduct</li>
<li>GRN</li>
<li>Input</li>
<li>Interp</li>
<li>LRN/Norm</li>
<li>Logistic</li>
<li>MVN</li>
<li>Memory</li>
<li>Normalize</li>
<li>PReLU</li>
<li>PSROIPooling</li>
<li>Permute</li>
<li>Pooling</li>
<li>Power</li>
<li>PowerFile</li>
<li>PriorBox</li>
<li>PriorBoxClustered</li>
<li>Proposal</li>
<li>ROIPooling</li>
<li>ReLU</li>
<li>ReLU6</li>
<li>RegionYolo</li>
<li>ReorgYolo</li>
<li>Resample</li>
<li>Reshape</li>
<li>ScaleShift</li>
<li>Sigmoid</li>
<li>SimplerNMS</li>
<li>Slice</li>
<li>SoftMax</li>
<li>SpatialTransformer</li>
<li>Split</li>
<li>TanH</li>
<li>Tile</li>
<li>Upsampling</li>
</ul>
<h2>Limitations</h2>
<p>Shape Inference is a preview feature with a set of limitations:</p>
<ul>
<li>Reshape layer might not work correctly for TensorFlow* models if its shape and parameters are dynamically depend on other layers (for example, for the pre-trainned vehicle-license-plate-detection-barrier-0107 model).</li>
<li>Models with fixed dimensions in the <code>dim</code> attribute of the Reshape layer can't be resized.</li>
<li>Shape inference for Interp layer works for almost all cases, except for Caffe models with fixed width and height parameters (for example, semantic-segmentation-adas-0001). </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>