<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Install OpenVINO™ toolkit for Raspbian* OS - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Install OpenVINO™ toolkit for Raspbian* OS </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><blockquote class="doxtable">
<p><b>NOTE</b>:</p><ul>
<li>These steps apply to 32-bit Raspbian* OS, which is an official OS for Raspberry Pi* boards.</li>
<li>These steps have been validated with Raspberry Pi 3*.</li>
<li>All steps in this guide are required unless otherwise stated.</li>
<li>An internet connection is required to follow the steps in this guide. If you have access to the Internet through the proxy server only, please make sure that it is configured in your OS environment. </li>
</ul>
</blockquote>
<h2>Introduction</h2>
<p>The OpenVINO™ toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the toolkit extends computer vision (CV) workloads across Intel® hardware, maximizing performance. The OpenVINO toolkit includes the Intel® Deep Learning Deployment Toolkit (Intel® DLDT).</p>
<p>The OpenVINO™ toolkit for Raspbian* OS includes the Inference Engine and the MYRIAD plugins. You can use it with the Intel® Movidius™ Neural Compute Stick (Intel® NCS) or the Intel® Neural Compute Stick 2 plugged in one of USB ports.</p>
<h3>Included in the Installation Package</h3>
<p>The OpenVINO toolkit for Raspbian OS is an archive with pre-installed header files and libraries. The following components are installed by default:</p>
<table class="doxtable">
<tr>
<th align="left">Component </th><th align="left">Description  </th></tr>
<tr>
<td align="left"><a class="el" href="_docs_IE_DG_inference_engine_intro.html">Inference Engine</a> </td><td align="left">This is the engine that runs the deep learning model. It includes a set of libraries for an easy inference integration into your applications. </td></tr>
<tr>
<td align="left"><a href="https://docs.opencv.org/master/">OpenCV*</a> </td><td align="left">OpenCV* community version compiled for Intel® hardware. </td></tr>
<tr>
<td align="left"><a class="el" href="_docs_IE_DG_Samples_Overview.html">Sample Applications</a> </td><td align="left">A set of simple console applications demonstrating how to use Intel's Deep Learning Inference Engine in your applications. </td></tr>
</table>
<blockquote class="doxtable">
<p><b>NOTE</b>:</p><ul>
<li>The package does not include the <a class="el" href="_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a>. To convert models to Intermediate Representation (IR), you need to install it separately to your host machine.</li>
<li>The package does not include the Open Model Zoo demo applications. You can download them separately from the <a href="https://github.com/opencv/open_model_zoo">Open Models Zoo repository</a>. </li>
</ul>
</blockquote>
<h2>Development and Target Platforms</h2>
<p><b>Hardware</b></p>
<ul>
<li>Raspberry Pi* board with ARM* ARMv7-A CPU architecture. Check that <code>uname -m</code> returns <code>armv7l</code>.</li>
<li>One of Intel® Movidius™ Visual Processing Units (VPU):<ul>
<li>Intel® Movidius™ Neural Compute Stick</li>
<li>Intel® Neural Compute Stick 2</li>
</ul>
</li>
</ul>
<p><b>Operating Systems</b></p>
<ul>
<li>Raspbian* Buster, 32-bit</li>
<li>Raspbian* Stretch, 32-bit</li>
</ul>
<p><b>Software</b></p>
<ul>
<li>CMake* 3.7.2 or higher</li>
<li>Python* 3.5, 32-bit</li>
</ul>
<h2>Overview</h2>
<p>This guide provides step-by-step instructions on how to install the OpenVINO™ toolkit for Raspbian* OS. Links are provided for each type of compatible hardware including downloads, initialization and configuration steps. The following steps will be covered:</p>
<ol type="1">
<li><a href="#install-package">Install the OpenVINO™ toolkit</a></li>
<li><a href="#install-dependencies">Install External Software Dependencies</a></li>
<li><a href="#set-environment-variables">Set the environment variables</a></li>
<li><a href="#add-usb-rules">Add USB rules</a></li>
<li><a href="#run-sample">Run the Object Detection Sample</a> to validate Inference Engine installation</li>
<li><a href="#run-inference-opencv">Run Inference of Face Detection Model (for OpenCV*)</a> to validate OpenCV installation</li>
<li><a href="#workflow-for-raspberry-pi">Learn About Workflow for Raspberry Pi</a></li>
</ol>
<h2><a class="anchor" id="install-package"></a>Install the OpenVINO™ Toolkit for Raspbian* OS Package</h2>
<p>The guide assumes you downloaded the OpenVINO toolkit for Raspbian* OS. If you do not have a copy of the toolkit package file <code>l_openvino_toolkit_runtime_raspbian_p_&lt;version&gt;.tgz</code>, download the latest version from the <a href="https://download.01.org/opencv/2019/openvinotoolkit/">Intel® Open Source Technology Center</a> and then return to this guide to proceed with the installation.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: The OpenVINO toolkit for Raspbian OS is distributed without installer, so you need to perform extra steps comparing to the <a class="el" href="_docs_install_guides_installing_openvino_linux.html">Intel® Distribution of OpenVINO™ toolkit for Linux* OS</a>. </p>
</blockquote>
<ol type="1">
<li>Open the Terminal* or your preferred console application.</li>
<li>Go to the directory in which you downloaded the OpenVINO toolkit. This document assumes this is your <code>~/Downloads</code> directory. If not, replace <code>~/Downloads</code> with the directory where the file is located. <div class="fragment"><div class="line">cd ~/Downloads/</div></div><!-- fragment --> By default, the package file is saved as <code>l_openvino_toolkit_runtime_raspbian_p_&lt;version&gt;.tgz</code>.</li>
<li>Create an installation folder. <div class="fragment"><div class="line">sudo mkdir -p /opt/intel/openvino</div></div><!-- fragment --></li>
<li>Unpack the archive: <div class="fragment"><div class="line">sudo tar -xf  l_openvino_toolkit_runtime_raspbian_p_&lt;version&gt;.tgz --strip 1 -C /opt/intel/openvino</div></div><!-- fragment --></li>
</ol>
<p>Now the OpenVINO toolkit components are installed. Additional configuration steps are still required. Continue to the next sections to install External Software Dependencies, configure the environment and set up USB rules.</p>
<h2><a class="anchor" id="install-dependencies"></a>Install External Software Dependencies</h2>
<p>CMake* version 3.7.2 or higher is required for building the Inference Engine sample application. To install, open a Terminal* window and run the following command: </p><div class="fragment"><div class="line">sudo apt install cmake</div></div><!-- fragment --><p>CMake is installed. Continue to the next section to set the environment variables.</p>
<h2><a class="anchor" id="set-environment-variables"></a>Set the Environment Variables</h2>
<p>You must update several environment variables before you can compile and run OpenVINO toolkit applications. Run the following script to temporarily set the environment variables: </p><div class="fragment"><div class="line">source /opt/intel/openvino/bin/setupvars.sh</div></div><!-- fragment --><p>**(Optional)** The OpenVINO environment variables are removed when you close the shell. As an option, you can permanently set the environment variables as follows: </p><div class="fragment"><div class="line">echo &quot;source /opt/intel/openvino/bin/setupvars.sh&quot; &gt;&gt; ~/.bashrc</div></div><!-- fragment --><p>To test your change, open a new terminal. You will see the following: </p><div class="fragment"><div class="line">[setupvars.sh] OpenVINO environment initialized</div></div><!-- fragment --><p>Continue to the next section to add USB rules for Intel® Movidius™ Neural Compute Stick and Intel® Neural Compute Stick 2 devices.</p>
<h2><a class="anchor" id="add-usb-rules"></a>Add USB Rules</h2>
<ol type="1">
<li>Add the current Linux user to the <code>users</code> group: <div class="fragment"><div class="line">sudo usermod -a -G users &quot;$(whoami)&quot;</div></div><!-- fragment --> Log out and log in for it to take effect.</li>
<li>If you didn't modify <code>.bashrc</code> to permanently set the environment variables, run <code>setupvars.sh</code> again after logging in: <div class="fragment"><div class="line">source /opt/intel/openvino/bin/setupvars.sh</div></div><!-- fragment --></li>
<li>To perform inference on the Intel® Movidius™ Neural Compute Stick or Intel® Neural Compute Stick 2, install the USB rules running the <code>install_NCS_udev_rules.sh</code> script: <div class="fragment"><div class="line">sh /opt/intel/openvino/install_dependencies/install_NCS_udev_rules.sh</div></div><!-- fragment --></li>
<li>Plug in your Intel® Movidius™ Neural Compute Stick or Intel® Neural Compute Stick 2.</li>
</ol>
<p>You are ready to compile and run the Object Detection sample to verify the Inference Engine installation.</p>
<h2><a class="anchor" id="run-sample"></a>Build and Run Object Detection Sample</h2>
<p>Follow the next steps to run pre-trained Face Detection network using Inference Engine samples from the OpenVINO toolkit.</p>
<ol type="1">
<li>Navigate to a directory that you have write access to and create a samples build directory. This example uses a directory named <code>build</code>: <div class="fragment"><div class="line">mkdir build &amp;&amp; cd build</div></div><!-- fragment --></li>
<li>Build the Object Detection Sample: <div class="fragment"><div class="line">cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=&quot;-march=armv7-a&quot; /opt/intel/openvino/deployment_tools/inference_engine/samples</div></div><!-- fragment --> <div class="fragment"><div class="line">make -j2 object_detection_sample_ssd</div></div><!-- fragment --></li>
<li>Download the pre-trained Face Detection model or copy it from the host machine:<ul>
<li>To download the <code>.bin</code> file with weights: <div class="fragment"><div class="line">wget --no-check-certificate https://download.01.org/opencv/2019/open_model_zoo/R1/models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.bin</div></div><!-- fragment --></li>
<li>To download the <code>.xml</code> file with the network topology: <div class="fragment"><div class="line">wget --no-check-certificate https://download.01.org/opencv/2019/open_model_zoo/R1/models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.xml</div></div><!-- fragment --></li>
</ul>
</li>
<li>Run the sample with specifying the model and a path to the input image: <div class="fragment"><div class="line">./armv7l/Release/object_detection_sample_ssd -m face-detection-adas-0001.xml -d MYRIAD -i &lt;path_to_image&gt;</div></div><!-- fragment --> The application outputs an image (<code>out_0.bmp</code>) with detected faced enclosed in rectangles.</li>
</ol>
<p>Continue to the next section to verify the OpenCV installation.</p>
<h2><a class="anchor" id="run-inference-opencv"></a>Run Inference of Face Detection Model Using OpenCV* API</h2>
<p>To validate OpenCV* installation, run the OpenCV deep learning module with the Inference Engine backend. Here is a Python* sample, which works with the pre-trained Face Detection model:</p>
<ol type="1">
<li>Download the pre-trained Face Detection model or copy it from a host machine:<ul>
<li>To download the <code>.bin</code> file with weights: <div class="fragment"><div class="line">wget --no-check-certificate https://download.01.org/opencv/2019/open_model_zoo/R1/models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.bin</div></div><!-- fragment --></li>
<li>To download the <code>.xml</code> file with the network topology: <div class="fragment"><div class="line">wget --no-check-certificate https://download.01.org/opencv/2019/open_model_zoo/R1/models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.xml</div></div><!-- fragment --></li>
</ul>
</li>
<li>Create a new Python* file named as <code>openvino_fd_myriad.py</code> and copy the following script there: <div class="fragment"><div class="line">import cv2 as cv</div><div class="line"></div><div class="line"># Load the model.</div><div class="line">net = cv.dnn.readNet(&#39;face-detection-adas-0001.xml&#39;,</div><div class="line">                     &#39;face-detection-adas-0001.bin&#39;)</div><div class="line"># Specify target device.</div><div class="line">net.setPreferableTarget(cv.dnn.DNN_TARGET_MYRIAD)</div><div class="line"></div><div class="line"># Read an image.</div><div class="line">frame = cv.imread(&#39;/path/to/image&#39;)</div><div class="line">if frame is None:</div><div class="line">    raise Exception(&#39;Image not found!&#39;)</div><div class="line"></div><div class="line"># Prepare input blob and perform an inference.</div><div class="line">blob = cv.dnn.blobFromImage(frame, size=(672, 384), ddepth=cv.CV_8U)</div><div class="line">net.setInput(blob)</div><div class="line">out = net.forward()</div><div class="line"></div><div class="line"># Draw detected faces on the frame.</div><div class="line">for detection in out.reshape(-1, 7):</div><div class="line">    confidence = float(detection[2])</div><div class="line">    xmin = int(detection[3] * frame.shape[1])</div><div class="line">    ymin = int(detection[4] * frame.shape[0])</div><div class="line">    xmax = int(detection[5] * frame.shape[1])</div><div class="line">    ymax = int(detection[6] * frame.shape[0])</div><div class="line"></div><div class="line">    if confidence &gt; 0.5:</div><div class="line">        cv.rectangle(frame, (xmin, ymin), (xmax, ymax), color=(0, 255, 0))</div><div class="line"></div><div class="line"># Save the frame to an image file.</div><div class="line">cv.imwrite(&#39;out.png&#39;, frame)</div></div><!-- fragment --></li>
<li>Run the script: <div class="fragment"><div class="line">python3 openvino_fd_myriad.py</div></div><!-- fragment --></li>
</ol>
<p>In this script OpenCV* loads the Face Detection model from the Intermediate Representation (IR) format and an image. Then it runs the inference and saves the image with detected faces.</p>
<p>Congratulations, you have finished the OpenVINO™ toolkit for Raspbian* OS installation. You have completed all required installation, configuration and build steps in this guide.</p>
<p>Read the next topic if you want to learn more about OpenVINO workflow for Raspberry Pi.</p>
<h2><a class="anchor" id="workflow-for-raspberry-pi"></a>Workflow for Raspberry Pi*</h2>
<p>If you want to use your model for inference, the model must be converted to the .bin and .xml Intermediate Representation (IR) files that are used as input by Inference Engine. OpenVINO™ toolkit support on Raspberry Pi only includes the Inference Engine module of the Intel® Distribution of OpenVINO™ toolkit. The Model Optimizer is not supported on this platform. To get the optimized models you can use one of the following options:</p>
<ul>
<li><p class="startli">Download a set of ready-to-use pre-trained models for the appropriate version of OpenVINO from the Intel® Open Source Technology Center:</p><ul>
<li>Models for the 2019 R1 release of OpenVINO are available at <a href="https://download.01.org/opencv/2019/open_model_zoo/R1/">https://download.01.org/opencv/2019/open_model_zoo/R1/</a>.</li>
<li>Models for the 2018 R5 release of OpenVINO are available at <a href="https://download.01.org/openvinotoolkit/2018_R5/open_model_zoo/">https://download.01.org/openvinotoolkit/2018_R5/open_model_zoo/</a>.</li>
</ul>
<p class="startli">For more information on pre-trained models, see <a class="el" href="_models_intel_index.html">Pre-Trained Models Documentation</a></p>
</li>
<li><p class="startli">Convert the model using the Model Optimizer from a full installation of Intel® Distribution of OpenVINO™ toolkit on one of the supported platforms. Installation instructions are available:</p><ul>
<li><a class="el" href="_docs_install_guides_installing_openvino_macos.html">Installation Guide for macOS*</a></li>
<li><a class="el" href="_docs_install_guides_installing_openvino_windows.html">Installation Guide for Windows*</a></li>
<li><a class="el" href="_docs_install_guides_installing_openvino_linux.html">Installation Guide for Linux*</a></li>
</ul>
<p class="startli">For more information about how to use the Model Optimizer, see the <a href="https://software.intel.com/articles/OpenVINO-ModelOptimizer">Model Optimizer Developer Guide</a> </p>
</li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>