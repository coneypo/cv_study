<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>(Deprecated) Case Study: Converting SSD Models Created with TensorFlow* Object Detection API - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">(Deprecated) Case Study: Converting SSD Models Created with TensorFlow* Object Detection API </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This is a deprecated page. Please, consider reading <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">this</a> page describing new approach to convert Object Detection API models giving closer to TensorFlow inference results.</p>
<h2>Converting Models Created with TensorFlow Object Detection API Version prior 1.6.0</h2>
<p>As explained in the <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Subgraph_Replacement_Model_Optimizer.html">Sub-graph Replacement in Model Optimizer</a> section, there are multiple ways to setup the sub-graph matching. In this example we are focusing on the defining the sub-graph via a set of "start" and "end" nodes. The result of matching is two buckets of nodes:</p><ul>
<li>Nodes "between" start and end nodes.</li>
<li>Nodes connected to the first list, but just on the constant path (e.g. these nodes are not connected to the inputs of the entire graph).</li>
</ul>
<p>Let's look closer to the SSD models from the TensorFlow* detection model <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">zoo</a>: <a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz">SSD MobileNet</a> and <a href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz">SSD InceptionV2</a>.</p>
<ul>
<li>Nodes "between" start and end nodes</li>
<li>Nodes connected to the first list, but just on the constant path (for example, these nodes are not connected to the inputs of the entire graph). Let's look closer to the SSD models from the TensorFlow* detection model <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">zoo</a> : <a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz">SSD MobileNet</a> and <a href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_17.tar.gz">SSD InceptionV2</a>.</li>
</ul>
<p>A distinct layer of any SSD topology is the <code>DetectionOutput</code> layer. This layer is implemented with a dozens of primitive operations in TensorFlow, while in Inference Engine, it is one <a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">layer</a>. Thus, to convert a SSD model from the TensorFlow, the Model Optimizer should replace the entire sub-graph of operations that implement the <code>DetectionOutput</code> layer with a single well-known <code>DetectionOutput</code> node.</p>
<p>The Inference Engine <code>DetectionOutput</code> layer consumes three tensors in the following order:</p>
<ol type="1">
<li>Tensor with locations of bounding boxes</li>
<li>Tensor with confidences for each bounding box</li>
<li>Tensor with prior boxes (anchors in TensorFlow terminology)</li>
</ol>
<p><code>DetectionOutput</code> layer produces one tensor with seven numbers for each actual detection. There are more output tensors in the TensorFlow Object Detection API, but the values in them are consistent with the Inference Engine ones.</p>
<p>The difference with <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Subgraph_Replacement_Model_Optimizer.html">other examples</a> is that here the <code>DetectionOutput</code> sub-graph is replaced with a new sub-graph (not a single layer).</p>
<p>Look at sub-graph replacement configuration file <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf/legacy_ssd_support.json</code> that is used to enable two models listed above: </p><div class="fragment"><div class="line">[  </div><div class="line">    {  </div><div class="line">        &quot;custom_attributes&quot;: {  </div><div class="line">            &quot;code_type&quot;: &quot;caffe.PriorBoxParameter.CENTER_SIZE&quot;,  </div><div class="line">            &quot;confidence_threshold&quot;: 0.01,  </div><div class="line">            &quot;keep_top_k&quot;: 200,  </div><div class="line">            &quot;nms_threshold&quot;: 0.45,  </div><div class="line">            &quot;pad_mode&quot;: &quot;caffe.ResizeParameter.CONSTANT&quot;,  </div><div class="line">            &quot;resize_mode&quot;: &quot;caffe.ResizeParameter.WARP&quot;  </div><div class="line">        },  </div><div class="line">        &quot;id&quot;: &quot;TFObjectDetectionAPIDetectionOutput&quot;,  </div><div class="line">        &quot;include_inputs_to_sub_graph&quot;: true,  </div><div class="line">        &quot;include_outputs_to_sub_graph&quot;: true,  </div><div class="line">        &quot;instances&quot;: {  </div><div class="line">            &quot;end_points&quot;: [  </div><div class="line">                &quot;detection_boxes&quot;,  </div><div class="line">                &quot;detection_scores&quot;,  </div><div class="line">                &quot;num_detections&quot;  </div><div class="line">            ],  </div><div class="line">            &quot;start_points&quot;: [  </div><div class="line">                &quot;Postprocessor/Shape&quot;,  </div><div class="line">                &quot;Postprocessor/Slice&quot;,  </div><div class="line">                &quot;Postprocessor/ExpandDims&quot;,  </div><div class="line">                &quot;Postprocessor/Reshape_1&quot;  </div><div class="line">            ]  </div><div class="line">        },  </div><div class="line">        &quot;match_kind&quot;: &quot;points&quot;  </div><div class="line">    },</div><div class="line">    {</div><div class="line">        &quot;custom_attributes&quot;: {</div><div class="line">        },</div><div class="line">        &quot;id&quot;: &quot;PreprocessorReplacement&quot;,</div><div class="line">        &quot;inputs&quot;: [</div><div class="line">            [</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/Shape$&quot;,</div><div class="line">                    &quot;port&quot;: 0</div><div class="line">                },</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/TensorArrayUnstack/Shape$&quot;,</div><div class="line">                    &quot;port&quot;: 0</div><div class="line">                },</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3$&quot;,</div><div class="line">                    &quot;port&quot;: 2</div><div class="line">                }</div><div class="line">            ]</div><div class="line">        ],</div><div class="line">        &quot;instances&quot;: [</div><div class="line">            &quot;.*Preprocessor/&quot;</div><div class="line">        ],</div><div class="line">        &quot;match_kind&quot;: &quot;scope&quot;,</div><div class="line">        &quot;outputs&quot;: [</div><div class="line">            {</div><div class="line">                &quot;node&quot;: &quot;sub$&quot;,</div><div class="line">                &quot;port&quot;: 0</div><div class="line">            },</div><div class="line">            {</div><div class="line">                &quot;node&quot;: &quot;map/TensorArrayStack_1/TensorArrayGatherV3$&quot;,</div><div class="line">                &quot;port&quot;: 0</div><div class="line">            }</div><div class="line">        ]</div><div class="line">    }</div><div class="line">]</div></div><!-- fragment --><p><b>Key lines</b>:</p>
<ul>
<li>Lines 3-10 define static attributes that will be saved to the Intermediate Representation <code>.xml</code> file for <code>DetectionOutput</code> layer.</li>
<li>Lines 12 and 13 define values for attributes that should be always set to "true" for this release of the Model Optimizer. These two attributes are specific for sub-graph match by points only.</li>
<li>Lines 14-26 define one instance of the sub-graph to be match. It is an important difference between sub-graph matching by scope and points. Several instances could be specified for matching by scope, but matching with points allows specifying just one instance. So the full node names (not regular expressions like in case of match with scope) are specified in <code>instances</code> dictionary.</li>
</ul>
<p>The second sub-graph replacer with identifier <code>PreprocessorReplacement</code> is used to remove the <code>Preprocessing</code> block from the graph. The replacer removes all nodes from this scope except nodes performing mean value subtraction and scaling (if applicable). Implementation of the replacer is in the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf/Preprocessor.py</code> file.</p>
<p>Now let's analyze the structure of the topologies generated with the Object Detection API. There are several blocks in the graph performing particular task:</p>
<ul>
<li><code>Preprocessor</code> block resizes, scales and subtracts mean values from the input image.</li>
<li><code>FeatureExtractor</code> block is a <a href="https://arxiv.org/abs/1704.04861">MobileNet</a> or other backbone to extract features.</li>
<li><code>MultipleGridAnchorGenerator</code> block creates initial bounding boxes locations (anchors).</li>
<li><code>Postprocessor</code> block acts as a <code>DetectionOutput</code> layer. So we need to replace <code>Postprocessor</code> block with <code>DetectionOutput</code> layer. It is necessary to add all input nodes of the <code>Postprocessor</code> scope to the list <code>start_points</code>. Consider inputs of each of these nodes:<ul>
<li><code>Postprocessor/Shape</code> consumes tensor with locations.</li>
<li><code>Postprocessor/Slice</code> consumes tensor with confidences.</li>
<li><code>Postprocessor/ExpandDims</code> consumes tensor with prior boxes.</li>
<li><code>Postprocessor/Reshape_1</code> consumes tensor with locations similarly to the <code>Postprocessor/Shape</code> node. Despite the fact that the last node <code>Postprocessor/Reshape_1</code> gets the same tensor as node <code>Postprocessor/Shape</code>, it must be explicitly put to the list.</li>
</ul>
</li>
</ul>
<p>Object Detection API <code>Postprocessor</code> block generates output nodes: <code>detection_boxes</code>, <code>detection_scores</code>, <code>num_detections</code>, <code>detection_classes</code>.</p>
<p>Now consider the implementation of the sub-graph replacer, available in the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf/SSDs.py</code>. The file is rather big, so only some code snippets are used: </p><div class="fragment"><div class="line">class PostprocessorReplacement(FrontReplacementFromConfigFileSubGraph):</div><div class="line">    replacement_id = &#39;TFObjectDetectionAPIDetectionOutput&#39;</div></div><!-- fragment --><p>These lines define the new <code>PostprocessorReplacement</code> class inherited from <code>FrontReplacementFromConfigFileSubGraph</code>. <code>FrontReplacementFromConfigFileSubGraph</code> is designed to replace sub-graph of operations described in the configuration file. There are methods to override for implementing custom replacement logic that we need:</p>
<ul>
<li><code>generate_sub_graph</code> performs new sub-graph generation and returns dictionary where key is an alias name for the node and value is a Node objects. The dictionary has the same format as parameter <code>match</code> in the <code>replace_sub_graph</code> method in the example with <a href="Subgraph_Replacement_Model_Optimizer.html#replace-using-isomorphism-pattern">networkx sub-graph isomorphism pattern</a>. This dictionary is passed as argument to the next three methods, so it should contain entries the for nodes that the functions need.</li>
<li><code>input_edges_match</code> specifies mapping between input edges to sub-graph before replacement and after replacement. The key of the dictionary is a tuple specifying input tensor of the sub-graph before replacement: sub-graph input node name and input port number for this node. The value for this key is also a tuple specifying the node where this tensor should be attached during replacement: the node name (or alias name of the node) and the input port for this node. If the port number is zero, the parameter could be omitted so the key or value is just a node name (alias). Default implementation of the method returns an empty dictionary, so Model Optimizer does not create new edges.</li>
<li><code>output_edges_match</code> returns mapping between old output edges of the matched nodes and new sub-graph node and output edge index. The format is similar to the dictionary returned in the <code>input_edges_match</code> method. The only difference is that instead of specifying input port numbers for the nodes it is necessary to specify output port number. Of course, this mapping is needed for the output nodes only. Default implementation of the method returns an empty dictionary, so the Model Optimizer does not create new edges.</li>
<li><code>nodes_to_remove</code> specifies list of nodes that Model Optimizer should remove after sub-graph replacement. Default implementation of the method removes all sub-graph nodes.</li>
</ul>
<p>Review of the replacer code, considering details of the <code>DetectionOutput</code> layer implementation in the Inference Engine. There are several constraints to the input tensors of the <code>DetectionOutput</code> layer:</p>
<ul>
<li>The tensor with locations must be of shape <code>[#&zwj;batch, #&zwj;prior_boxes * 4]</code> or <code>[#&zwj;batch, #&zwj;prior_boxes * 5]</code> depending on shared locations between different batches or not.</li>
<li>The tensor with confidences must be of shape <code>[#&zwj;batch, #&zwj;prior_boxes * #&zwj;classes]</code> and confidences values are in range [0, 1], that is passed through <code>softmax</code> layer.</li>
<li>The tensor with prior boxes must be of shape <code>[#&zwj;batch, 2, #&zwj;prior_boxes * 4]</code>. Inference Engine expects that it contains variance values which TensorFlow Object Detection API does not add.</li>
</ul>
<p>To enable these models, add <code>Reshape</code> operations for locations and confidences tensors and update the values for the prior boxes to include the variance constants (they are not there in TensorFlow Object Detection API).</p>
<p>Look at the <code>generate_sub_graph</code> method: </p><div class="fragment"><div class="line">def generate_sub_graph(self, graph: nx.MultiDiGraph, match: SubgraphMatch):</div><div class="line">    log.debug(&#39;PostprocessorReplacement.generate_sub_graph&#39;)</div><div class="line">    log.debug(&#39;matched_nodes = {}&#39;.format(match.matched_nodes_names()))</div><div class="line">    # softmax to be applied to the confidence</div><div class="line">    softmax_conf_op = Softmax(graph, {&#39;axis&#39;: 2, &#39;nchw_layout&#39;: True})</div><div class="line">    softmax_conf_node = softmax_conf_op.add_node(dict(name=&#39;DetectionOutput_SoftMax_conf_&#39;))</div><div class="line">    # Inference Engine DetectionOutput layer consumes flattened tensors</div><div class="line">    # reshape operation to flatten locations tensor</div><div class="line">    reshape_loc_op = Reshape(graph, {&#39;dim&#39;: np.array([0, -1])})</div><div class="line">    reshape_loc_node = reshape_loc_op.add_node(dict(name=&#39;DetectionOutput_Reshape_loc_&#39;))</div><div class="line">    # Inference Engine DetectionOutput layer consumes flattened tensors</div><div class="line">    # reshape operation to flatten confidence tensor</div><div class="line">    reshape_conf_op = Reshape(graph, {&#39;dim&#39;: np.array([0, -1])})</div><div class="line">    reshape_conf_node = reshape_conf_op.add_node(dict(name=&#39;DetectionOutput_Reshape_conf_&#39;))</div><div class="line">    # create Node object from Op class</div><div class="line">    detection_output_op = DetectionOutput(graph, match.custom_replacement_desc.custom_attributes)</div><div class="line">    detection_output_op.attrs[&#39;old_infer&#39;] = detection_output_op.attrs[&#39;infer&#39;]</div><div class="line">    detection_output_op.attrs[&#39;infer&#39;] = __class__.do_infer</div><div class="line">    detection_output_node = detection_output_op.add_node(dict(name=detection_output_op.attrs[&#39;type&#39;] + &#39;_&#39;))</div><div class="line">    # create internal edges of the sub-graph. In this case we add edges to connect input port 0 and 1 of the</div><div class="line">    # detection output with output of reshape of locations and reshape of confidence</div><div class="line">    create_edge(softmax_conf_node, reshape_conf_node, 0, 0)</div><div class="line">    create_edge(reshape_loc_node, detection_output_node, 0, 0)</div><div class="line">    create_edge(reshape_conf_node, detection_output_node, 0, 1)</div><div class="line">    return {&#39;detection_output_node&#39;: detection_output_node, &#39;reshape_conf_node&#39;: softmax_conf_node,</div><div class="line">            &#39;reshape_loc_node&#39;: reshape_loc_node}</div></div><!-- fragment --><p> The method has two inputs: the graph to operate on and the instance of <code>SubgraphMatch</code> object, which describes matched sub-graph. The latter class has several useful methods to get particular input/output node of the sub-graph by input/output index or by node name pattern. Examples of these methods usage are given below.</p>
<p><b>Key lines</b>:</p>
<ul>
<li>Lines 6 and 7 create new instance of operation of type <code>Softmax</code> and graph Node object corresponding to that operation.</li>
<li>Lines 11-12 and 16-17 create new instance of operation of type <code>Reshape</code> to reshape locations and confidences tensors correspondingly.</li>
<li>Lines 20-23 create new instance of operation <code>DetectionOutput</code> and graph Node object corresponding to that operation.</li>
<li>Lines 27-29 connect <code>softmax</code> node with <code>reshape</code> node and connect two reshaped locations and confidences tensors with <code>DetectionOutput</code> node.</li>
<li>Lines 30-31 define dictionary with aliases for detection output node, reshape locations and confidences nodes. These aliases are used in the <code>input_edges_match</code> and <code>output_edges_match</code> methods.</li>
</ul>
<p>The <code>input_edges_match</code> method is the following: </p><div class="fragment"><div class="line">def input_edges_match(self, graph: nx.DiGraph, match: SubgraphMatch, new_sub_graph: dict):</div><div class="line">    locs_consumer_node, locs_consumer_node_port = match.input_nodes(0)[0]</div><div class="line">    conf_consumer_node, conf_consumer_node_port = match.input_nodes(1)[0]</div><div class="line">    priors_consumer_node, priors_consumer_node_port = match.input_nodes(2)[0]</div><div class="line">    # create matching nodes for locations and confidence tensors using simple scheme &quot;old_node_name: new_node_name&quot;</div><div class="line">    # which in fact means &quot;(old_node_name, 0): (new_node_name, 0)&quot;, while first &#39;0&#39; means old_port and the second</div><div class="line">    # zero defines &#39;new_port&#39;.</div><div class="line">    return {locs_consumer_node.id: new_sub_graph[&#39;reshape_loc_node&#39;].id,</div><div class="line">            conf_consumer_node.id: new_sub_graph[&#39;reshape_conf_node&#39;].id,</div><div class="line">            priors_consumer_node.id: (new_sub_graph[&#39;detection_output_node&#39;].id, 2),</div><div class="line">            }</div></div><!-- fragment --><p> The method has three parameters: input <code>graph</code>, <code>match</code> object describing matched sub-graph and <code>new_sub_graph</code> dictionary with alias names returned from the <code>generate_sub_graph</code> method.</p>
<p><b>Key lines</b>:</p>
<ul>
<li>Lines 2-4 initialize Node objects and input ports for the nodes where the input tensors for the sub-graph are consumed. The method <code>match.input_nodes(ind)</code> returns list of tuples where the first element is a Node object and the second is the input port for this node which consumes the ind-th input tensor of the sub-graph. <code>input_points</code> list in the configuration file defines the order of input tensors to the sub-graph. For example, the <code>locs_consumer_node</code> object of type Node is a node that consumes tensor with locations in the port with number <code>locs_consumer_node_port</code>.</li>
<li>Lines 8-11 define dictionary with the mapping of tensors as described above. Note that the attribute <code>id</code> of the Node object contains the name of the node in the graph.</li>
</ul>
<p>The <code>output_edges_match</code> method is the following: </p><div class="fragment"><div class="line">def output_edges_match(self, graph: nx.DiGraph, match: SubgraphMatch, new_sub_graph: dict):</div><div class="line">    # the DetectionOutput in IE produces single tensor, but in TF it produces two tensors, so we need to create only</div><div class="line">    # one output edge match</div><div class="line">    return {match.output_node(0)[0].id: new_sub_graph[&#39;detection_output_node&#39;].id}</div></div><!-- fragment --><p>The method has the same three parameters as <code>input_edges_match</code> method. The returned dictionary contains mapping just for one tensor initially produces by the first output node of the sub-graph (which is <code>detection_boxes</code> according to the configuration file) to a single output tensor of the created <code>DetectionOutput</code> node. In fact, it is possible to use any output node of the initial sub-graph in mapping, because the sub-graph output nodes are the output nodes of the whole graph (their output is not consumed by any other nodes).</p>
<p>Now, the Model Optimizer knows how to replace the sub-graph. The last step to enable the model is to cut-off some parts of the graph not needed during inference.</p>
<p>It is necessary to remove the <code>Preprocessor</code> block where image is resized. Inference Engine does not support dynamic input shapes, so the Model Optimizer must froze the input image size, and thus, resizing of the image is not necessary. This is achieved by replacer <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf/Preprocessor.py</code> which is executed automatically.</p>
<p>There are several <code>Switch</code> operations in the <code>Postprocessor</code> block without output edges. For example: </p><div class="fragment"><div class="line">Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/cond/switch_t</div></div><!-- fragment --> <div class="fragment"><div class="line">Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/cond/switch_f</div></div><!-- fragment --> <div class="fragment"><div class="line">Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond_1/cond/switch_t</div></div><!-- fragment --> <div class="fragment"><div class="line">Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond_1/cond/switch_f</div></div><!-- fragment --><p>Model Optimizer marks these nodes as output nodes of the topology. Some parts of the <code>Posprocessor</code> blocks are not removed during sub-graph replacement because of that. In order to fix this issue, it is necessary to specify output nodes of the graph manually using the <code>--output</code> command line parameter.</p>
<h3>Example Model Optimizer Command-Line for TensorFlow* SSD</h3>
<p>The final command line to convert SSDs from the TensorFlow Object Detection API Zoo is: </p><div class="fragment"><div class="line">./mo_tf.py --input_model=&lt;path_to_frozen.pb&gt; --tensorflow_use_custom_operations_config extensions/front/tf/legacy_ssd_support.json --output=&quot;detection_boxes,detection_scores,num_detections&quot;</div></div><!-- fragment --><h2>Converting MobileNet V2 model created with TensorFlow Object Detection API <a class="anchor" id="convert_mobilenet_v2"></a></h2>
<p>The <a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz">MobileNet V2 model</a> differs from the previous version, so converting the model requires a new sub-graph replacement configuration file and new command line parameters. The major differences are:</p>
<ul>
<li>The <code>Preprocessor</code> block has two outputs: the pre-processed image and the pre-processed image size.</li>
<li>The <code>Postprocessor</code> block has one more input (in comparison with models created with TensorFlow Object Detection API version 1.6 or lower): the pre-processed image size.</li>
<li>Some node names have been changed in the <code>Postprocessor</code> block.</li>
</ul>
<p>The updated sub-graph replacement configuration file <code>extensions/front/tf/ssd_v2_support.json</code> reflecting these changes is the following:</p>
<div class="fragment"><div class="line">[</div><div class="line">    {</div><div class="line">        &quot;custom_attributes&quot;: {</div><div class="line">            &quot;code_type&quot;: &quot;caffe.PriorBoxParameter.CENTER_SIZE&quot;,</div><div class="line">            &quot;confidence_threshold&quot;: 0.01,</div><div class="line">            &quot;keep_top_k&quot;: 200,</div><div class="line">            &quot;nms_threshold&quot;: 0.6,</div><div class="line">            &quot;pad_mode&quot;: &quot;caffe.ResizeParameter.CONSTANT&quot;,</div><div class="line">            &quot;resize_mode&quot;: &quot;caffe.ResizeParameter.WARP&quot;</div><div class="line">        },</div><div class="line">        &quot;id&quot;: &quot;TFObjectDetectionAPIDetectionOutput&quot;,</div><div class="line">        &quot;include_inputs_to_sub_graph&quot;: true,</div><div class="line">        &quot;include_outputs_to_sub_graph&quot;: true,</div><div class="line">        &quot;instances&quot;: {</div><div class="line">            &quot;end_points&quot;: [</div><div class="line">                &quot;detection_boxes&quot;,</div><div class="line">                &quot;detection_scores&quot;,</div><div class="line">                &quot;num_detections&quot;</div><div class="line">            ],</div><div class="line">            &quot;start_points&quot;: [</div><div class="line">                &quot;Postprocessor/Shape&quot;,</div><div class="line">                &quot;Postprocessor/scale_logits&quot;,</div><div class="line">                &quot;Postprocessor/ExpandDims&quot;,</div><div class="line">                &quot;Postprocessor/Reshape_1&quot;,</div><div class="line">                &quot;Postprocessor/ToFloat&quot;</div><div class="line">            ]</div><div class="line">        },</div><div class="line">        &quot;match_kind&quot;: &quot;points&quot;</div><div class="line">    },</div><div class="line">    {</div><div class="line">        &quot;custom_attributes&quot;: {</div><div class="line">        },</div><div class="line">        &quot;id&quot;: &quot;PreprocessorReplacement&quot;,</div><div class="line">        &quot;inputs&quot;: [</div><div class="line">            [</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/Shape$&quot;,</div><div class="line">                    &quot;port&quot;: 0</div><div class="line">                },</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/TensorArrayUnstack/Shape$&quot;,</div><div class="line">                    &quot;port&quot;: 0</div><div class="line">                },</div><div class="line">                {</div><div class="line">                    &quot;node&quot;: &quot;map/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3$&quot;,</div><div class="line">                    &quot;port&quot;: 2</div><div class="line">                }</div><div class="line">            ]</div><div class="line">        ],</div><div class="line">        &quot;instances&quot;: [</div><div class="line">            &quot;.*Preprocessor/&quot;</div><div class="line">        ],</div><div class="line">        &quot;match_kind&quot;: &quot;scope&quot;,</div><div class="line">        &quot;outputs&quot;: [</div><div class="line">            {</div><div class="line">                &quot;node&quot;: &quot;sub$&quot;,</div><div class="line">                &quot;port&quot;: 0</div><div class="line">            },</div><div class="line">            {</div><div class="line">                &quot;node&quot;: &quot;map/TensorArrayStack_1/TensorArrayGatherV3$&quot;,</div><div class="line">                &quot;port&quot;: 0</div><div class="line">            }</div><div class="line">        ]</div><div class="line">    }</div><div class="line">]</div></div><!-- fragment --><h3>Example of Model Optimizer Command-Line for TensorFlow SSD MobileNet V2</h3>
<p>The final command line to convert MobileNet SSD V2 from the TensorFlow Object Detection Zoo is the following:</p>
<div class="fragment"><div class="line">./mo_tf.py --input_model=&lt;path_to_frozen.pb&gt; --tensorflow_use_custom_operations_config extensions/front/tf/ssd_v2_support.json --output=&quot;detection_boxes,detection_scores,num_detections&quot;</div></div><!-- fragment --> </div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>