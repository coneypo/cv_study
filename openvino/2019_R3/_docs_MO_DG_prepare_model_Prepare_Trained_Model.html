<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Preparing and Optimizing Your Trained Model - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Preparing and Optimizing Your Trained Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Inference Engine enables <em>deploying</em> your network model trained with any of supported deep learning frameworks: Caffe*, TensorFlow*, Kaldi*, MXNet* or converted to the ONNX* format. To perform the inference, the Inference Engine does not operate with the original model, but with its Intermediate Representation (IR), which is optimized for execution on end-point target devices. To generate an IR for your trained model, the Model Optimizer tool is used.</p>
<h2>How the Model Optimizer Works</h2>
<p>Model Optimizer loads a model into memory, reads it, builds the internal representation of the model, optimizes it, and produces the Intermediate Representation. Intermediate Representation is the only format the Inference Engine accepts.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: Model Optimizer does not infer models. Model Optimizer is an offline tool that runs before the inference takes place. </p>
</blockquote>
<p>Model Optimizer has two main purposes:</p>
<ul>
<li><b>Produce a valid Intermediate Representation</b>. If this main conversion artifact is not valid, the Inference Engine cannot run. The primary responsibility of the Model Optimizer is to produce the two files (<code>.xml</code> and <code>.bin</code>) that form the Intermediate Representation.</li>
<li><b>Produce an optimized Intermediate Representation</b>. Pre-trained models contain layers that are important for training, such as the <code>Dropout</code> layer. These layers are useless during inference and might increase the inference time. In many cases, these layers can be automatically removed from the resulting Intermediate Representation. However, if a group of layers can be represented as one mathematical operation, and thus as a single layer, the Model Optimizer recognizes such patterns and replaces these layers with the only one. The result is an Intermediate Representation that has fewer layers than the original model. This decreases the inference time.</li>
</ul>
<p>To produce a valid Intermediate Representation, the Model Optimizer must be able to read the original model layers, handle their properties and represent them in Intermediate Representation format, while maintaining validity of the resulting Intermediate Representation.</p>
<p>For example, according to the <a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">catalog of Intermediate Representation layers</a>, every layer must have an output. The layer <code>output</code> is represented in the Intermediate Representation by the output blob dimensions.</p>
<h2>What You Need to Know about Your Model</h2>
<p>Many common layers exist across known frameworks and neural network topologies. Examples of these layers are <code>Convolution</code>, <code>Pooling</code>, and <code>Activation</code>. To read the original model and produce the Intermediate Representation of a model, the Model Optimizer must be able to work with these layers.</p>
<p>The full list of them depends on the framework and can be found in the <a class="el" href="_docs_MO_DG_prepare_model_Supported_Frameworks_Layers.html">Supported Framework Layers</a> section. If your topology contains only layers from the list of layers, as is the case for the topologies used by most users, the Model Optimizer easily creates the Intermediate Representation. After that you can proceed to work with the Inference Engine.</p>
<p>However, if you use a topology with layers that are not recognized by the Model Optimizer out of the box, see <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">Custom Layers in the Model Optimizer</a> to learn how to work with custom layers.</p>
<h2>Model Optimizer Directory Structure</h2>
<p>After installation with OpenVINO&trade; toolkit or Intel&reg; Deep Learning Deployment Toolkit, the Model Optimizer folder has the following structure: </p><div class="fragment"><div class="line">|-- model_optimizer</div><div class="line">    |-- extensions</div><div class="line">        |-- front - Front-End framework agnostic transformations (operations output shapes are not defined yet). </div><div class="line">            |-- caffe - Front-End Caffe-specific transformations and Caffe layers extractors</div><div class="line">                |-- CustomLayersMapping.xml.example - example of file for registering custom Caffe layers (compatible with the 2017R3 release)</div><div class="line">            |-- kaldi - Front-End Kaldi-specific transformations and Kaldi operations extractors</div><div class="line">            |-- mxnet - Front-End MxNet-specific transformations and MxNet symbols extractors</div><div class="line">            |-- onnx - Front-End ONNX-specific transformations and ONNX operators extractors            </div><div class="line">            |-- tf - Front-End TensorFlow-specific transformations, TensorFlow operations extractors, sub-graph replacements configuration files. </div><div class="line">        |-- middle - Middle-End framework agnostic transformations (layers output shapes are defined).</div><div class="line">        |-- back - Back-End framework agnostic transformations (preparation for IR generation).        </div><div class="line">    |-- mo</div><div class="line">        |-- back - Back-End logic: contains IR emitting logic</div><div class="line">        |-- front - Front-End logic: contains matching between Framework-specific layers and IR specific, calculation of output shapes for each registered layer</div><div class="line">        |-- graph - Graph utilities to work with internal IR representation</div><div class="line">        |-- middle - Graph transformations - optimizations of the model</div><div class="line">        |-- pipeline - Sequence of steps required to create IR for each framework</div><div class="line">        |-- utils - Utility functions</div><div class="line">    |-- tf_call_ie_layer - Source code that enables TensorFlow fallback in Inference Engine during model inference</div><div class="line">    |-- mo.py - Centralized entry point that can be used for any supported framework</div><div class="line">    |-- mo_caffe.py - Entry point particularly for Caffe</div><div class="line">    |-- mo_kaldi.py - Entry point particularly for Kaldi</div><div class="line">    |-- mo_mxnet.py - Entry point particularly for MXNet</div><div class="line">    |-- mo_onnx.py - Entry point particularly for ONNX</div><div class="line">    |-- mo_tf.py - Entry point particularly for TensorFlow</div></div><!-- fragment --><p>The following sections provide the information about how to use the Model Optimizer, from configuring the tool and generating an IR for a given model to customizing the tool for your needs:</p>
<ul>
<li><a class="el" href="_docs_MO_DG_prepare_model_Config_Model_Optimizer.html">Configuring Model Optimizer</a></li>
<li><a class="el" href="_docs_MO_DG_prepare_model_convert_model_Converting_Model.html">Converting a Model to Intermediate Representation</a></li>
<li><a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">Custom Layers in Model Optimizer</a></li>
<li><a class="el" href="_docs_MO_DG_prepare_model_Model_Optimization_Techniques.html">Model Optimization Techniques</a></li>
<li><a class="el" href="_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">Model Optimizer Frequently Asked Questions</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>