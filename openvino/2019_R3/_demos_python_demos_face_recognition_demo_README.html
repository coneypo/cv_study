<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Interactive Face Recognition Demo - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Interactive Face Recognition Demo </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This example demonstrates an approach to create interactive applications for video processing. It shows the basic architecture for building model pipelines supporting model placement on different devices and simultaneous parallel or sequential execution using OpenVINO library in Python. In particular, this demo uses 3 models to build a pipeline able to detect faces on videos, their keypoints (aka "landmarks"), and recognize persons using the provided faces database (the gallery). The following pretrained models can be used:</p>
<ul>
<li><code>face-detection-retail-0004</code> and <code>face-detection-adas-0001</code>, to detect faces and predict their bounding boxes;</li>
<li><code>landmarks-regression-retail-0009</code>, to predict face keypoints;</li>
<li><code>face-reidentification-retail-0095</code>, to recognize persons.</li>
</ul>
<p>For more information about the pre-trained models, refer to the <a class="el" href="_models_intel_index.html">model documentation</a>.</p>
<h3>How it works</h3>
<p>The application is invoked from command line. It reads the specified input video stream frame-by-frame, be it a camera device or a video file, and performs independent analysis of each frame. In order to make predictions the application deploys 3 models on the specified devices using OpenVINO library and runs them in asynchronous manner. An input frame is processed by the face detection model to predict face bounding boxes. Then, face keypoints are predicted by the corresponding model. The final step in frame processing is done by the face recognition model, which uses keypoints found to align the faces and the face gallery to match faces found on a video frame with the ones in the gallery. Then, the processing results are visualized and displayed on the screen or written to the output file.</p>
<h3>Creating a gallery for face recognition</h3>
<p>To recognize faces the application uses a face database, or a gallery. The gallery is a folder with images of persons. Each image in the gallery can be of arbitrary size and should contain one or more frontally-oriented faces with decent quality. There are allowed multiple images of the same person, but the naming format in that case should be specific - <code>{id}-{num_of_instance}.jpg</code>. For example, there could be images <code>Paul-0.jpg</code>, <code>Paul-1.jpg</code> etc. and they all will be treated as images of the same person. In case when there is one image per person, you can use format <code>{id}.jpg</code> (e.g. <code>Paul.jpg</code>). The application can use face detector during the gallery building, that is controlled by <code>--run_detector</code> flag. This allows gallery images to contain more than one face image and not to be tightly cropped. In that mode the user will be asked if he wants to add a specific image to the images gallery (and it leads to automatic dumping images to the same folder on disk). If it is, then the user should specify the name for the image in the open window and press <code>Enter</code>. If it's not, then press <code>Escape</code>. The user may add multiple images of the same person by setting the same name in the open window. However, the resulting gallery needs to be checked more thoroughly, since a face detector can fail and produce poor crops.</p>
<p>Image file name is used as a person name during the visualization. Use the following name convention: <code>person_N_name.png</code> or <code>person_N_name.jpg</code>.</p>
<h3>Installation and dependencies</h3>
<p>The demo depends on:</p><ul>
<li>OpenVINO library (2018R5 or newer)</li>
<li>Python (any of 2.7+ or 3.4+, which is supported by OpenVINO)</li>
<li>OpenCV (&gt;=3.4.0)</li>
</ul>
<p>To install all the required Python modules you can use:</p>
<div class="fragment"><div class="line">pip install -r requirements.txt</div></div><!-- fragment --><h3>Running the demo:</h3>
<p>Running the application with the <code>-h</code> option or without any arguments yields the following message:</p>
<div class="fragment"><div class="line">python ./face_recognition_demo.py -h</div><div class="line"></div><div class="line">usage: face_recognition_demo.py [-h] [-i PATH] [-o PATH] [--no_show] [-tl]</div><div class="line">                                [-cw CROP_WIDTH] [-ch CROP_HEIGHT]</div><div class="line">                                [--match_algo {HUNGARIAN,MIN_DIST}] -fg PATH</div><div class="line">                                [--run_detector] -m_fd PATH -m_lm PATH -m_reid</div><div class="line">                                PATH [-fd_iw FD_INPUT_WIDTH]</div><div class="line">                                [-fd_ih FD_INPUT_HEIGHT]</div><div class="line">                                [-d_fd {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}]</div><div class="line">                                [-d_lm {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}]</div><div class="line">                                [-d_reid {CPU,GPU,FPGA,MYRIAD,HETERO,HDDL}]</div><div class="line">                                [-l PATH] [-c PATH] [-v] [-pc] [-t_fd [0..1]]</div><div class="line">                                [-t_id [0..1]] [-exp_r_fd NUMBER]</div><div class="line"></div><div class="line">optional arguments:</div><div class="line">  -h, --help            show this help message and exit</div><div class="line"></div><div class="line">General:</div><div class="line">  -i PATH, --input PATH</div><div class="line">                        (optional) Path to the input video (&#39;cam&#39; for the</div><div class="line">                        camera, default)</div><div class="line">  -o PATH, --output PATH</div><div class="line">                        (optional) Path to save the output video to</div><div class="line">  --no_show             (optional) Do not display output</div><div class="line">  -tl, --timelapse      (optional) Auto-pause after each frame</div><div class="line">  -cw CROP_WIDTH, --crop_width CROP_WIDTH</div><div class="line">                        (optional) Crop the input stream to this width</div><div class="line">                        (default: no crop). Both -cw and -ch parameters should</div><div class="line">                        be specified to use crop.</div><div class="line">  -ch CROP_HEIGHT, --crop_height CROP_HEIGHT</div><div class="line">                        (optional) Crop the input stream to this height</div><div class="line">                        (default: no crop). Both -cw and -ch parameters should</div><div class="line">                        be specified to use crop.</div><div class="line">  --match_algo {HUNGARIAN,MIN_DIST}</div><div class="line">                        (optional)algorithm for face matching(default:</div><div class="line">                        HUNGARIAN)</div><div class="line"></div><div class="line">Faces database:</div><div class="line">  -fg PATH              Path to the face images directory</div><div class="line">  --run_detector        (optional) Use Face Detection model to find faces on</div><div class="line">                        the face images, otherwise use full images.</div><div class="line">  --allow_grow          (optional) Flag to allow growing the face database,</div><div class="line">                        in addition allow dumping new faces on disk. In that</div><div class="line">                        case the user will be asked if he wants to add a</div><div class="line">                        specific image to the images gallery (and it leads to</div><div class="line">                        automatic dumping images to the same folder on disk).</div><div class="line">                        If it is, then the user should specify the name for</div><div class="line">                        the image in the open window and press `Enter`.</div><div class="line">                        If it&#39;s not, then press `Escape`. The user may add</div><div class="line">                        new images for the same person by setting the same</div><div class="line">                        name in the open window.</div><div class="line"></div><div class="line">Models:</div><div class="line">  -m_fd PATH            Path to the Face Detection model XML file</div><div class="line">  -m_lm PATH            Path to the Facial Landmarks Regression model XML file</div><div class="line">  -m_reid PATH          Path to the Face Reidentification model XML file</div><div class="line">  -fd_iw FD_INPUT_WIDTH, --fd_input_width FD_INPUT_WIDTH</div><div class="line">                        (optional) specify the input width of detection model</div><div class="line">                        (default: use default input width of model).</div><div class="line">                        Both -fd_iw and -fd_ih parameters should be specified</div><div class="line">                        for reshape.</div><div class="line">  -fd_ih FD_INPUT_HEIGHT, --fd_input_height FD_INPUT_HEIGHT</div><div class="line">                        (optional) specify the input height of detection model</div><div class="line">                        (default: use default input height of model). </div><div class="line">                        Both -fd_iw and -fd_ih parameters should be specified</div><div class="line">                        for reshape.</div><div class="line"></div><div class="line">Inference options:</div><div class="line">  -d_fd {CPU,GPU,FPGA,MYRIAD,HETERO}</div><div class="line">                        (optional) Target device for the Face Detection model</div><div class="line">                        (default: CPU)</div><div class="line">  -d_lm {CPU,GPU,FPGA,MYRIAD,HETERO}</div><div class="line">                        (optional) Target device for the Facial Landmarks</div><div class="line">                        Regression model (default: CPU)</div><div class="line">  -d_reid {CPU,GPU,FPGA,MYRIAD,HETERO}</div><div class="line">                        (optional) Target device for the Face Reidentification</div><div class="line">                        model (default: CPU)</div><div class="line">  -l PATH, --cpu_lib PATH</div><div class="line">                        (optional) For MKLDNN (CPU)-targeted custom layers, if</div><div class="line">                        any. Path to a shared library with custom layers</div><div class="line">                        implementations</div><div class="line">  -c PATH, --gpu_lib PATH</div><div class="line">                        (optional) For clDNN (GPU)-targeted custom layers, if</div><div class="line">                        any. Path to the XML file with descriptions of the</div><div class="line">                        kernels</div><div class="line">  -v, --verbose         (optional) Be more verbose</div><div class="line">  -pc, --perf_stats     (optional) Output detailed per-layer performance stats</div><div class="line">  -t_fd [0..1]          (optional) Probability threshold for face</div><div class="line">                        detections(default: 0.6)</div><div class="line">  -t_id [0..1]          (optional) Cosine distance threshold between two</div><div class="line">                        vectors for face identification (default: 0.3)</div><div class="line">  -exp_r_fd NUMBER      (optional) Scaling ratio for bboxes passed to face</div><div class="line">                        recognition (default: 1.15)</div></div><!-- fragment --><p>Example of a valid command line to run the application:</p>
<p>Linux (<code>sh</code>, <code>bash</code>, ...) (assuming OpenVINO installed in <code>/opt/intel/openvino</code>):</p>
<div class="fragment"><div class="line"># Set up the environment</div><div class="line">source /opt/intel/openvino/bin/setupvars.sh</div><div class="line"></div><div class="line">python ./face_recognition_demo.py \</div><div class="line">-m_fd &lt;path_to_model&gt;/face-detection-retail-0004.xml \</div><div class="line">-m_lm &lt;path_to_model&gt;/landmarks-regression-retail-0009.xml \</div><div class="line">-m_reid &lt;path_to_model&gt;/face-reidentification-retail-0095.xml \</div><div class="line">-l &lt;path_to_cpu_extensions&gt;/libcpu_extension_sse4.so \</div><div class="line">--verbose \</div><div class="line">-fg &quot;/home/face_gallery&quot;</div></div><!-- fragment --><p>Windows (<code>cmd</code>, <code>powershell</code>) (assuming OpenVINO installed in <code>C:/Intel/openvino</code>):</p>
<div class="fragment"><div class="line"># Set up the environment</div><div class="line">call C:/Intel/openvino/bin/setupvars.bat</div><div class="line"></div><div class="line">python ./face_recognition_demo.py ^</div><div class="line">-m_fd &lt;path_to_model&gt;/face-detection-retail-0004.xml ^</div><div class="line">-m_lm &lt;path_to_model&gt;/landmarks-regression-retail-0009.xml ^</div><div class="line">-m_reid &lt;path_to_model&gt;/face-reidentification-retail-0095.xml ^</div><div class="line">-l &lt;path_to_cpu_extensions&gt;/cpu_extension_avx2.dll ^</div><div class="line">--verbose ^</div><div class="line">-fg &quot;C:/face_gallery&quot;</div></div><!-- fragment --><p>Notice that the custom networks should be converted to the Inference Engine format (*.xml + *bin) first. To do this use the <a href="https://software.intel.com/en-us/articles/OpenVINO-ModelOptimizer">Model Optimizer</a> tool.</p>
<h3>Demo output</h3>
<p>The demo uses OpenCV window to display the resulting video frame and detections. If specified, it also writes output to a file. It outputs logs to the terminal.</p>
<h2>See also</h2>
<ul>
<li><a class="el" href="_demos_README.html">Using Inference Engine Demos</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>