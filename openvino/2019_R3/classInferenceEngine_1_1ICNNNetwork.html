<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>InferenceEngine::ICNNNetwork Class Reference - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceInferenceEngine.html">InferenceEngine</a></li><li class="navelem"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html">ICNNNetwork</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">InferenceEngine::ICNNNetwork Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>This is the main interface to describe the NN topology.  
 <a href="classInferenceEngine_1_1ICNNNetwork.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="ie__icnn__network_8hpp_source.html">ie_icnn_network.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for InferenceEngine::ICNNNetwork:</div>
<div class="dyncontent">
<div class="center"><img src="classInferenceEngine_1_1ICNNNetwork__inherit__graph.png" border="0" usemap="#InferenceEngine_1_1ICNNNetwork_inherit__map" alt="Inheritance graph"/></div>
<map name="InferenceEngine_1_1ICNNNetwork_inherit__map" id="InferenceEngine_1_1ICNNNetwork_inherit__map">
<area shape="rect" id="node2" title="This class is used for objects allocated by a shared module (in *.so) " alt="" coords="27,95,206,136"/>
<area shape="rect" id="node3" title="This class is used for objects returned from the shared library factory to prevent copying..." alt="" coords="27,5,206,47"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for InferenceEngine::ICNNNetwork:</div>
<div class="dyncontent">
<div class="center"><img src="classInferenceEngine_1_1ICNNNetwork__coll__graph.png" border="0" usemap="#InferenceEngine_1_1ICNNNetwork_coll__map" alt="Collaboration graph"/></div>
<map name="InferenceEngine_1_1ICNNNetwork_coll__map" id="InferenceEngine_1_1ICNNNetwork_coll__map">
<area shape="rect" id="node2" title="This class is used for objects allocated by a shared module (in *.so) " alt="" coords="27,95,206,136"/>
<area shape="rect" id="node3" title="This class is used for objects returned from the shared library factory to prevent copying..." alt="" coords="27,5,206,47"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a05b6f650d23e571e03da46a3a89db633"><td class="memItemLeft" align="right" valign="top"><a id="a05b6f650d23e571e03da46a3a89db633"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>Ptr</b> = std::shared_ptr&lt; <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html">ICNNNetwork</a> &gt;</td></tr>
<tr class="separator:a05b6f650d23e571e03da46a3a89db633"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bcef7f638f6588a672a32080047ff1d"><td class="memItemLeft" align="right" valign="top"><a id="a8bcef7f638f6588a672a32080047ff1d"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a8bcef7f638f6588a672a32080047ff1d">InputShapes</a> = std::map&lt; std::string, <a class="el" href="namespaceInferenceEngine.html#a9400de686d3d0f48c30cd73d40e48576">SizeVector</a> &gt;</td></tr>
<tr class="memdesc:a8bcef7f638f6588a672a32080047ff1d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Map of pairs: name of corresponding data and its dimension. <br /></td></tr>
<tr class="separator:a8bcef7f638f6588a672a32080047ff1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aca41e0f5e93332cd143192b5b0155a5d"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classInferenceEngine_1_1Precision.html">Precision</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#aca41e0f5e93332cd143192b5b0155a5d">getPrecision</a> () const noexcept=0</td></tr>
<tr class="memdesc:aca41e0f5e93332cd143192b5b0155a5d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the main network operating precision. This may be MIXED if not homogeneous.  <a href="#aca41e0f5e93332cd143192b5b0155a5d">More...</a><br /></td></tr>
<tr class="separator:aca41e0f5e93332cd143192b5b0155a5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67b659f1a8fd1574bb1939ea3f672fad"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a67b659f1a8fd1574bb1939ea3f672fad">getOutputsInfo</a> (<a class="el" href="namespaceInferenceEngine.html#a76ce999f68455cf962a473718deb500c">OutputsDataMap</a> &amp;out) const noexcept=0</td></tr>
<tr class="memdesc:a67b659f1a8fd1574bb1939ea3f672fad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the network output <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node information. The received info is stored in the given <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node. For single and multiple outputs networks.  <a href="#a67b659f1a8fd1574bb1939ea3f672fad">More...</a><br /></td></tr>
<tr class="separator:a67b659f1a8fd1574bb1939ea3f672fad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0d904dcfd039972e04923f1e0befbdd"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac0d904dcfd039972e04923f1e0befbdd">getInputsInfo</a> (<a class="el" href="namespaceInferenceEngine.html#a08270747275eb79985154365aa782a2a">InputsDataMap</a> &amp;inputs) const noexcept=0</td></tr>
<tr class="memdesc:ac0d904dcfd039972e04923f1e0befbdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the network input <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node information. The received info is stored in the given InputsDataMap object. For single and multiple inputs networks. This method must be called to find out input names for using them later during filling of a map of blobs passed later to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a9d2f325d953d4f7fea65ae9f3188022b" title="Infers an image(s). Input and output dimensions depend on the topology. As an example for classificat...">InferenceEngine::IInferencePlugin::Infer()</a>  <a href="#ac0d904dcfd039972e04923f1e0befbdd">More...</a><br /></td></tr>
<tr class="separator:ac0d904dcfd039972e04923f1e0befbdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae952db225b323f5c809ded22c30da4ed"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classInferenceEngine_1_1InputInfo.html#a607e9d454a48136c3cae731cc5a140d2">InputInfo::Ptr</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ae952db225b323f5c809ded22c30da4ed">getInput</a> (const std::string &amp;inputName) const noexcept=0</td></tr>
<tr class="memdesc:ae952db225b323f5c809ded22c30da4ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns information on certain input pointed by inputName.  <a href="#ae952db225b323f5c809ded22c30da4ed">More...</a><br /></td></tr>
<tr class="separator:ae952db225b323f5c809ded22c30da4ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85a482ac476c13554b959ebd1efeb312"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a85a482ac476c13554b959ebd1efeb312">getName</a> (char *pName, size_t len) const noexcept=0</td></tr>
<tr class="memdesc:a85a482ac476c13554b959ebd1efeb312"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the network name. The name is stored in the given pName string.  <a href="#a85a482ac476c13554b959ebd1efeb312">More...</a><br /></td></tr>
<tr class="separator:a85a482ac476c13554b959ebd1efeb312"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5cb3d873dd395d2537cbafce612f5a44"><td class="memItemLeft" align="right" valign="top">virtual const std::string &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a5cb3d873dd395d2537cbafce612f5a44">getName</a> () const noexcept=0</td></tr>
<tr class="memdesc:a5cb3d873dd395d2537cbafce612f5a44"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the network name.  <a href="#a5cb3d873dd395d2537cbafce612f5a44">More...</a><br /></td></tr>
<tr class="separator:a5cb3d873dd395d2537cbafce612f5a44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab170b0f4b3f85237f6aa97a5844be519"><td class="memItemLeft" align="right" valign="top">virtual size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ab170b0f4b3f85237f6aa97a5844be519">layerCount</a> () const noexcept=0</td></tr>
<tr class="memdesc:ab170b0f4b3f85237f6aa97a5844be519"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the number of layers in the network as an integer value.  <a href="#ab170b0f4b3f85237f6aa97a5844be519">More...</a><br /></td></tr>
<tr class="separator:ab170b0f4b3f85237f6aa97a5844be519"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5add149aee50cbcfecc76901f8d81a89"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a91f97c826d2753815815c119ba383e63">DataPtr</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a5add149aee50cbcfecc76901f8d81a89">getData</a> (const char *dname) noexcept=0</td></tr>
<tr class="memdesc:a5add149aee50cbcfecc76901f8d81a89"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a smart pointer reference to a <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node given its name. If the <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node is missing, returns reference to a default initialized new empty data pointer with given name.  <a href="#a5add149aee50cbcfecc76901f8d81a89">More...</a><br /></td></tr>
<tr class="separator:a5add149aee50cbcfecc76901f8d81a89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5da0c5819a7507a4bc1f137b251be24"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#af5da0c5819a7507a4bc1f137b251be24">addLayer</a> (const <a class="el" href="namespaceInferenceEngine.html#af972e334feb2788341e38ac3e6103e60">CNNLayerPtr</a> &amp;layer) noexcept=0</td></tr>
<tr class="memdesc:af5da0c5819a7507a4bc1f137b251be24"><td class="mdescLeft">&#160;</td><td class="mdescRight">Insert a layer into the network. A user is responsible to connect it to other data elements.  <a href="#af5da0c5819a7507a4bc1f137b251be24">More...</a><br /></td></tr>
<tr class="separator:af5da0c5819a7507a4bc1f137b251be24"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07f2f7ada6d7208710ae3dc144347df8"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a07f2f7ada6d7208710ae3dc144347df8">addOutput</a> (const std::string &amp;layerName, size_t outputIndex=0, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *resp=nullptr) noexcept=0</td></tr>
<tr class="memdesc:a07f2f7ada6d7208710ae3dc144347df8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adds output to the layer.  <a href="#a07f2f7ada6d7208710ae3dc144347df8">More...</a><br /></td></tr>
<tr class="separator:a07f2f7ada6d7208710ae3dc144347df8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9661a132ab8eabe950d41ecd53221c0a"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a9661a132ab8eabe950d41ecd53221c0a">getLayerByName</a> (const char *layerName, <a class="el" href="namespaceInferenceEngine.html#af972e334feb2788341e38ac3e6103e60">CNNLayerPtr</a> &amp;out, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *resp) const noexcept=0</td></tr>
<tr class="memdesc:a9661a132ab8eabe950d41ecd53221c0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets network layer with the given name.  <a href="#a9661a132ab8eabe950d41ecd53221c0a">More...</a><br /></td></tr>
<tr class="separator:a9661a132ab8eabe950d41ecd53221c0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1896dd3645734522b8f2b68a40d3f8e"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac1896dd3645734522b8f2b68a40d3f8e">setTargetDevice</a> (<a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796">TargetDevice</a> device) noexcept=0</td></tr>
<tr class="memdesc:ac1896dd3645734522b8f2b68a40d3f8e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets a desirable device to perform all work on. Some plug-ins might not support some target devices and may abort execution with an appropriate error message.  <a href="#ac1896dd3645734522b8f2b68a40d3f8e">More...</a><br /></td></tr>
<tr class="separator:ac1896dd3645734522b8f2b68a40d3f8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ac8ac85442ca15673a9e7865a578364"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796">TargetDevice</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a0ac8ac85442ca15673a9e7865a578364">getTargetDevice</a> () const noexcept=0</td></tr>
<tr class="memdesc:a0ac8ac85442ca15673a9e7865a578364"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the target device. If <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac1896dd3645734522b8f2b68a40d3f8e" title="Sets a desirable device to perform all work on. Some plug-ins might not support some target devices a...">setTargetDevice()</a> was not called before, returns eDefault.  <a href="#a0ac8ac85442ca15673a9e7865a578364">More...</a><br /></td></tr>
<tr class="separator:a0ac8ac85442ca15673a9e7865a578364"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abe649d332d99d5c6abda004cfe659ad1"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#abe649d332d99d5c6abda004cfe659ad1">setBatchSize</a> (const size_t size) noexcept</td></tr>
<tr class="memdesc:abe649d332d99d5c6abda004cfe659ad1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Changes the inference batch size.  <a href="#abe649d332d99d5c6abda004cfe659ad1">More...</a><br /></td></tr>
<tr class="separator:abe649d332d99d5c6abda004cfe659ad1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac29fc798d8a318f380624bd350b28501"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac29fc798d8a318f380624bd350b28501">setBatchSize</a> (size_t size, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *responseDesc) noexcept=0</td></tr>
<tr class="memdesc:ac29fc798d8a318f380624bd350b28501"><td class="mdescLeft">&#160;</td><td class="mdescRight">Changes the inference batch size.  <a href="#ac29fc798d8a318f380624bd350b28501">More...</a><br /></td></tr>
<tr class="separator:ac29fc798d8a318f380624bd350b28501"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa40a55d05b2908287af7f17ea96dd7e9"><td class="memItemLeft" align="right" valign="top">virtual size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#aa40a55d05b2908287af7f17ea96dd7e9">getBatchSize</a> () const noexcept=0</td></tr>
<tr class="memdesc:aa40a55d05b2908287af7f17ea96dd7e9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the inference batch size.  <a href="#aa40a55d05b2908287af7f17ea96dd7e9">More...</a><br /></td></tr>
<tr class="separator:aa40a55d05b2908287af7f17ea96dd7e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98affa5884d9884ca12ff347ac5c26e4"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a98affa5884d9884ca12ff347ac5c26e4">reshape</a> (const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a8bcef7f638f6588a672a32080047ff1d">InputShapes</a> &amp;, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *) noexcept</td></tr>
<tr class="memdesc:a98affa5884d9884ca12ff347ac5c26e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run shape inference with new input shapes for the network.  <a href="#a98affa5884d9884ca12ff347ac5c26e4">More...</a><br /></td></tr>
<tr class="separator:a98affa5884d9884ca12ff347ac5c26e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32c6e07a71a0570d7a44fa3b2ae7064c"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a32c6e07a71a0570d7a44fa3b2ae7064c">AddExtension</a> (const IShapeInferExtensionPtr &amp;, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *) noexcept</td></tr>
<tr class="memdesc:a32c6e07a71a0570d7a44fa3b2ae7064c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Registers extension within the plugin.  <a href="#a32c6e07a71a0570d7a44fa3b2ae7064c">More...</a><br /></td></tr>
<tr class="separator:a32c6e07a71a0570d7a44fa3b2ae7064c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac37a4417a36a32bad1e51bf060f1dc53"><td class="memItemLeft" align="right" valign="top"><a id="ac37a4417a36a32bad1e51bf060f1dc53"></a>
virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><b>getStats</b> (<a class="el" href="classInferenceEngine_1_1ICNNNetworkStats.html">ICNNNetworkStats</a> **, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *) const noexcept</td></tr>
<tr class="separator:ac37a4417a36a32bad1e51bf060f1dc53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd12b5e9b9c6881ce33230a77b3031cf"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#acd12b5e9b9c6881ce33230a77b3031cf">serialize</a> (const std::string &amp;xmlPath, const std::string &amp;binPath, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *resp) const noexcept=0</td></tr>
<tr class="memdesc:acd12b5e9b9c6881ce33230a77b3031cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Serialize network to IR and weights files.  <a href="#acd12b5e9b9c6881ce33230a77b3031cf">More...</a><br /></td></tr>
<tr class="separator:acd12b5e9b9c6881ce33230a77b3031cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This is the main interface to describe the NN topology. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a32c6e07a71a0570d7a44fa3b2ae7064c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32c6e07a71a0570d7a44fa3b2ae7064c">&sect;&nbsp;</a></span>AddExtension()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::AddExtension </td>
          <td>(</td>
          <td class="paramtype">const IShapeInferExtensionPtr &amp;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Registers extension within the plugin. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">extension</td><td>Pointer to already loaded reader extension with shape propagation implementations </td></tr>
    <tr><td class="paramname">resp</td><td>Pointer to the response message that holds a description of an error if any occurred </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation. OK if succeeded </dd></dl>

</div>
</div>
<a id="af5da0c5819a7507a4bc1f137b251be24"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5da0c5819a7507a4bc1f137b251be24">&sect;&nbsp;</a></span>addLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void InferenceEngine::ICNNNetwork::addLayer </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="namespaceInferenceEngine.html#af972e334feb2788341e38ac3e6103e60">CNNLayerPtr</a> &amp;&#160;</td>
          <td class="paramname"><em>layer</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Insert a layer into the network. A user is responsible to connect it to other data elements. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer</td><td>Const reference to a layer smart pointer </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a07f2f7ada6d7208710ae3dc144347df8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07f2f7ada6d7208710ae3dc144347df8">&sect;&nbsp;</a></span>addOutput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::addOutput </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>layerName</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>outputIndex</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname"><em>resp</em> = <code>nullptr</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adds output to the layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layerName</td><td>Name of the layer </td></tr>
    <tr><td class="paramname">outputIndex</td><td>Index of the output </td></tr>
    <tr><td class="paramname">resp</td><td>Response message </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation </dd></dl>

</div>
</div>
<a id="aa40a55d05b2908287af7f17ea96dd7e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa40a55d05b2908287af7f17ea96dd7e9">&sect;&nbsp;</a></span>getBatchSize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual size_t InferenceEngine::ICNNNetwork::getBatchSize </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the inference batch size. </p>
<dl class="section return"><dt>Returns</dt><dd>The size of batch as a size_t value </dd></dl>

</div>
</div>
<a id="a5add149aee50cbcfecc76901f8d81a89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5add149aee50cbcfecc76901f8d81a89">&sect;&nbsp;</a></span>getData()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a91f97c826d2753815815c119ba383e63">DataPtr</a>&amp; InferenceEngine::ICNNNetwork::getData </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>dname</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns a smart pointer reference to a <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node given its name. If the <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node is missing, returns reference to a default initialized new empty data pointer with given name. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dname</td><td>Name of the <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node smart pointer </dd></dl>

</div>
</div>
<a id="ae952db225b323f5c809ded22c30da4ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae952db225b323f5c809ded22c30da4ed">&sect;&nbsp;</a></span>getInput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classInferenceEngine_1_1InputInfo.html#a607e9d454a48136c3cae731cc5a140d2">InputInfo::Ptr</a> InferenceEngine::ICNNNetwork::getInput </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>inputName</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns information on certain input pointed by inputName. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputName</td><td>Name of input layer to get info on </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A smart pointer to the input information </dd></dl>

</div>
</div>
<a id="ac0d904dcfd039972e04923f1e0befbdd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0d904dcfd039972e04923f1e0befbdd">&sect;&nbsp;</a></span>getInputsInfo()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void InferenceEngine::ICNNNetwork::getInputsInfo </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceInferenceEngine.html#a08270747275eb79985154365aa782a2a">InputsDataMap</a> &amp;&#160;</td>
          <td class="paramname"><em>inputs</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the network input <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node information. The received info is stored in the given InputsDataMap object. For single and multiple inputs networks. This method must be called to find out input names for using them later during filling of a map of blobs passed later to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a9d2f325d953d4f7fea65ae9f3188022b" title="Infers an image(s). Input and output dimensions depend on the topology. As an example for classificat...">InferenceEngine::IInferencePlugin::Infer()</a> </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>Reference to InputsDataMap object. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9661a132ab8eabe950d41ecd53221c0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9661a132ab8eabe950d41ecd53221c0a">&sect;&nbsp;</a></span>getLayerByName()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::getLayerByName </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>layerName</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespaceInferenceEngine.html#af972e334feb2788341e38ac3e6103e60">CNNLayerPtr</a> &amp;&#160;</td>
          <td class="paramname"><em>out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname"><em>resp</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets network layer with the given name. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layerName</td><td>Given name of the layer </td></tr>
    <tr><td class="paramname">out</td><td>Pointer to the found <a class="el" href="classInferenceEngine_1_1CNNLayer.html" title="This is a base abstraction Layer - all DNN Layers inherit from this class. ">CNNLayer</a> object with the given name </td></tr>
    <tr><td class="paramname">resp</td><td>Pointer to the response message that holds a description of an error if any occurred </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation. OK if succeeded </dd></dl>

</div>
</div>
<a id="a85a482ac476c13554b959ebd1efeb312"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85a482ac476c13554b959ebd1efeb312">&sect;&nbsp;</a></span>getName() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void InferenceEngine::ICNNNetwork::getName </td>
          <td>(</td>
          <td class="paramtype">char *&#160;</td>
          <td class="paramname"><em>pName</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>len</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the network name. The name is stored in the given pName string. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">pName</td><td>- will receive actual network name, specified in IR file, pName should point to valid memory address before invoking this function </td></tr>
    <tr><td class="paramname">len</td><td>- size in bytes of pName buffer, actual name is trimmed by this size </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a5cb3d873dd395d2537cbafce612f5a44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5cb3d873dd395d2537cbafce612f5a44">&sect;&nbsp;</a></span>getName() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const std::string&amp; InferenceEngine::ICNNNetwork::getName </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the network name. </p>
<dl class="section return"><dt>Returns</dt><dd>Network name </dd></dl>

</div>
</div>
<a id="a67b659f1a8fd1574bb1939ea3f672fad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67b659f1a8fd1574bb1939ea3f672fad">&sect;&nbsp;</a></span>getOutputsInfo()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void InferenceEngine::ICNNNetwork::getOutputsInfo </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceInferenceEngine.html#a76ce999f68455cf962a473718deb500c">OutputsDataMap</a> &amp;&#160;</td>
          <td class="paramname"><em>out</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the network output <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node information. The received info is stored in the given <a class="el" href="classInferenceEngine_1_1Data.html" title="This class represents the main Data representation node. ">Data</a> node. For single and multiple outputs networks. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">out</td><td>Reference to the OutputsDataMap object </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aca41e0f5e93332cd143192b5b0155a5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca41e0f5e93332cd143192b5b0155a5d">&sect;&nbsp;</a></span>getPrecision()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classInferenceEngine_1_1Precision.html">Precision</a> InferenceEngine::ICNNNetwork::getPrecision </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the main network operating precision. This may be MIXED if not homogeneous. </p>
<dl class="section return"><dt>Returns</dt><dd>A precision type </dd></dl>

</div>
</div>
<a id="a0ac8ac85442ca15673a9e7865a578364"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ac8ac85442ca15673a9e7865a578364">&sect;&nbsp;</a></span>getTargetDevice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796">TargetDevice</a> InferenceEngine::ICNNNetwork::getTargetDevice </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Gets the target device. If <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac1896dd3645734522b8f2b68a40d3f8e" title="Sets a desirable device to perform all work on. Some plug-ins might not support some target devices a...">setTargetDevice()</a> was not called before, returns eDefault. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000053">Deprecated:</a></b></dt><dd>Deprecated since TargetDevice is deprecated </dd></dl>
<dl class="section return"><dt>Returns</dt><dd>A TargetDevice instance </dd></dl>

</div>
</div>
<a id="ab170b0f4b3f85237f6aa97a5844be519"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab170b0f4b3f85237f6aa97a5844be519">&sect;&nbsp;</a></span>layerCount()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual size_t InferenceEngine::ICNNNetwork::layerCount </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the number of layers in the network as an integer value. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of layers as an integer value </dd></dl>

</div>
</div>
<a id="a98affa5884d9884ca12ff347ac5c26e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98affa5884d9884ca12ff347ac5c26e4">&sect;&nbsp;</a></span>reshape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::reshape </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a8bcef7f638f6588a672a32080047ff1d">InputShapes</a> &amp;&#160;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname">&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Run shape inference with new input shapes for the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputShapes</td><td>- map of pairs: name of corresponding data and its dimension. </td></tr>
    <tr><td class="paramname">resp</td><td>Pointer to the response message that holds a description of an error if any occurred </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation </dd></dl>

</div>
</div>
<a id="acd12b5e9b9c6881ce33230a77b3031cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd12b5e9b9c6881ce33230a77b3031cf">&sect;&nbsp;</a></span>serialize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::serialize </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>xmlPath</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>binPath</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname"><em>resp</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Serialize network to IR and weights files. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">xmlPath</td><td>Path to output IR file. </td></tr>
    <tr><td class="paramname">binPath</td><td>Path to output weights file. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation </dd></dl>

</div>
</div>
<a id="abe649d332d99d5c6abda004cfe659ad1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe649d332d99d5c6abda004cfe659ad1">&sect;&nbsp;</a></span>setBatchSize() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::setBatchSize </td>
          <td>(</td>
          <td class="paramtype">const size_t&#160;</td>
          <td class="paramname"><em>size</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Changes the inference batch size. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000054">Deprecated:</a></b></dt><dd>Use <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac29fc798d8a318f380624bd350b28501" title="Changes the inference batch size. ">ICNNNetwork::setBatchSize(size_t, ResponseDesc*)</a> </dd></dl>

</div>
</div>
<a id="ac29fc798d8a318f380624bd350b28501"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac29fc798d8a318f380624bd350b28501">&sect;&nbsp;</a></span>setBatchSize() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="namespaceInferenceEngine.html#a2ce897aa6a353c071958fe379f5d6421">StatusCode</a> InferenceEngine::ICNNNetwork::setBatchSize </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structInferenceEngine_1_1ResponseDesc.html">ResponseDesc</a> *&#160;</td>
          <td class="paramname"><em>responseDesc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Changes the inference batch size. </p>
<dl class="section note"><dt>Note</dt><dd>There are several limitations and it's not recommended to use it. Set batch to the input shape and call <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a98affa5884d9884ca12ff347ac5c26e4" title="Run shape inference with new input shapes for the network. ">ICNNNetwork::reshape</a>. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">size</td><td>Size of batch to set </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Status code of the operation </dd></dl>
<dl class="section note"><dt>Note</dt><dd>: Current implementation of the function sets batch size to the first dimension of all layers in the networks. Before calling it make sure that all your layers have batch in the first dimension, otherwise the method works incorrectly. This limitation is resolved via shape inference feature by using <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a98affa5884d9884ca12ff347ac5c26e4" title="Run shape inference with new input shapes for the network. ">InferenceEngine::ICNNNetwork::reshape</a> method. To read more refer to the Shape Inference section in documentation </dd></dl>

</div>
</div>
<a id="ac1896dd3645734522b8f2b68a40d3f8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1896dd3645734522b8f2b68a40d3f8e">&sect;&nbsp;</a></span>setTargetDevice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void InferenceEngine::ICNNNetwork::setTargetDevice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796">TargetDevice</a>&#160;</td>
          <td class="paramname"><em>device</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets a desirable device to perform all work on. Some plug-ins might not support some target devices and may abort execution with an appropriate error message. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000052">Deprecated:</a></b></dt><dd>Deprecated since TargetDevice is deprecated. Specify target device in <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> directly. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">device</td><td>Device to set as a target </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="ie__icnn__network_8hpp_source.html">ie_icnn_network.hpp</a></li>
</ul>
</div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>