<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting a ONNX* Model - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting a ONNX* Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Introduction to ONNX</h2>
<p><a href="https://github.com/onnx/onnx">ONNX*</a> is a representation format for deep learning models. ONNX allows AI developers easily transfer models between different frameworks that helps to choose the best combination for them. Today, PyTorch*, Caffe2*, Apache MXNet*, Microsoft Cognitive Toolkit* and other tools are developing ONNX support.</p>
<h2>Supported Public ONNX Topologies</h2>
<table class="doxtable">
<tr>
<th align="left">Model Name </th><th align="left">Path to <a href="https://github.com/onnx/models">Public Models</a> master branch  </th></tr>
<tr>
<td align="left">bvlc_alexnet </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/bvlc_alexnet.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">bvlc_googlenet </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/bvlc_googlenet.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">bvlc_reference_caffenet </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/bvlc_reference_caffenet.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">bvlc_reference_rcnn_ilsvrc13 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/bvlc_reference_rcnn_ilsvrc13.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">inception_v1 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/inception_v1.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">inception_v2 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/inception_v2.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">resnet50 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/resnet50.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">squeezenet </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/squeezenet.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">densenet121 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/densenet121.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">emotion_ferplus </td><td align="left"><a href="https://www.cntk.ai/OnnxModels/emotion_ferplus/opset_2/emotion_ferplus.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">mnist </td><td align="left"><a href="https://www.cntk.ai/OnnxModels/mnist/opset_1/mnist.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">shufflenet </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/shufflenet.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">VGG19 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/vgg19.tar.gz">model archive</a> </td></tr>
<tr>
<td align="left">zfnet512 </td><td align="left"><a href="https://s3.amazonaws.com/download.onnx/models/opset_8/zfnet512.tar.gz">model archive</a> </td></tr>
</table>
<p>Listed models are built with operation set version 8. Models that are upgraded to higher operation set versions may not be supported.</p>
<h2>Supported Pytorch* Models via ONNX Conversion</h2>
<p>Starting from the R4 release, the OpenVINO™ toolkit officially supports public Pytorch* models (from <code>torchvision</code> 0.2.1 and <code>pretrainedmodels</code> 0.7.4 packages) via ONNX conversion. The list of supported topologies is presented below:</p>
<table class="doxtable">
<tr>
<th align="left">Package Name</th><th align="left">Supported Models  </th></tr>
<tr>
<td align="left"><a href="https://pytorch.org/docs/stable/torchvision/index.html">Torchvision Models</a> </td><td align="left">alexnet, densenet121, densenet161, densenet169, densenet201, resnet101, resnet152, resnet18, resnet34, resnet50, vgg11, vgg13, vgg16, vgg19 </td></tr>
<tr>
<td align="left"><a href="https://github.com/Cadene/pretrained-models.pytorch">Pretrained Models</a> </td><td align="left">alexnet, fbresnet152, resnet101, resnet152, resnet18, resnet34, resnet152, resnet18, resnet34, resnet50, resnext101_32x4d, resnext101_64x4d, vgg11 </td></tr>
</table>
<p>| <a href="https://github.com/sacmehta/ESPNet/tree/master/pretrained">ESPNet Models</a> |</p>
<h2>Supported PaddlePaddle* Models via ONNX Conversion</h2>
<p>Starting from the R5 release, the OpenVINO™ toolkit officially supports public PaddlePaddle* models via ONNX conversion. The list of supported topologies downloadable from PaddleHub is presented below:</p>
<table class="doxtable">
<tr>
<th align="left">Model Name </th><th align="left">Command to download the model from PaddleHub  </th></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=mobilenet_v2_imagenet">MobileNetV2</a> </td><td align="left"><code>hub install mobilenet_v2_imagenet==1.0.1</code> </td></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=resnet_v2_18_imagenet">ResNet18</a> </td><td align="left"><code>hub install resnet_v2_18_imagenet==1.0.0</code> </td></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=resnet_v2_34_imagenet">ResNet34</a> </td><td align="left"><code>hub install resnet_v2_34_imagenet==1.0.0</code> </td></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=resnet_v2_50_imagenet">ResNet50</a> </td><td align="left"><code>hub install resnet_v2_50_imagenet==1.0.1</code> </td></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=resnet_v2_101_imagenet">ResNet101</a> </td><td align="left"><code>hub install resnet_v2_101_imagenet==1.0.1</code> </td></tr>
<tr>
<td align="left"><a href="https://www.paddlepaddle.org.cn/hubdetail?name=resnet_v2_152_imagenet">ResNet152</a> </td><td align="left"><code>hub install resnet_v2_152_imagenet==1.0.1</code> </td></tr>
</table>
<blockquote class="doxtable">
<p><b>NOTE</b>: To convert a model downloaded from PaddleHub use <a href="https://github.com/PaddlePaddle/paddle2onnx">paddle2onnx</a> converter. </p>
</blockquote>
<p>The list of supported topologies from the <a href="https://github.com/PaddlePaddle/models/tree/release/1.5">models v1.5</a> package:</p><ul>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/mobilenet.py">MobileNetV1</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/mobilenet_v2.py">MobileNetV2</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/resnet.py">ResNet</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/resnet_vc.py">ResNet_vc</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/resnet_vd.py">ResNet_vd</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/resnext.py">ResNeXt</a></li>
<li><a href="https://github.com/PaddlePaddle/models/blob/release/1.5/PaddleCV/image_classification/models/resnext_vd.py">ResNeXt_vd</a></li>
</ul>
<blockquote class="doxtable">
<p><b>NOTE</b>: To convert these topologies one should first serialize the model by calling <code>paddle.fluid.io.save_inference_model</code> </p>
</blockquote>
<p>(<a href="https://www.paddlepaddle.org.cn/documentation/docs/en/1.3/api/io.html#save-inference-model">description</a>) command and after that use <a href="https://github.com/PaddlePaddle/paddle2onnx">paddle2onnx</a> converter.</p>
<h2>Convert an ONNX* Model <a class="anchor" id="Convert_From_ONNX"></a></h2>
<p>The Model Optimizer process assumes you have an ONNX model that was directly downloaded from a public repository or converted from any framework that supports exporting to the ONNX format.</p>
<p>To convert an ONNX* model:</p>
<ol type="1">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory.</li>
<li>Use the <code>mo.py</code> script to simply convert a model with the path to the input model <code>.nnet</code> file: <div class="fragment"><div class="line">python3 mo.py --input_model &lt;INPUT_MODEL&gt;.onnx</div></div><!-- fragment --></li>
</ol>
<p>There are no ONNX* specific parameters, so only <a class="el" href="_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">framework-agnostic parameters</a> are available to convert your model.</p>
<h2>Supported ONNX* Layers</h2>
<p>Refer to <a class="el" href="_docs_MO_DG_prepare_model_Supported_Frameworks_Layers.html">Supported Framework Layers</a> for the list of supported standard layers. </p>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>