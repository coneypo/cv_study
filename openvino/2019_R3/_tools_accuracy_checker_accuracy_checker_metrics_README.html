<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Metrics - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Metrics </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>For correct work metrics require specific representation format. (e. g. map expects detection annotation and detection prediction for evaluation).</p>
<p>In case when you use complicated representation located in representation container, you need to add options <code>annotation_source</code> and <code>prediction_source</code> in configuration file to select specific representation, another way metric calculation possible only if container has only one suitable representation and will be resolved automatically. <code>annotation_source</code> and <code>prediction_source</code> should contain only one annotation identifier and output layer name respectively. You may optionally provide <code>reference</code> field for metric, if you want calculated metric tested against specific value (i.e. reported in canonical paper) and acceptable <code>threshold</code> for metric deviation from reference value.</p>
<p>Every metric has parameters available for configuration.</p>
<p>Accuracy Checker supports following set of metrics:</p>
<ul>
<li><code>accuracy</code> - classification accuracy metric, defined as the number of correct predictions divided by the total number of predictions. Supported representation: <code>ClassificationAnnotation</code>, <code>ClassificationPrediction</code><ul>
<li><code>top_k</code> - the number of classes with the highest probability, which will be used to decide if prediction is correct.</li>
</ul>
</li>
<li><code>accuracy_per_class</code> - classification accuracy metric which represents results for each class. Supported representation: <code>ClassificationAnnotation</code>, <code>ClassificationPrediction</code>.<ul>
<li><code>top_k</code> - the number of classes with the highest probability, which will be used to decide if prediction is correct.</li>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
</ul>
</li>
<li><code>character_recognition_accuracy</code> - accuracy metric for character recognition task. Supported representation: <code>CharacterRecognitionAnnotation</code>, <code>CharacterRecognitionPrediction</code>.</li>
<li><code>map</code> - mean average precision. Supported representations: <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>overlap_threshold</code> - minimal value for intersection over union that allows to make decision that prediction bounding box is true positive.</li>
<li><code>overlap_method</code> - method for calculation bbox overlap. You can choose between intersection over union (<code>iou</code>), defined as area of intersection divided by union of annotation and prediction boxes areas, and intersection over area (<code>ioa</code>), defined as area of intersection divided by ara of prediction box.</li>
<li><code>include_boundaries</code> - allows include boundaries in overlap calculation process. If it is True then width and height of box is calculated by max - min + 1.</li>
<li><code>ignore_difficult</code> - allows to ignore difficult annotation boxes in metric calculation. In this case, difficult boxes are filtered annotations from postprocessing stage.</li>
<li><code>distinct_conf</code> - select only values for distinct confidences.</li>
<li><code>allow_multiple_matches_per_ignored</code> - allows multiple matches per ignored.</li>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>integral</code> - integral type for average precision calculation. Pascal VOC <code>11point</code> and <code>max</code> approaches are available.</li>
</ul>
</li>
<li><code>miss_rate</code> - miss rate metric of detection models. Supported representations: <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>overlap_threshold</code> - minimal value for intersection over union that allows to make decision that prediction bounding box is true positive.</li>
<li><code>overlap_method</code> - method for calculation bbox overlap. You can choose between intersection over union (<code>iou</code>), defined as area of intersection divided by union of annotation and prediction boxes areas, and intersection over area (<code>ioa</code>), defined as area of intersection divided by ara of prediction box.</li>
<li><code>include_boundaries</code> - allows include boundaries in overlap calculation process. If it is True then width and height of box is calculated by max - min + 1.</li>
<li><code>ignore_difficult</code> - allows to ignore difficult annotation boxes in metric calculation. In this case, difficult boxes are filtered annotations from postprocessing stage.</li>
<li><code>distinct_conf</code> - select only values for distinct confidences.</li>
<li><code>allow_multiple_matches_per_ignored</code> - allows multiple matches per ignored.</li>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>fppi_level</code> - false positive per image level.</li>
</ul>
</li>
<li><code>recall</code> - recall metric of detection models. Supported representations: <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>overlap_threshold</code> - minimal value for intersection over union that allows to make decision that prediction bounding box is true positive.</li>
<li><code>overlap_method</code> - method for calculation bbox overlap. You can choose between intersection over union (<code>iou</code>), defined as area of intersection divided by union of annotation and prediction boxes areas, and intersection over area (<code>ioa</code>), defined as area of intersection divided by ara of prediction box.</li>
<li><code>include_boundaries</code> - allows include boundaries in overlap calculation process. If it is True then width and height of box is calculated by max - min + 1.</li>
<li><code>ignore_difficult</code> - allows to ignore difficult annotation boxes in metric calculation. In this case, difficult boxes are filtered annotations from postprocessing stage.</li>
<li><code>distinct_conf</code> - select only values for distinct confidences.</li>
<li><code>allow_multiple_matches_per_ignored</code> - allows multiple matches per ignored.</li>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
</ul>
</li>
<li><code>detection_accuracy</code> - accuracy for detection models. Supported representations: <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>overlap_threshold</code> - minimal value for intersection over union that allows to make decision that prediction bounding box is true positive.</li>
<li><code>overlap_method</code> - method for calculation bbox overlap. You can choose between intersection over union (<code>iou</code>), defined as area of intersection divided by union of annotation and prediction boxes areas, and intersection over area (<code>ioa</code>), defined as area of intersection divided by ara of prediction box.</li>
<li><code>include_boundaries</code> - allows include boundaries in overlap calculation process. If it is True then width and height of box is calculated by max - min + 1.</li>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>use_normalization</code> - allows to normalize confusion_matrix for metric calculation.</li>
</ul>
</li>
<li><code>segmentation_accuracy</code> - pixel accuracy for semantic segmentation models. Supported representations: <code>SegmentationAnnotation</code>, <code>SegmentationPrediction</code>.<ul>
<li><code>use_argmax</code> - allows to use argmax for prediction mask.</li>
</ul>
</li>
<li><code>mean_iou</code> - mean intersection over union for semantic segmentation models. Supported representations: <code>SegmentationAnnotation</code>, <code>SegmentationPrediction</code>.<ul>
<li><code>use_argmax</code> - allows to use argmax for prediction mask.</li>
</ul>
</li>
<li><code>mean_accuracy</code> - mean accuracy for semantic segmentation models. Supported representations: <code>SegmentationAnnotation</code>, <code>SegmentationPrediction</code>.<ul>
<li><code>use_argmax</code> - allows to use argmax for prediction mask.</li>
</ul>
</li>
<li><code>frequency_weighted_accuracy</code> - frequency weighted accuracy for semantic segmentation models. Supported representations: <code>SegmentationAnnotation</code>, <code>SegmentationPrediction</code>.<ul>
<li><code>use_argmax</code> - allows to use argmax for prediction mask. More detailed information about calculation segmentation metrics you can find <a href="https://arxiv.org/pdf/1411.4038v2.pdf">here</a>.</li>
</ul>
</li>
<li><code>cmc</code> - Cumulative Matching Characteristics (CMC) score. Supported representations: <code>ReIdentificationAnnotation</code>, <code>ReIdentificationPrediction</code>.<ul>
<li><code>top_k</code> - number of k highest ranked samples to consider when matching.</li>
<li><code>separate_camera_set</code> - should identities from the same camera view be filtered out.</li>
<li><code>single_gallery_shot</code> - each identity has only one instance in the gallery.</li>
<li><code>number_single_shot_repeats</code> - number of repeats for single_gallery_shot setting (required for CUHK).</li>
<li><code>first_match_break</code> - break on first matched gallery sample.</li>
</ul>
</li>
<li><code>reid_map</code> - Mean Average Precision score for object reidentification. Supported representations: <code>ReIdentificationAnnotation</code>, <code>ReIdentificationPrediction</code>.<ul>
<li><code>uninterpolated_auc</code> - should area under precision recall curve be computed using trapezoidal rule or directly.</li>
</ul>
</li>
<li><code>pairwise_accuracy</code> - pairwise accuracy for object reidentification. Supported representations: <code>ReIdentificationClassificationAnnotation</code>, <code>ReIdentificationPrediction</code>.<ul>
<li><code>min_score</code> - min score for determining that objects are different. You can provide value or use <code>train_median</code> value which will be calculated if annotations has training subset.</li>
</ul>
</li>
<li><code>pairwise_accuracy_subsets</code> - object reidentification pairwise accuracy with division dataset on test and train subsets for calculation mean score. Supported representations: <code>ReIdentificationClassificationAnnotation</code>, <code>ReIdentificationPrediction</code>.<ul>
<li><code>subset_number</code> - number of subsets for separating.</li>
</ul>
</li>
<li><code>mae</code> - <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">Mean Absolute Error</a>. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.</li>
<li><code>mae_on_intervals</code> - Mean Absolute Error estimated magnitude for specific value range. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.<ul>
<li><code>intervals</code> - comma-separated list of interval boundaries.</li>
<li><code>ignore_values_not_in_interval</code> - allows create additional intervals for values less than minimal value in interval and greater than maximal.</li>
<li><code>start</code> , <code>step</code>, <code>end</code> - way to generate range of intervals from <code>start</code> to <code>end</code> with length <code>step</code>.</li>
</ul>
</li>
<li><code>mse</code> - <a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a>. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.</li>
<li><code>mse_on_intervals</code> - Mean Squared Error estimated magnitude for specific value range. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.<ul>
<li><code>intervals</code> - comma-separated list of interval boundaries.</li>
<li><code>ignore_values_not_in_interval</code> - allows create additional intervals for values less than minimal value in interval and greater than maximal.</li>
<li><code>start</code>, <code>step</code>, <code>end</code> - generate range of intervals from <code>start</code> to <code>end</code> with length <code>step</code>.</li>
</ul>
</li>
<li><code>rmse</code> - <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">Root Mean Squared Error</a>. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.</li>
<li><code>rmse_on_intervals</code> - Root Mean Squared Error estimated magnitude for specific value range. Supported representations: <code>RegressionAnnotation</code>, <code>RegressionPrediction</code>.<ul>
<li><code>intervals</code> - comma-separated list of interval boundaries.</li>
<li><code>ignore_values_not_in_interval</code> - allows create additional intervals for values less than minimal value in interval and greater than maximal.</li>
<li><code>start</code>, <code>step</code>, <code>end</code> - generate range of intervals from <code>start</code> to <code>end</code> with length <code>step</code>.</li>
</ul>
</li>
<li><code>per_point_normed_error</code> - Normed Error for measurement the quality of landmarks' positions. Estimated results for each point independently. Supported representations: <code>FacialLandmarksAnnotation</code>, <code>FacialLandmarksPrediction</code>.</li>
<li><code>normed_error</code> - Normed Error for measurement the quality of landmarks' positions. Supported representations: <code>FacialLandmarksAnnotation</code>, <code>FacialLandmarksPrediction</code>.<ul>
<li><code>calculate_std</code> - allows calculation of standard deviation (default value: <code>False</code>)</li>
<li><code>percentile</code> - calculate error rate for given percentile.</li>
</ul>
</li>
<li><code>psnr</code> - <a href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio">Peak signal to noise ratio</a>. Supported representations: <code>SuperResolutionAnnotation</code>, <code>SuperResolutionPrediction</code>.<ul>
<li><code>color_order</code> - the field specified which color order <code>BGR</code> or <code>RGB</code> will be used during metric calculation (Optional. Default value is RGB).</li>
</ul>
</li>
<li><code>angle_error</code> - Mean angle error and Standard deviation of angle error for gaze estimation. Supported representations: <code>GazeVectorAnnotation</code>, <code>GazeVectorPrediction</code>.</li>
<li><code>multi_accuracy</code> - accuracy for multilabel recognition task. Supported representations: <code>MultiLabelRecognitionAnnotation</code>, <code>MultiLabelRecognitionPrediction</code>.<ul>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>calculate_average</code> - allows calculation of average accuracy (default value: <code>True</code>).</li>
</ul>
</li>
<li><code>multi_precision</code> - precision metric for multilabel recognition. Supported representations: <code>MultiLabelRecognitionAnnotation</code>, <code>MultiLabelRecognitionPrediction</code>.<ul>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>calculate_average</code> - allows calculation of average precision (default value: <code>True</code>).</li>
</ul>
</li>
<li><code>multi_recall</code> - recall metric for multilabel recognition. Supported representations: <code>MultiLabelRecognitionAnnotation</code>, <code>MultiLabelRecognitionPrediction</code>.<ul>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>calculate_average</code> - allows calculation of average recall (default value: <code>True</code>).</li>
</ul>
</li>
<li><code>f1_score</code> - <a href="https://en.wikipedia.org/wiki/F1_score">F score</a> metric for multilabel recognition. Supported representations: <code>MultiLabelRecognitionAnnotation</code>, <code>MultiLabelRecognitionPrediction</code>.<ul>
<li><code>label_map</code> - the field in annotation metadata, which contains dataset label map.</li>
<li><code>calculate_average</code> - allows calculation of average f-score (default value: <code>True</code>).</li>
</ul>
</li>
<li><code>focused_text_hmean</code> - Harmonic mean of precision and recall for focused scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=2&amp;com=introduction">Robust Reading Competition challenge 2</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>area_recall_constrain</code> - minimal value for recall that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>center_diff_threshold</code> - acceptable difference between center of predicted text region and ground truth.</li>
<li><code>one_to_one_match_score</code> - weight for one to one matching results (Optional, default 1).</li>
<li><code>one_to_many_match_score</code> - weight for one to many matching results (Optional, default 0.8).</li>
<li><code>many_to_one_match_score</code> - weight for many to one matching results (optional, default 1).</li>
</ul>
</li>
<li><code>focused_text_precision</code> - precision for focused scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=2&amp;com=introduction">Robust Reading Competition challenge 2</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>area_recall_constrain</code> - minimal value for recall that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>center_diff_threshold</code> - acceptable difference between center of predicted text region and ground truth.</li>
<li><code>one_to_one_match_score</code> - weight for one to one matching results (Optional, default 1).</li>
<li><code>one_to_many_match_score</code> - weight for one to many matching results (Optional, default 0.8).</li>
<li><code>many_to_one_match_score</code> - weight for many to one matching results (optional, default 1).</li>
</ul>
</li>
<li><code>focused_text_precision</code> - recall for focused scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=2&amp;com=introduction">Robust Reading Competition challenge 2</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>area_recall_constrain</code> - minimal value for recall that allows to make decision that prediction polygon matched with annotation.</li>
<li><code>center_diff_threshold</code> - acceptable difference between center of predicted text region and ground truth.</li>
<li><code>one_to_one_match_score</code> - weight for one to one matching results (Optional, default 1).</li>
<li><code>one_to_many_match_score</code> - weight for one to many matching results (Optional, default 0.8).</li>
<li><code>many_to_one_match_score</code> - weight for many to one matching results (optional, default 1).</li>
</ul>
</li>
<li><code>incidental_text_hmean</code> - Harmonic mean of precision and recall for incidental scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=4&amp;com=introduction">Robust Reading Competition challenge 4</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>iou_constrain</code> - minimal value for intersection over union that allows to make decision that prediction polygon is true positive.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with ignored annotation.</li>
</ul>
</li>
<li><code>incidental_text_precision</code> - precision for incidental scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=4&amp;com=introduction">Robust Reading Competition challenge 4</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>iou_constrain</code> - minimal value for intersection over union that allows to make decision that prediction polygon is true positive.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with ignored annotation.</li>
</ul>
</li>
<li><code>incidental_text_precision</code> - recall for incidental scene text detection task introduced in <a href="https://rrc.cvc.uab.es/?ch=4&amp;com=introduction">Robust Reading Competition challenge 4</a>. Supported representations: <code>TextDetectionAnnotation</code>, <code>TextDetectionPrediction</code>.<ul>
<li><code>ignore_difficult</code> - allows to ignore difficult ground truth text polygons in metric calculation.</li>
<li><code>iou_constrain</code> - minimal value for intersection over union that allows to make decision that prediction polygon is true positive.</li>
<li><code>area_precision_constrain</code> - minimal value for precision that allows to make decision that prediction polygon matched with ignored annotation.</li>
</ul>
</li>
<li><code>coco_precision</code> - MS COCO Average Precision metric for keypoints recognition and object detection tasks. Supported representations: <code>PoseEstimationAnnotation</code>, <code>PoseEstimationPrediction</code>, <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>max_detections</code> - max number of predicted results per image. If you have more predictions,the results with minimal confidence will be ignored.</li>
<li><code>threshold</code> - intersection over union threshold. You can specify one value or comma separated range of values. This parameter supports precomputed values for standard COCO thresholds (<code>.5</code>, <code>.75</code>, <code>.5:.05:.95</code>).</li>
</ul>
</li>
<li><code>coco_recall</code> - MS COCO Average Recall metric for keypoints recognition and object detection tasks. Supported representations: <code>PoseEstimationAnnotation</code>, <code>PoseEstimationPrediction</code>, <code>DetectionAnnotation</code>, <code>DetectionPrediction</code>.<ul>
<li><code>max_detections</code> - max number of predicted results per image. If you have more predictions,the results with minimal confidence will be ignored.</li>
<li><code>threshold</code> - intersection over union threshold. You can specify one value or comma separated range of values. This parameter supports precomputed values for standard COCO thresholds (<code>.5</code>, <code>.75</code>, <code>.5:.05:.95</code>).</li>
</ul>
</li>
<li><code>hit_ratio</code> - metric for recommendation system evaluation. Supported representations: <code>HitRatioAnnotation</code>, <code>HitRatioPrediction</code>.<ul>
<li><code>top_k</code> - definition of number elements in rank list (optional, default 10).</li>
</ul>
</li>
<li><code>ndcg</code> - <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">Normalized Discounted Cumulative Gain</a>. Supported representations: <code>HitRatioAnnotation</code>, <code>HitRatioPrediction</code>.<ul>
<li><code>top_k</code> - definition of number elements in rank list (optional, default 10).</li>
</ul>
</li>
<li><code>dice</code> - <a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">Sørensen–Dice coefficient</a>. Supported representations: <code>BrainTumorSegmentationAnnotation, BrainTumorSegmentationPrediction</code>.</li>
<li><code>dice_index</code> - <a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">Sørensen–Dice coefficient</a>. Supported representations: <code>BrainTumorSegmentationAnnotation, BrainTumorSegmentationPrediction</code>, <code>SegmentationAnnotation, SegmentationPrediction</code>. Supports result representation for multiple classes. Metric represents result for each class if <code>label_map</code> for used dataset is provided, otherwise it represents overall result. For <code>brats_numpy</code> converter file with labels set in <code>labels_file</code> tag.<ul>
<li><code>mean</code> - allows calculation mean value (default - <code>True</code>).</li>
<li><code>median</code> - allows calculation median value (default - <code>False</code>).</li>
<li><code>use_argmax</code> - allows to use argmax for prediction mask (default - <code>True</code>).</li>
</ul>
</li>
<li><code>bleu</code> - <a href="https://en.wikipedia.org/wiki/BLEU">Bilingual Evaluation Understudy</a>. Supperted representations: <code>MachineTranslationAnnotation</code>, <code>MachineTranslationPrediction</code>.<ul>
<li><code>smooth</code> - Whether or not to apply Lin et al. 2004 smoothing.</li>
<li><code>max_order</code> - Maximum n-gram order to use when computing BLEU score. (Optional, default 4). </li>
</ul>
</li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>