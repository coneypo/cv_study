<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting YOLO* Models to the Intermediate Representation (IR) - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting YOLO* Models to the Intermediate Representation (IR) </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This tutorial explains how to convert real-time object detection YOLOv1*, YOLOv2*, and YOLOv3* public models to the Intermediate Representation (IR). All YOLO* models are originally implemented in the DarkNet* framework and consist of two files:</p><ul>
<li><code>.cfg</code> file with model configurations</li>
<li><code>.weights</code> file with model weights</li>
</ul>
<p>Depending on a YOLO model version, the Model Optimizer converts it differently:</p>
<ul>
<li>YOLOv3 has several implementations. This tutorial uses a TensorFlow implementation of YOLOv3 model, which can be directly converted to the IR.</li>
<li>YOLOv1 and YOLOv2 models must be first converted to TensorFlow* using DarkFlow*.</li>
</ul>
<h2><a class="anchor" id="yolov3-to-ir"></a>Convert YOLOv3 Model to IR</h2>
<p>On GitHub*, you can find several public versions of TensorFlow YOLOv3 model implementation. This tutorial explains how to convert YOLOv3 model from the <a href="https://github.com/mystic123/tensorflow-yolo-v3">https://github.com/mystic123/tensorflow-yolo-v3</a> repository (commit ed60b90) to IR , but the process is similar for other versions of TensorFlow YOLOv3 model.</p>
<h3><a class="anchor" id="yolov3-overview"></a>Overview of YOLOv3 Model Architecture</h3>
<p>Originally, YOLOv3 model includes feature extractor called <code>Darknet-53</code> with three branches at the end that make detections at three different scales. These branches must end with the YOLO <code>Region</code> layer.</p>
<p><code>Region</code> layer was first introduced in the DarkNet framework. Other frameworks, including TensorFlow, do not have the <code>Region</code> implemented as a single layer, so every author of public YOLOv3 model creates it using simple layers. This badly affects performance. For this reason, the main idea of YOLOv3 model conversion to IR is to cut off these custom <code>Region</code>-like parts of the model and complete the model with the <code>Region</code> layers where required.</p>
<h3>Dump YOLOv3 TensorFlow* Model</h3>
<p>To dump TensorFlow model out of <a href="https://github.com/mystic123/tensorflow-yolo-v3">https://github.com/mystic123/tensorflow-yolo-v3</a> GitHub repository (commit ed60b90), follow the instructions below:</p>
<ol type="1">
<li>Clone the repository:<br />
 <div class="fragment"><div class="line">git clone https://github.com/mystic123/tensorflow-yolo-v3.git</div><div class="line">cd tensorflow-yolo-v3</div></div><!-- fragment --></li>
<li>(Optional) Checkout to the commit that the conversion was tested on:<br />
 <div class="fragment"><div class="line">git checkout ed60b90</div></div><!-- fragment --></li>
<li>Download <a href="https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names">coco.names</a> file from the DarkNet website <b>OR</b> use labels that fit your task.</li>
<li>Download the <a href="https://pjreddie.com/media/files/yolov3.weights">yolov3.weights</a> (for the YOLOv3 model) or <a href="https://pjreddie.com/media/files/yolov3-tiny.weights">yolov3-tiny.weights</a> (for the YOLOv3-tiny model) file <b>OR</b> use your pretrained weights with the same structure</li>
<li>Run a converter:</li>
</ol>
<ul>
<li>for YOLO-v3: <div class="fragment"><div class="line">python3 convert_weights_pb.py --class_names coco.names --data_format NHWC --weights_file yolov3.weights</div></div><!-- fragment --></li>
<li>for YOLOv3-tiny: <div class="fragment"><div class="line">python3 convert_weights_pb.py --class_names coco.names --data_format NHWC --weights_file yolov3-tiny.weights --tiny</div></div><!-- fragment --></li>
</ul>
<p>If you have YOLOv3 weights trained for an input image with the size different from 416 (320, 608 or your own), please provide the <code>--size</code> key with the size of your image specified while running the converter. For example, run the following command for an image with size 608: </p><div class="fragment"><div class="line">python3 convert_weights_pb.py --class_names coco.names --data_format NHWC --weights_file yolov3_608.weights --size 608</div></div><!-- fragment --><h3>Convert YOLOv3 TensorFlow Model to the IR</h3>
<p>To solve the problems explained in the <a href="#yolov3-overview">YOLOv3 architecture overview</a> section, use the <code>yolo_v3.json</code> or <code>yolo_v3_tiny.json</code> (depending on a model) configuration file with custom operations located in the <code>&lt;OPENVINO_INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf</code> repository.</p>
<p>It consists of several attributes:<br />
 </p><div class="fragment"><div class="line">[</div><div class="line">  {</div><div class="line">    &quot;id&quot;: &quot;TFYOLOV3&quot;,</div><div class="line">    &quot;match_kind&quot;: &quot;general&quot;,</div><div class="line">    &quot;custom_attributes&quot;: {</div><div class="line">      &quot;classes&quot;: 80,</div><div class="line">      &quot;coords&quot;: 4,</div><div class="line">      &quot;num&quot;: 9,</div><div class="line">      &quot;mask&quot;: [0, 1, 2],</div><div class="line">      &quot;entry_points&quot;: [&quot;detector/yolo-v3/Reshape&quot;, &quot;detector/yolo-v3/Reshape_4&quot;, &quot;detector/yolo-v3/Reshape_8&quot;]</div><div class="line">    }</div><div class="line">  }</div><div class="line">]</div></div><!-- fragment --><p> where:</p><ul>
<li><code>id</code> and <code>match_kind</code> are parameters that you cannot change.</li>
<li><code>custom_attributes</code> is a parameter that stores all the YOLOv3 specific attributes:<ul>
<li><code>classes</code>, <code>coords</code>, <code>num</code>, and <code>mask</code> are attributes that you should copy from the configuration file file that was used for model training. If you used DarkNet officially shared weights, you can use <code>yolov3.cfg</code> or <code>yolov3-tiny.cfg</code> configuration file from <a href="https://github.com/pjreddie/darknet/tree/master/cfg">https://github.com/pjreddie/darknet/tree/master/cfg</a>. Replace the default values in <code>custom_attributes</code> with the parameters that follow the <code>[yolo]</code> title in the configuration file.</li>
<li><code>entry_points</code></li>
</ul>
</li>
</ul>
<p>To generate the IR of the YOLOv3 TensorFlow model, run:<br />
 </p><div class="fragment"><div class="line">python3 mo_tf.py</div><div class="line">--input_model /path/to/yolo_v3.pb</div><div class="line">--tensorflow_use_custom_operations_config $MO_ROOT/extensions/front/tf/yolo_v3.json</div><div class="line">--batch 1</div></div><!-- fragment --><p>To generate the IR of the YOLOv3-tiny TensorFlow model, run:<br />
 </p><div class="fragment"><div class="line">python3 mo_tf.py</div><div class="line">--input_model /path/to/yolo_v3_tiny.pb</div><div class="line">--tensorflow_use_custom_operations_config $MO_ROOT/extensions/front/tf/yolo_v3_tiny.json</div><div class="line">--batch 1</div></div><!-- fragment --><p>where:</p>
<ul>
<li><code>--batch</code> defines shape of model input. In the example, <code>--batch</code> is equal to 1, but you can also specify other integers larger than 1.</li>
<li><code>--tensorflow_use_custom_operations_config</code> adds missing <code>Region</code> layers to the model. In the IR, the <code>Region</code> layer is named as <code>RegionYolo</code>.</li>
</ul>
<p>OpenVINO&trade; toolkit provides a demo that uses YOLOv3 model. For more information, refer to <a class="el" href="_demos_object_detection_demo_yolov3_async_README.html">Object Detection YOLO* V3 Demo, Async API Performance Showcase</a>.</p>
<h2>Convert YOLOv1 and YOLOv2 Models to the IR</h2>
<p>Before converting Choose a YOLOv1 or YOLOv2 model version that best suits your task. Download model configuration file and corresponding weight file:</p><ul>
<li>from <a href="https://github.com/thtrieu/darkflow">DarkFlow repository</a>: configuration files are stored in the <code>cfg</code> directory, links to weight files are given in the <code>README.md</code> file. The files from this repository are adatped for conversion to TensorFlow using DarkFlow.</li>
<li>from DarkNet website and repository: configuration files are stored in the <code>cfg</code> directory of the <a href="https://github.com/pjreddie/darknet">repository</a>, links to weight files are given on the <a href="https://pjreddie.com/darknet/yolov1/">YOLOv1</a> and <a href="https://pjreddie.com/darknet/yolov2/">YOLOv2</a> websites.</li>
</ul>
<p>To convert DarkNet YOLOv1 and YOLOv2 models to IR, follow the next stepsg:</p>
<ol type="1">
<li><a href="#install-darkflow">Install DarkFlow </a></li>
<li><a href="#yolov1-v2-to-tf">Convert DarkNet YOLOv1 or YOLOv2 model to TensorFlow</a> using DarkFlow</li>
<li><a href="#yolov1-v2-to-ir">Convert TensorFlow YOLOv1 or YOLOv2 model to IR</a></li>
</ol>
<h4><a class="anchor" id="install-darkflow"></a>Install DarkFlow*</h4>
<p>You need DarkFlow to convert YOLOv1 and YOLOv2 models to TensorFlow. To install DarkFlow:</p><ol type="1">
<li>Install DarkFlow <a href="https://github.com/thtrieu/darkflow#dependencies">required dependencies</a>.</li>
<li>Clone DarkFlow git repository:<br />
 <div class="fragment"><div class="line">git clone https://github.com/thtrieu/darkflow.git</div></div><!-- fragment --></li>
<li>Go to the root directory of the cloned repository:<br />
 <div class="fragment"><div class="line">cd darkflow</div></div><!-- fragment --></li>
<li>Install DarkFlow using the instructions from the <code>README.md</code> file in the <a href="https://github.com/thtrieu/darkflow/blob/master/README.md#getting-started">DarkFlow repository</a>.</li>
</ol>
<h4><a class="anchor" id="yolov1-v2-to-tf"></a>Convert DarkNet* YOLOv1 or YOLOv2 Model to TensorFlow*</h4>
<p>To convert YOLOv1 or YOLOv2 model to TensorFlow, go to the root directory of the cloned DarkFlow repository and run the following command:<br />
 </p><div class="fragment"><div class="line">python3 ./flow --model &lt;path_to_model&gt;/&lt;model_name&gt;.cfg --load &lt;path_to_model&gt;/&lt;model_name&gt;.weights --savepb</div></div><!-- fragment --><p>If the model was successfully converted, you can find the <code>&lt;model_name&gt;.meta</code> and <code>&lt;model_name&gt;.pb</code> files in <code>built_graph</code> subdirectory of the cloned DarkFlow repository.</p>
<p>File <code>&lt;model_name&gt;.pb</code> is a TensorFlow representation of the YOLO model.</p>
<h4><a class="anchor" id="yolov1-v2-to-ir"></a>Convert TensorFlow YOLOv1 or YOLOv2 Model to the IR</h4>
<p>Converted TensorFlow YOLO model is missing <code>Region</code> layer and its parameters. Original YOLO <code>Region</code> layer parameters are stored in the configuration <code>&lt;path_to_model&gt;/&lt;model_name&gt;.cfg</code> file under the <code>[region]</code> title.</p>
<p>To recreate the original model structure, use the corresponding yolo <code>.json</code> configuration file with custom operations and <code>Region</code> layer parameters when converting the model to the IR. This file is located in the <code>&lt;OPENVINO_INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf</code> directory.</p>
<p>If chosen model has specific values of this parameters, create another configuration file with custom operations and use it for conversion.</p>
<p>To generate the IR of the YOLOv1 model, provide TensorFlow YOLOv1 or YOLOv2 model to the Model Optimizer with the following parameters:<br />
 </p><div class="fragment"><div class="line">python3 ./mo_tf.py</div><div class="line">--input_model &lt;path_to_model&gt;/&lt;model_name&gt;.pb       \</div><div class="line">--batch 1                                       \</div><div class="line">--tensorflow_use_custom_operations_config &lt;OPENVINO_INSTALL_DIR&gt;/deployment_tools/model_optimizer/extensions/front/tf/&lt;yolo_config&gt;.json</div></div><!-- fragment --><p> where:</p>
<ul>
<li><code>--batch</code> defines shape of model input. In the example, <code>--batch</code> is equal to 1, but you can also specify other integers larger than 1.</li>
<li><code>--tensorflow_use_custom_operations_config</code> adds missing <code>Region</code> layers to the model. In the IR, the <code>Region</code> layer is named as <code>RegionYolo</code>. For other applicable parameters, refer to <a class="el" href="_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">Convert Model from TensorFlow</a>. </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>