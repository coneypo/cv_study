<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Convert Kaldi* ASpIRE Chain Time Delay Neural Network (TDNN) Model to the Intermediate Representation - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Convert Kaldi* ASpIRE Chain Time Delay Neural Network (TDNN) Model to the Intermediate Representation </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>You can <a href="https://kaldi-asr.org/models/1/0001_aspire_chain_model.tar.gz">download a pre-trained model</a> for the ASpIRE Chain Time Delay Neural Network (TDNN) from the Kaldi* project official web-site.</p>
<h2>Convert ASpIRE Chain TDNN Model to IR</h2>
<p>To generate the Intermediate Representation (IR) of the model, run the Model Optimizer with the following parameters: </p><div class="fragment"><div class="line">python3 ./mo_kaldi.py --input_model exp/chain/tdnn_7b/final.mdl --output output</div></div><!-- fragment --><p>The IR will have two inputs: <code>input</code> for data and <code>ivector</code> for ivectors.</p>
<h2>Example: Run ASpIRE Chain TDNN Model with the Speech Recognition Sample</h2>
<p>These instructions show how to run the converted model with the <a class="el" href="_inference_engine_samples_speech_sample_README.html">Speech Recognition sample</a>. In this example, the input data contains one utterance from one speaker.</p>
<p>To follow the steps described below, you must first do the following:</p><ol type="1">
<li>Download a <a href="https://github.com/kaldi-asr/kaldi">Kaldi repository</a>.</li>
<li>Build it using instructions in <code>README.md</code> in the repository.</li>
<li>Download the <a href="https://kaldi-asr.org/models/1/0001_aspire_chain_model.tar.gz">model archive</a> from Kaldi website.</li>
<li>Extract the downloaded model archive to the <code>egs/aspire/s5</code> folder of the Kaldi repository.</li>
</ol>
<p>To run the ASpIRE Chain TDNN Model with Speech Recognition sample:</p>
<ol type="1">
<li>Prepare the model for decoding. Refer to the <code>README.txt</code> file from the downloaded model archive for instructions.</li>
<li>Convert data and ivectors to <code>.ark</code> format. Refer to the corresponding sections below for instructions.</li>
</ol>
<h3>Prepare Data</h3>
<p>If you have a <code>.wav</code> data file, you can convert it to <code>.ark</code> format using the following command: </p><div class="fragment"><div class="line">&lt;path_to_kaldi_repo&gt;/src/featbin/compute-mfcc-feats --config=&lt;path_to_kaldi_repo&gt;/egs/aspire/s5/conf/mfcc_hires.conf scp:./wav.scp ark,scp:feats.ark,feats.scp</div></div><!-- fragment --><h3>Prepare Ivectors</h3>
<p>To prepare ivectors for the Speech Recognition sample, do the following:</p>
<ol type="1">
<li>Go to the <code>egs/aspire/s5/</code> directory of the built Kaldi repository: <div class="fragment"><div class="line">cd &lt;path_to_kaldi_repo&gt;/egs/aspire/s5/</div></div><!-- fragment --></li>
<li>Extract ivectors from the data: <div class="fragment"><div class="line">./steps/online/nnet2/extract_ivectors_online.sh --ivector_period &lt;max_frame_count_in_utterance&gt; &lt;data folder&gt; exp/tdnn_7b_chain_online/ivector_extractor &lt;ivector folder&gt; </div></div><!-- fragment --> To simplify the preparation of ivectors for the Speech Recognition sample, specify the maximum number of frames in utterances as a parameter for <code>--ivector_period</code> to get only one ivector per utterance. As a result, in <code>&lt;ivector folder&gt;</code>, you will find the <code>ivector_online.1.ark</code> file.</li>
<li>Go to the <code>&lt;ivector folder&gt;</code>: <div class="fragment"><div class="line">cd &lt;ivector folder&gt;</div></div><!-- fragment --></li>
<li>Convert the <code>ivector_online.1.ark</code> file to text format using the <code>copy-feats</code> tool. Run the following command: <div class="fragment"><div class="line">&lt;path_to_kaldi_repo&gt;/src/featbin/copy-feats --binary=False ark:ivector_online.1.ark ark:ivector_online.1.ark.txt</div></div><!-- fragment --></li>
<li>For the Speech Recognition sample, the <code>.ark</code> file must contain an ivector for each frame. You must copy the ivector <code>frame_count</code> times. To do this, you can run the following script in the Python* command prompt: <div class="fragment"><div class="line">f=open(&quot;ivector_online.1.ark.txt&quot;, &quot;r&quot;)</div><div class="line">g=open(&quot;ivector_online_ie.ark.txt&quot;, &quot;w&quot;)</div><div class="line">for line in f:</div><div class="line">    if &quot;[&quot; not in line:</div><div class="line">        for i in range(frame_count):</div><div class="line">            line = line.replace(&quot;]&quot;, &quot; &quot;)</div><div class="line">            g.write(line)</div><div class="line">    else:</div><div class="line">        g.write(line)</div><div class="line">g.write(&quot;]&quot;)</div><div class="line">f.close()</div><div class="line">g.close()</div></div><!-- fragment --></li>
<li>Create an <code>.ark</code> file from <code>.txt</code>: <div class="fragment"><div class="line">&lt;path_to_kaldi_repo&gt;/src/featbin/copy-feats --binary=True ark:ivector_online_ie.ark.txt ark:ivector_online_ie.ark</div></div><!-- fragment --></li>
</ol>
<h3>Run the Speech Recognition Sample</h3>
<p>Run the Speech Recognition sample with the created ivector <code>.ark</code> file as follows: </p><div class="fragment"><div class="line">speech_sample -i feats.ark,ivector_online_ie.ark -m final.xml -d CPU -o prediction.ark -cw_l 17 -cw_r 12</div></div><!-- fragment --><p>Results can be decoded as described in "Use of Sample in Kaldi* Speech Recognition Pipeline" chapter in <a class="el" href="_inference_engine_samples_speech_sample_README.html">the Speech Recognition Sample description</a>. </p>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>