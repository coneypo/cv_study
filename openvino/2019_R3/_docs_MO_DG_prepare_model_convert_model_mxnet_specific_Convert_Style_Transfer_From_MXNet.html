<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting a Style Transfer Model from MXNet* - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting a Style Transfer Model from MXNet* </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The tutorial explains how to generate a model for style transfer using the public MXNet* neural style transfer sample. To use the style transfer sample from OpenVINO&trade;, follow the steps below as no public pre-trained style transfer model is provided with the OpenVINO toolkit.</p>
<h4>1. Download or clone the repository with an MXNet neural style transfer sample: <a href="https://github.com/zhaw/neural_style">Zhaw's Neural Style Transfer repository</a>.</h4>
<h4>2. Prepare the environment required to work with the cloned repository:</h4>
<ol type="1">
<li>Install packages dependency:<br />
 <div class="fragment"><div class="line">sudo apt-get install python-tk</div></div><!-- fragment --></li>
<li>Install Python* requirements: <div class="fragment"><div class="line">pip3 install --user mxnet</div><div class="line">pip3 install --user matplotlib</div><div class="line">pip3 install --user scikit-image</div></div><!-- fragment --></li>
</ol>
<h4>3. Download the pre-trained <a href="https://github.com/dmlc/web-data/raw/master/mxnet/neural-style/model/vgg19.params">VGG19 model</a> and save it to the root directory of the cloned repository because the sample expects the model <code>vgg19.params</code> file to be in that directory.<br />
</h4>
<h4>4. Modify source code files of style transfer sample from cloned repository.<br />
</h4>
<ol type="1">
<li>Go to the <code>fast_mrf_cnn</code> subdirectory. <div class="fragment"><div class="line">cd ./fast_mrf_cnn</div></div><!-- fragment --></li>
<li>Open the <code>symbol.py</code> file and modify the <code>decoder_symbol()</code> function. Replace. <div class="fragment"><div class="line">def decoder_symbol():</div><div class="line">    data = mx.sym.Variable(<span class="stringliteral">&#39;data&#39;</span>)</div><div class="line">    data = mx.sym.Convolution(data=data, num_filter=256, kernel=(3,3), pad=(1,1), stride=(1, 1), name=<span class="stringliteral">&#39;deco_conv1&#39;</span>)</div></div><!-- fragment --> with the following code:<br />
 <div class="fragment"><div class="line"><span class="keyword">def </span>decoder_symbol_with_vgg(vgg_symbol):</div><div class="line">    data = mx.sym.Convolution(data=vgg_symbol, num_filter=256, kernel=(3,3), pad=(1,1), stride=(1, 1), name=<span class="stringliteral">&#39;deco_conv1&#39;</span>)</div></div><!-- fragment --></li>
<li>Save and close the <code>symbol.py</code> file.</li>
<li>Open and edit the <code>make_image.py</code> file: Modify the <code>__init__()</code> function in the <code>Maker</code> class. Replace:<br />
 <div class="fragment"><div class="line">decoder = symbol.decoder_symbol()</div></div><!-- fragment --> with the following code:<br />
 <div class="fragment"><div class="line">decoder = symbol.decoder_symbol_with_vgg(vgg_symbol)</div></div><!-- fragment --></li>
<li>To join the pre-trained weights with the decoder weights, make the following changes: After the code lines for loading the decoder weights:<br />
 <div class="fragment"><div class="line">args = mx.nd.load(<span class="stringliteral">&#39;%s_decoder_args.nd&#39;</span>%model_prefix)</div><div class="line">auxs = mx.nd.load(<span class="stringliteral">&#39;%s_decoder_auxs.nd&#39;</span>%model_prefix)</div></div><!-- fragment --> add the following line:<br />
 <div class="fragment"><div class="line">arg_dict.update(args)</div></div><!-- fragment --></li>
<li>Use <code>arg_dict</code> instead of <code>args</code> as a parameter of the <code>decoder.bind()</code> function. Replace the line:<br />
 <div class="fragment"><div class="line">self.deco_executor = decoder.bind(ctx=mx.cpu(), args=args, aux_states=auxs)</div></div><!-- fragment --> with the following:<br />
 <div class="fragment"><div class="line">self.deco_executor = decoder.bind(ctx=mx.cpu(), args=arg_dict, aux_states=auxs)</div></div><!-- fragment --></li>
<li>Replace all <code>mx.gpu</code> with <code>mx.cpu</code> in the <code>decoder.bind()</code> function.</li>
<li>To save the result model as a <code>.json</code> file, add the following code to the end of the <code>generate()</code> function in the <code>Maker</code> class:<br />
 <div class="fragment"><div class="line">self.vgg_executor._symbol.save(<span class="stringliteral">&#39;{}-symbol.json&#39;</span>.format(<span class="stringliteral">&#39;vgg19&#39;</span>))</div><div class="line">self.deco_executor._symbol.save(<span class="stringliteral">&#39;{}-symbol.json&#39;</span>.format(<span class="stringliteral">&#39;nst_vgg19&#39;</span>))</div></div><!-- fragment --></li>
<li>Save and close the <code>make_image.py</code> file.</li>
</ol>
<h4>5. Run the sample with a decoder model according to the instructions from the <code>README.md</code> file in the cloned repository.</h4>
<p>For example, to run the sample with the pre-trained decoder weights from the <code>models</code> folder and output shape, use the following code:<br />
 </p><div class="fragment"><div class="line"><span class="keyword">import</span> make_image</div><div class="line">maker = make_image.Maker(<span class="stringliteral">&#39;models/13&#39;</span>, (1024, 768))</div><div class="line">maker.generate(<span class="stringliteral">&#39;output.jpg&#39;</span>, <span class="stringliteral">&#39;../images/tubingen.jpg&#39;</span>)</div></div><!-- fragment --><p> Where <code>'models/13'</code> string is composed of the following sub-strings:</p><ul>
<li><code>'models/'</code> - path to the folder that contains .nd files with pre-trained styles weights and <code>'13'</code></li>
<li>Decoder prefix: the repository contains a default decoder, which is the 13_decoder.</li>
</ul>
<p>You can choose any style from <a href="https://pan.baidu.com/s/1skMHqYp">collection of pre-trained weights</a>. The <code>generate()</code> function generates <code>nst_vgg19-symbol.json</code> and <code>vgg19-symbol.json</code> files for the specified shape. In the code, it is [1024 x 768] for a 4:3 ratio, and you can specify another, for example, [224,224] for a square ratio.</p>
<h4>6. Run the Model Optimizer to generate an Intermediate Representation (IR):</h4>
<ol type="1">
<li>Create a new directory. For example:<br />
 <div class="fragment"><div class="line">mkdir nst_model</div></div><!-- fragment --></li>
<li>Copy the initial and generated model files to the created directory. For example, to copy the pre-trained decoder weights from the <code>models</code> folder to the <code>nst_model</code> directory, run the following commands:<br />
 <div class="fragment"><div class="line">cp nst_vgg19-symbol.json nst_model</div><div class="line">cp vgg19-symbol.json nst_model</div><div class="line">cp ../vgg19.params nst_model/vgg19-0000.params</div><div class="line">cp models/13_decoder_args.nd nst_model</div><div class="line">cp models/13_decoder_auxs.nd nst_model</div></div><!-- fragment --> <blockquote class="doxtable">
<p><b>NOTE</b>: Make sure that all the <code>.params</code> and <code>.json</code> files are in the same directory as the <code>.nd</code> files. Otherwise, the conversion process fails. </p>
</blockquote>
</li>
<li>Run the Model Optimizer for MXNet. Use the <code>--nd_prefix_name</code> option to specify the decoder prefix and <code>--input_shape</code> to specify input shapes in [N,C,W,H] order. For example:<br />
 <div class="fragment"><div class="line">python3 mo.py --input_symbol &lt;path/to/nst_model&gt;/nst_vgg19-symbol.json --framework mxnet --output_dir &lt;path/to/output_dir&gt; --input_shape [1,3,224,224] --nd_prefix_name 13_decoder --pretrained_model &lt;path/to/nst_model&gt;/vgg19-0000.params</div></div><!-- fragment --></li>
<li>The IR is generated (<code>.bin</code>, <code>.xml</code> and <code>.mapping</code> files) in the specified output directory and ready to be consumed by the Inference Engine. </li>
</ol>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>