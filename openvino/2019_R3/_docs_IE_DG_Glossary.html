<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Glossary - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Glossary </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Acronyms and Abbreviations</h2>
<table class="doxtable">
<tr>
<th align="left">Abbreviation </th><th align="left">Description  </th></tr>
<tr>
<td align="left">API </td><td align="left">Application Programming Interface </td></tr>
<tr>
<td align="left">AVX </td><td align="left">Advanced Vector Extensions </td></tr>
<tr>
<td align="left">clDNN </td><td align="left">Compute Library for Deep Neural Networks </td></tr>
<tr>
<td align="left">CLI </td><td align="left">Command Line Interface </td></tr>
<tr>
<td align="left">CNN </td><td align="left">Convolutional Neural Network </td></tr>
<tr>
<td align="left">CPU </td><td align="left">Central Processing Unit </td></tr>
<tr>
<td align="left">CV </td><td align="left">Computer Vision </td></tr>
<tr>
<td align="left">DL </td><td align="left">Deep Learning </td></tr>
<tr>
<td align="left">DLDT </td><td align="left">Intel(R) Deep Learning Deployment Toolkit </td></tr>
<tr>
<td align="left">DLL </td><td align="left">Dynamic Link Library </td></tr>
<tr>
<td align="left">DNN </td><td align="left">Deep Neural Networks </td></tr>
<tr>
<td align="left">ELU </td><td align="left">Exponential Linear rectification Unit </td></tr>
<tr>
<td align="left">FCN </td><td align="left">Fully Convolutional Network </td></tr>
<tr>
<td align="left">FP </td><td align="left">Floating Point </td></tr>
<tr>
<td align="left">FPGA </td><td align="left">Field-Programmable Gate Array </td></tr>
<tr>
<td align="left">GCC </td><td align="left">GNU Compiler Collection </td></tr>
<tr>
<td align="left">GPU </td><td align="left">Graphics Processing Unit </td></tr>
<tr>
<td align="left">HD </td><td align="left">High Definition </td></tr>
<tr>
<td align="left">IE </td><td align="left">Inference Engine </td></tr>
<tr>
<td align="left">IR </td><td align="left">Intermediate Representation </td></tr>
<tr>
<td align="left">JIT </td><td align="left">Just In Time </td></tr>
<tr>
<td align="left">JTAG </td><td align="left">Joint Test Action Group </td></tr>
<tr>
<td align="left">LPR </td><td align="left">License-Plate Recognition </td></tr>
<tr>
<td align="left">LRN </td><td align="left">Local Response Normalization </td></tr>
<tr>
<td align="left">mAP </td><td align="left">Mean Average Precision </td></tr>
<tr>
<td align="left">Intel(R) MKL-DNN </td><td align="left">Intel(R) Math Kernel Library Deep Neural Networks </td></tr>
<tr>
<td align="left">MO </td><td align="left">Model Optimizer </td></tr>
<tr>
<td align="left">MVN </td><td align="left">Mean Variance Normalization </td></tr>
<tr>
<td align="left">NCDHW </td><td align="left">Number of images, Channels, Depth, Height, Width </td></tr>
<tr>
<td align="left">NCHW </td><td align="left">Number of images, Channels, Height, Width </td></tr>
<tr>
<td align="left">NHWC </td><td align="left">Number of images, Height, Width, Channels </td></tr>
<tr>
<td align="left">NMS </td><td align="left">Non-Maximum Suppression </td></tr>
<tr>
<td align="left">NN </td><td align="left">Neural Network </td></tr>
<tr>
<td align="left">NST </td><td align="left">Neural Style Transfer </td></tr>
<tr>
<td align="left">OD </td><td align="left">Object Detection </td></tr>
<tr>
<td align="left">OS </td><td align="left">Operating System </td></tr>
<tr>
<td align="left">PCI </td><td align="left">Peripheral Component Interconnect </td></tr>
<tr>
<td align="left">PReLU </td><td align="left">Parametric Rectified Linear Unit </td></tr>
<tr>
<td align="left">PSROI </td><td align="left">Position Sensitive Region Of Interest </td></tr>
<tr>
<td align="left">RCNN, R-CNN </td><td align="left">Region-based Convolutional Neural Network </td></tr>
<tr>
<td align="left">ReLU </td><td align="left">Rectified Linear Unit </td></tr>
<tr>
<td align="left">ROI </td><td align="left">Region Of Interest </td></tr>
<tr>
<td align="left">SDK </td><td align="left">Software Development Kit </td></tr>
<tr>
<td align="left">SSD </td><td align="left">Single Shot multibox Detector </td></tr>
<tr>
<td align="left">SSE </td><td align="left">Streaming SIMD Extensions </td></tr>
<tr>
<td align="left">USB </td><td align="left">Universal Serial Bus </td></tr>
<tr>
<td align="left">VGG </td><td align="left">Visual Geometry Group </td></tr>
<tr>
<td align="left">VOC </td><td align="left">Visual Object Classes </td></tr>
<tr>
<td align="left">WINAPI </td><td align="left">Windows Application Programming Interface </td></tr>
</table>
<h2>Terms</h2>
<p>Glossary of terms used in the Inference Engine</p>
<table class="doxtable">
<tr>
<th align="left">Term </th><th align="left">Description  </th></tr>
<tr>
<td align="left">Batch </td><td align="left">Number of images to analyze during one call of infer. Maximum batch size is a property of the network and it is set before loading of the network to the plugin. In NHWC, NCHW and NCDHW image data layout representation, the N refers to the number of images in the batch </td></tr>
<tr>
<td align="left">Blob </td><td align="left">Memory container used for storing inputs, outputs of the network, weights and biases of the layers </td></tr>
<tr>
<td align="left">Device (Affinitity) </td><td align="left">A preferred Intel(R) hardware device to run the inference (CPU, GPU, FPGA, etc.) </td></tr>
<tr>
<td align="left">Extensibility mechanism, Custom layers </td><td align="left">The mechanism that provides you with capabilities to extend the Inference Engine and Model Optimizer so that they can work with topologies containing layers that are not yet supported </td></tr>
<tr>
<td align="left"><code>ICNNNetwork</code> </td><td align="left">An Interface of the Convolutional Neural Network that Inference Engine reads from IR. Consists of topology, weights and biases </td></tr>
<tr>
<td align="left"><code>IExecutableNetwork</code> </td><td align="left">An instance of the loaded network which allows the Inference Engine to request (several) infer requests and perform inference synchronously or asynchronously </td></tr>
<tr>
<td align="left"><code>IHeteroInferencePlugin</code> </td><td align="left">Interface that is implemented by the heterogeneity plugin to allow the Inference Engine to set the default affinities for layers by devices before loading the network to the heterogeneous plugin. You can modify affinities manually before loading to the plugin. </td></tr>
<tr>
<td align="left"><code>IInferencePlugin</code> </td><td align="left">Interface provided by each plugin to allow the Inference Engine to load <code>ICNNNetwork</code> to the plugin, create Executable network and set special dedicated options for the plugin </td></tr>
<tr>
<td align="left"><code>IInferRequest</code> </td><td align="left">Interface that represents the end point of inference on the model loaded to the plugin and represented by executable network. Inputs are set here, outputs should be requested from this interface as well </td></tr>
<tr>
<td align="left"><code>InferenceEngineProfileInfo</code> </td><td align="left">Represents basic inference profiling information per layer </td></tr>
<tr>
<td align="left">Inference Engine </td><td align="left">A C++ library with a set of classes that you can use in your application to infer input data (images) and get the result </td></tr>
<tr>
<td align="left">Inference Engine API </td><td align="left">The basic default API for all supported devices, which allows you to load a model from Intermediate Representation, set input and output formats and execute the model on various devices </td></tr>
<tr>
<td align="left">Inference Engine Plugin </td><td align="left">Inference Engine plugin is a software component that contains complete implementation for inference on a certain Intel(R) hardware device: CPU, GPU, VPU, FPGA, etc. Each plugin implements the unified API and provides additional hardware-specific APIs. </td></tr>
<tr>
<td align="left">Layer catalog </td><td align="left">A list of supported layers and its parameters. Sets of supported layers are different for different plugins, please check the documentation on plugins to verify if the Inference Engine supports certain layer on the dedicated hardware </td></tr>
<tr>
<td align="left"><code>Layout</code> </td><td align="left">Image data layout refers to the representation of images batch. Layout shows a sequence of 4D or 5D tensor data in memory. A typical NCHW format represents pixel in horizontal direction, rows by vertical dimension, planes by channel and images into batch </td></tr>
<tr>
<td align="left"><code>OutputsDataMap</code> </td><td align="left">Structure which contains information about output precisions and layouts </td></tr>
<tr>
<td align="left">Precision </td><td align="left">Represents data precision. For example, FP32 is 32-bit floating point, FP16 is 16-bit floating point. Precision can be changed before loading the network to the plugin </td></tr>
<tr>
<td align="left"><code>PreProcessInfo</code> </td><td align="left">Class that represents input data for the network. It contains information about input precision, its layout, and pre-processing </td></tr>
<tr>
<td align="left"><code>ResponseDesc</code> </td><td align="left">Represents debug information for an error </td></tr>
</table>
<h2>See Also</h2>
<ul>
<li><a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">Deep Learning Model Optimizer IR Layers Catalog</a></li>
<li><a class="el" href="_docs_IE_DG_Memory_primitives.html">Inference Engine Memory primitives</a></li>
<li><a class="el" href="_docs_IE_DG_supported_plugins_Supported_Devices.html">Terminology</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>