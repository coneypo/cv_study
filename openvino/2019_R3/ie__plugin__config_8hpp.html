<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ie_plugin_config.hpp File Reference - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#define-members">Macros</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">ie_plugin_config.hpp File Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>a header for advanced hardware related properties for clDNN plugin To use in SetConfig() method of plugins  
<a href="#details">More...</a></p>
<div class="textblock"><code>#include &lt;string&gt;</code><br />
<code>#include &lt;tuple&gt;</code><br />
<code>#include &lt;vector&gt;</code><br />
</div>
<p><a href="ie__plugin__config_8hpp_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespaceInferenceEngine"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine.html">InferenceEngine</a></td></tr>
<tr class="memdesc:namespaceInferenceEngine"><td class="mdescLeft">&#160;</td><td class="mdescRight">Inference Engine API. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespaceInferenceEngine_1_1Metrics"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html">InferenceEngine::Metrics</a></td></tr>
<tr class="memdesc:namespaceInferenceEngine_1_1Metrics"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metrics <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespaceInferenceEngine_1_1PluginConfigParams"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html">InferenceEngine::PluginConfigParams</a></td></tr>
<tr class="memdesc:namespaceInferenceEngine_1_1PluginConfigParams"><td class="mdescLeft">&#160;</td><td class="mdescRight">Generic plugin configuration. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="define-members"></a>
Macros</h2></td></tr>
<tr class="memitem:a69d0efa20c5b2bec020a706279f0c7be"><td class="memItemLeft" align="right" valign="top"><a id="a69d0efa20c5b2bec020a706279f0c7be"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__plugin__config_8hpp.html#a69d0efa20c5b2bec020a706279f0c7be">METRIC_KEY</a>(name)&#160;&#160;&#160;InferenceEngine::Metrics::METRIC_##name</td></tr>
<tr class="memdesc:a69d0efa20c5b2bec020a706279f0c7be"><td class="mdescLeft">&#160;</td><td class="mdescRight">shortcut for defining common Inference Engine metrics <br /></td></tr>
<tr class="separator:a69d0efa20c5b2bec020a706279f0c7be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb48efa632ae9bacfa86b8a3a0d9541e"><td class="memItemLeft" align="right" valign="top"><a id="adb48efa632ae9bacfa86b8a3a0d9541e"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__plugin__config_8hpp.html#adb48efa632ae9bacfa86b8a3a0d9541e">EXEC_NETWORK_METRIC_KEY</a>(name)&#160;&#160;&#160;<a class="el" href="ie__plugin__config_8hpp.html#a69d0efa20c5b2bec020a706279f0c7be">METRIC_KEY</a>(name)</td></tr>
<tr class="memdesc:adb48efa632ae9bacfa86b8a3a0d9541e"><td class="mdescLeft">&#160;</td><td class="mdescRight">shortcut for defining common Inference Engine ExecutableNetwork metrics <br /></td></tr>
<tr class="separator:adb48efa632ae9bacfa86b8a3a0d9541e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6dd157c1a4d27888bfdcdf1b64cfdb2"><td class="memItemLeft" align="right" valign="top"><a id="ad6dd157c1a4d27888bfdcdf1b64cfdb2"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__plugin__config_8hpp.html#ad6dd157c1a4d27888bfdcdf1b64cfdb2">METRIC_VALUE</a>(name)&#160;&#160;&#160;InferenceEngine::Metrics::name</td></tr>
<tr class="memdesc:ad6dd157c1a4d27888bfdcdf1b64cfdb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">shortcut for defining metric values <br /></td></tr>
<tr class="separator:ad6dd157c1a4d27888bfdcdf1b64cfdb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad09cfba062e8ec9fb7ab9383f656ec7"><td class="memItemLeft" align="right" valign="top"><a id="aad09cfba062e8ec9fb7ab9383f656ec7"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__plugin__config_8hpp.html#aad09cfba062e8ec9fb7ab9383f656ec7">CONFIG_KEY</a>(name)&#160;&#160;&#160;InferenceEngine::PluginConfigParams::_CONFIG_KEY(name)</td></tr>
<tr class="memdesc:aad09cfba062e8ec9fb7ab9383f656ec7"><td class="mdescLeft">&#160;</td><td class="mdescRight">shortcut for defining configuration keys <br /></td></tr>
<tr class="separator:aad09cfba062e8ec9fb7ab9383f656ec7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b1801501dc6436ffa1a9ed9c6333b40"><td class="memItemLeft" align="right" valign="top"><a id="a2b1801501dc6436ffa1a9ed9c6333b40"></a>
#define&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ie__plugin__config_8hpp.html#a2b1801501dc6436ffa1a9ed9c6333b40">CONFIG_VALUE</a>(name)&#160;&#160;&#160;InferenceEngine::PluginConfigParams::name</td></tr>
<tr class="memdesc:a2b1801501dc6436ffa1a9ed9c6333b40"><td class="mdescLeft">&#160;</td><td class="mdescRight">shortcut for defining configuration values <br /></td></tr>
<tr class="separator:a2b1801501dc6436ffa1a9ed9c6333b40"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a04ce5d4fb24fde259b329caffa358fa5"><td class="memItemLeft" align="right" valign="top"><a id="a04ce5d4fb24fde259b329caffa358fa5"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a04ce5d4fb24fde259b329caffa358fa5">InferenceEngine::Metrics::METRIC_AVAILABLE_DEVICES</a> = &quot;AVAILABLE_DEVICES&quot;</td></tr>
<tr class="memdesc:a04ce5d4fb24fde259b329caffa358fa5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of available device IDs. String value is "AVAILABLE_DEVICES". <br /></td></tr>
<tr class="separator:a04ce5d4fb24fde259b329caffa358fa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a67a2c5ea1cb1ea7d42c71b8bf0d0b97d">InferenceEngine::Metrics::METRIC_SUPPORTED_METRICS</a> = &quot;SUPPORTED_METRICS&quot;</td></tr>
<tr class="memdesc:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of supported metrics. String value is "SUPPORTED_METRICS" This can be used as an executable network metric as well.  <a href="namespaceInferenceEngine_1_1Metrics.html#a67a2c5ea1cb1ea7d42c71b8bf0d0b97d">More...</a><br /></td></tr>
<tr class="separator:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a41d90ac79d73d8706ae2e9eb46a673a1">InferenceEngine::Metrics::METRIC_SUPPORTED_CONFIG_KEYS</a> = &quot;SUPPORTED_CONFIG_KEYS&quot;</td></tr>
<tr class="memdesc:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of supported config keys. String value is "SUPPORTED_CONFIG_KEYS" This can be used as an executable network metric as well.  <a href="namespaceInferenceEngine_1_1Metrics.html#a41d90ac79d73d8706ae2e9eb46a673a1">More...</a><br /></td></tr>
<tr class="separator:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33c5772e0e22fab7b981cb33c2820f32"><td class="memItemLeft" align="right" valign="top"><a id="a33c5772e0e22fab7b981cb33c2820f32"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a33c5772e0e22fab7b981cb33c2820f32">InferenceEngine::Metrics::METRIC_FULL_DEVICE_NAME</a> = &quot;FULL_DEVICE_NAME&quot;</td></tr>
<tr class="memdesc:a33c5772e0e22fab7b981cb33c2820f32"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::string value representing a full device name. String value is "FULL_DEVICE_NAME". <br /></td></tr>
<tr class="separator:a33c5772e0e22fab7b981cb33c2820f32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54ebc63520c179a5854f5a199d24e1d2"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a54ebc63520c179a5854f5a199d24e1d2">InferenceEngine::Metrics::METRIC_OPTIMIZATION_CAPABILITIES</a> = &quot;OPTIMIZATION_CAPABILITIES&quot;</td></tr>
<tr class="memdesc:a54ebc63520c179a5854f5a199d24e1d2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of optimization options per device. String value is "OPTIMIZATION_CAPABILITIES" The possible values:  <a href="namespaceInferenceEngine_1_1Metrics.html#a54ebc63520c179a5854f5a199d24e1d2">More...</a><br /></td></tr>
<tr class="separator:a54ebc63520c179a5854f5a199d24e1d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33f8ec1373b4a3550b87abf3a7773aa2"><td class="memItemLeft" align="right" valign="top"><a id="a33f8ec1373b4a3550b87abf3a7773aa2"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::Metrics::FP32</b> = &quot;FP32&quot;</td></tr>
<tr class="separator:a33f8ec1373b4a3550b87abf3a7773aa2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45ef215735092ccc913e9d6c54cfb226"><td class="memItemLeft" align="right" valign="top"><a id="a45ef215735092ccc913e9d6c54cfb226"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::Metrics::FP16</b> = &quot;FP16&quot;</td></tr>
<tr class="separator:a45ef215735092ccc913e9d6c54cfb226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad31c07cfba5d2d2859af67742ca5a89b"><td class="memItemLeft" align="right" valign="top"><a id="ad31c07cfba5d2d2859af67742ca5a89b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::Metrics::INT8</b> = &quot;INT8&quot;</td></tr>
<tr class="separator:ad31c07cfba5d2d2859af67742ca5a89b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a888cf88b6ec040a80dc63b4995be2b0a"><td class="memItemLeft" align="right" valign="top"><a id="a888cf88b6ec040a80dc63b4995be2b0a"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::Metrics::BIN</b> = &quot;BIN&quot;</td></tr>
<tr class="separator:a888cf88b6ec040a80dc63b4995be2b0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a765ae7767f0eca6abc8dfaa67ce5d2ee"><td class="memItemLeft" align="right" valign="top"><a id="a765ae7767f0eca6abc8dfaa67ce5d2ee"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::Metrics::WINOGRAD</b> = &quot;WINOGRAD&quot;</td></tr>
<tr class="separator:a765ae7767f0eca6abc8dfaa67ce5d2ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39f21cea314e4a122b857d4112be2eb1"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a39f21cea314e4a122b857d4112be2eb1">InferenceEngine::Metrics::METRIC_RANGE_FOR_STREAMS</a> = &quot;RANGE_FOR_STREAMS&quot;</td></tr>
<tr class="memdesc:a39f21cea314e4a122b857d4112be2eb1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to provide information about a range for streams on platforms where streams are supported. Metric returns a value of std::tuple&lt;unsigned int, unsigned int&gt; type, where:  <a href="namespaceInferenceEngine_1_1Metrics.html#a39f21cea314e4a122b857d4112be2eb1">More...</a><br /></td></tr>
<tr class="separator:a39f21cea314e4a122b857d4112be2eb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4335554dc78de02b95418bb29ade2831"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a4335554dc78de02b95418bb29ade2831">InferenceEngine::Metrics::METRIC_RANGE_FOR_ASYNC_INFER_REQUESTS</a> = &quot;RANGE_FOR_ASYNC_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a4335554dc78de02b95418bb29ade2831"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to provide a hint for a range for number of async infer requests. If device supports streams, the metric provides range for number of IRs per stream. Metric returns a value of std::tuple&lt;unsigned int, unsigned int, unsigned int&gt; type, where:  <a href="namespaceInferenceEngine_1_1Metrics.html#a4335554dc78de02b95418bb29ade2831">More...</a><br /></td></tr>
<tr class="separator:a4335554dc78de02b95418bb29ade2831"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="memItemLeft" align="right" valign="top"><a id="a4cc6b8c1b548fad1e03ea2a897b15400"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a4cc6b8c1b548fad1e03ea2a897b15400">InferenceEngine::Metrics::METRIC_NUMBER_OF_WAITING_INFER_REQUESTS</a> = &quot;NUMBER_OF_WAITING_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned int value of number of waiting infer request. String value is "NUMBER_OF_WAITNING_INFER_REQUESTS". This can be used as an executable network metric as well. <br /></td></tr>
<tr class="separator:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="memItemLeft" align="right" valign="top"><a id="a8bb4bb50ecf459e83f2dec54e5506e0b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a8bb4bb50ecf459e83f2dec54e5506e0b">InferenceEngine::Metrics::METRIC_NUMBER_OF_EXEC_INFER_REQUESTS</a> = &quot;NUMBER_OF_EXEC_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned int value of number of infer request in execution stage. String value is "NUMBER_OF_EXEC_INFER_REQUESTS". This can be used as an executable network metric as well. <br /></td></tr>
<tr class="separator:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8a47d4063517a77764b632962d4cc8d"><td class="memItemLeft" align="right" valign="top"><a id="ac8a47d4063517a77764b632962d4cc8d"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#ac8a47d4063517a77764b632962d4cc8d">InferenceEngine::Metrics::METRIC_NETWORK_NAME</a> = &quot;NETWORK_NAME&quot;</td></tr>
<tr class="memdesc:ac8a47d4063517a77764b632962d4cc8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a name of network. String value is "NETWORK_NAME". <br /></td></tr>
<tr class="separator:ac8a47d4063517a77764b632962d4cc8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="memItemLeft" align="right" valign="top"><a id="a2f746c0fabfb75a6fced6cf394cb9b2e"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a2f746c0fabfb75a6fced6cf394cb9b2e">InferenceEngine::Metrics::METRIC_DEVICE_THERMAL</a> = &quot;DEVICE_THERMAL&quot;</td></tr>
<tr class="memdesc:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a float of device thermal. String value is "DEVICE_THERMAL". <br /></td></tr>
<tr class="separator:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57a821fbccfb015f161e00b805415a58"><td class="memItemLeft" align="right" valign="top"><a id="a57a821fbccfb015f161e00b805415a58"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a57a821fbccfb015f161e00b805415a58">InferenceEngine::Metrics::METRIC_OPTIMAL_NUMBER_OF_INFER_REQUESTS</a> = &quot;OPTIMAL_NUMBER_OF_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a57a821fbccfb015f161e00b805415a58"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned integer value of optimal number of executable network infer requests. <br /></td></tr>
<tr class="separator:a57a821fbccfb015f161e00b805415a58"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42d48631fa3332ded8c776513e897bf3"><td class="memItemLeft" align="right" valign="top"><a id="a42d48631fa3332ded8c776513e897bf3"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a42d48631fa3332ded8c776513e897bf3">InferenceEngine::PluginConfigParams::YES</a> = &quot;YES&quot;</td></tr>
<tr class="memdesc:a42d48631fa3332ded8c776513e897bf3"><td class="mdescLeft">&#160;</td><td class="mdescRight">generic boolean values <br /></td></tr>
<tr class="separator:a42d48631fa3332ded8c776513e897bf3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ceab5fe6f519a82b92c7a3794561c5f"><td class="memItemLeft" align="right" valign="top"><a id="a3ceab5fe6f519a82b92c7a3794561c5f"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::NO</b> = &quot;NO&quot;</td></tr>
<tr class="separator:a3ceab5fe6f519a82b92c7a3794561c5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd027d0800ad52c8658bb0098848d5ad"><td class="memItemLeft" align="right" valign="top"><a id="afd027d0800ad52c8658bb0098848d5ad"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#afd027d0800ad52c8658bb0098848d5ad">InferenceEngine::PluginConfigParams::KEY_CPU_THREADS_NUM</a> = &quot;CPU_THREADS_NUM&quot;</td></tr>
<tr class="memdesc:afd027d0800ad52c8658bb0098848d5ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">Limit #threads that are used by Inference Engine for inference on the CPU. <br /></td></tr>
<tr class="separator:afd027d0800ad52c8658bb0098848d5ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1264fc1aa7f58c908e884eb8fbaff8b2"><td class="memItemLeft" align="right" valign="top"><a id="a1264fc1aa7f58c908e884eb8fbaff8b2"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a1264fc1aa7f58c908e884eb8fbaff8b2">InferenceEngine::PluginConfigParams::KEY_CPU_BIND_THREAD</a> = &quot;CPU_BIND_THREAD&quot;</td></tr>
<tr class="memdesc:a1264fc1aa7f58c908e884eb8fbaff8b2"><td class="mdescLeft">&#160;</td><td class="mdescRight">The name for setting CPU affinity per thread option. It is passed to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a396d953bf2cc4baf4f8c4ef9f4af9593" title="Sets configuration for plugin, acceptable keys can be found in ie_plugin_config.hpp. ">IInferencePlugin::SetConfig()</a>, this option should be used with values: <a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a42d48631fa3332ded8c776513e897bf3" title="generic boolean values ">PluginConfigParams::YES</a> or PluginConfigParams::NO Ignored, if the OpenVINO compiled with OpenMP threading and any affinity-related OpenMP's environment variable is set. <br /></td></tr>
<tr class="separator:a1264fc1aa7f58c908e884eb8fbaff8b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f5f53765f721693c02480f6f6f23f69"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a4f5f53765f721693c02480f6f6f23f69">InferenceEngine::PluginConfigParams::CPU_THROUGHPUT_NUMA</a> = &quot;CPU_THROUGHPUT_NUMA&quot;</td></tr>
<tr class="memdesc:a4f5f53765f721693c02480f6f6f23f69"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimize CPU execution to maximize throughput. It is passed to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a396d953bf2cc4baf4f8c4ef9f4af9593" title="Sets configuration for plugin, acceptable keys can be found in ie_plugin_config.hpp. ">IInferencePlugin::SetConfig()</a>, this option should be used with values:  <a href="namespaceInferenceEngine_1_1PluginConfigParams.html#a4f5f53765f721693c02480f6f6f23f69">More...</a><br /></td></tr>
<tr class="separator:a4f5f53765f721693c02480f6f6f23f69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cd7a5a13a764191ddb7d6fe101662ac"><td class="memItemLeft" align="right" valign="top"><a id="a4cd7a5a13a764191ddb7d6fe101662ac"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::CPU_THROUGHPUT_AUTO</b> = &quot;CPU_THROUGHPUT_AUTO&quot;</td></tr>
<tr class="separator:a4cd7a5a13a764191ddb7d6fe101662ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae04df28b5ac394e398297e432f3c7b6e"><td class="memItemLeft" align="right" valign="top"><a id="ae04df28b5ac394e398297e432f3c7b6e"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::KEY_CPU_THROUGHPUT_STREAMS</b> = &quot;CPU_THROUGHPUT_STREAMS&quot;</td></tr>
<tr class="separator:ae04df28b5ac394e398297e432f3c7b6e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bb0c463f992548d15f0832aa7f68c9a"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a5bb0c463f992548d15f0832aa7f68c9a">InferenceEngine::PluginConfigParams::GPU_THROUGHPUT_AUTO</a> = &quot;GPU_THROUGHPUT_AUTO&quot;</td></tr>
<tr class="memdesc:a5bb0c463f992548d15f0832aa7f68c9a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimize GPU plugin execution to maximize throughput. It is passed to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a396d953bf2cc4baf4f8c4ef9f4af9593" title="Sets configuration for plugin, acceptable keys can be found in ie_plugin_config.hpp. ">IInferencePlugin::SetConfig()</a>, this option should be used with values:  <a href="namespaceInferenceEngine_1_1PluginConfigParams.html#a5bb0c463f992548d15f0832aa7f68c9a">More...</a><br /></td></tr>
<tr class="separator:a5bb0c463f992548d15f0832aa7f68c9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a526b77e80a636e46c65d4745fa396d89"><td class="memItemLeft" align="right" valign="top"><a id="a526b77e80a636e46c65d4745fa396d89"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::KEY_GPU_THROUGHPUT_STREAMS</b> = &quot;GPU_THROUGHPUT_STREAMS&quot;</td></tr>
<tr class="separator:a526b77e80a636e46c65d4745fa396d89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06e7d1c7f8905f0915d73eba49fa1bed"><td class="memItemLeft" align="right" valign="top"><a id="a06e7d1c7f8905f0915d73eba49fa1bed"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a06e7d1c7f8905f0915d73eba49fa1bed">InferenceEngine::PluginConfigParams::KEY_PERF_COUNT</a> = &quot;PERF_COUNT&quot;</td></tr>
<tr class="memdesc:a06e7d1c7f8905f0915d73eba49fa1bed"><td class="mdescLeft">&#160;</td><td class="mdescRight">The name for setting performance counters option. It is passed to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a396d953bf2cc4baf4f8c4ef9f4af9593" title="Sets configuration for plugin, acceptable keys can be found in ie_plugin_config.hpp. ">IInferencePlugin::SetConfig()</a>, this option should be used with values: <a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a42d48631fa3332ded8c776513e897bf3" title="generic boolean values ">PluginConfigParams::YES</a> or PluginConfigParams::NO. <br /></td></tr>
<tr class="separator:a06e7d1c7f8905f0915d73eba49fa1bed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66d52f19002274e481440b0c3a2d12e3"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a66d52f19002274e481440b0c3a2d12e3">InferenceEngine::PluginConfigParams::KEY_DYN_BATCH_LIMIT</a> = &quot;DYN_BATCH_LIMIT&quot;</td></tr>
<tr class="memdesc:a66d52f19002274e481440b0c3a2d12e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">The key defines dynamic limit of batch processing. Specified value is applied to all following Infer() calls. Inference Engine processes min(batch_limit, original_batch_size) first pictures from input blob. For example, if input blob has sizes 32x3x224x224 after applying plugin.SetConfig({KEY_DYN_BATCH_LIMIT, 10}) Inference Engine primitives processes only beginner subblobs with size 10x3x224x224. This value can be changed before any Infer() call to specify a new batch limit.  <a href="namespaceInferenceEngine_1_1PluginConfigParams.html#a66d52f19002274e481440b0c3a2d12e3">More...</a><br /></td></tr>
<tr class="separator:a66d52f19002274e481440b0c3a2d12e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7640912dbc0cb75c3396371760048f19"><td class="memItemLeft" align="right" valign="top"><a id="a7640912dbc0cb75c3396371760048f19"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::KEY_DYN_BATCH_ENABLED</b> = &quot;DYN_BATCH_ENABLED&quot;</td></tr>
<tr class="separator:a7640912dbc0cb75c3396371760048f19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70e7ec5da93eb586ed90c9313c934cdf"><td class="memItemLeft" align="right" valign="top"><a id="a70e7ec5da93eb586ed90c9313c934cdf"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a70e7ec5da93eb586ed90c9313c934cdf">InferenceEngine::PluginConfigParams::KEY_SINGLE_THREAD</a> = &quot;SINGLE_THREAD&quot;</td></tr>
<tr class="memdesc:a70e7ec5da93eb586ed90c9313c934cdf"><td class="mdescLeft">&#160;</td><td class="mdescRight">The key controls threading inside Inference Engine. It is passed to <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a396d953bf2cc4baf4f8c4ef9f4af9593" title="Sets configuration for plugin, acceptable keys can be found in ie_plugin_config.hpp. ">IInferencePlugin::SetConfig()</a>, this option should be used with values: <a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a42d48631fa3332ded8c776513e897bf3" title="generic boolean values ">PluginConfigParams::YES</a> or PluginConfigParams::NO. <br /></td></tr>
<tr class="separator:a70e7ec5da93eb586ed90c9313c934cdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b8c53f571862c6c394c67f3a66e7db2"><td class="memItemLeft" align="right" valign="top"><a id="a8b8c53f571862c6c394c67f3a66e7db2"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a8b8c53f571862c6c394c67f3a66e7db2">InferenceEngine::PluginConfigParams::KEY_CONFIG_FILE</a> = &quot;CONFIG_FILE&quot;</td></tr>
<tr class="memdesc:a8b8c53f571862c6c394c67f3a66e7db2"><td class="mdescLeft">&#160;</td><td class="mdescRight">This key directs the plugin to load a configuration file. The value should be a file name with the plugin specific configuration. <br /></td></tr>
<tr class="separator:a8b8c53f571862c6c394c67f3a66e7db2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a492dd572580d2a31c98180403f39befb"><td class="memItemLeft" align="right" valign="top"><a id="a492dd572580d2a31c98180403f39befb"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a492dd572580d2a31c98180403f39befb">InferenceEngine::PluginConfigParams::KEY_DUMP_KERNELS</a> = &quot;DUMP_KERNELS&quot;</td></tr>
<tr class="memdesc:a492dd572580d2a31c98180403f39befb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This key enables dumping of the kernels used by the plugin for custom layers. This option should be used with values: <a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a42d48631fa3332ded8c776513e897bf3" title="generic boolean values ">PluginConfigParams::YES</a> or PluginConfigParams::NO (default) <br /></td></tr>
<tr class="separator:a492dd572580d2a31c98180403f39befb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89f158fb06300ab3b4a64d27f6140587"><td class="memItemLeft" align="right" valign="top"><a id="a89f158fb06300ab3b4a64d27f6140587"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a89f158fb06300ab3b4a64d27f6140587">InferenceEngine::PluginConfigParams::KEY_TUNING_MODE</a> = &quot;TUNING_MODE&quot;</td></tr>
<tr class="memdesc:a89f158fb06300ab3b4a64d27f6140587"><td class="mdescLeft">&#160;</td><td class="mdescRight">This key controls performance tuning done or used by the plugin. This option should be used with values: PluginConfigParams::TUNING_CREATE, PluginConfigParams::TUNING_USE_EXISTING or PluginConfigParams::TUNING_DISABLED (default) <br /></td></tr>
<tr class="separator:a89f158fb06300ab3b4a64d27f6140587"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa1800005c22786bf8b1485625a35d22"><td class="memItemLeft" align="right" valign="top"><a id="aaa1800005c22786bf8b1485625a35d22"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::TUNING_CREATE</b> = &quot;TUNING_CREATE&quot;</td></tr>
<tr class="separator:aaa1800005c22786bf8b1485625a35d22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea91e5661440ef9eb2efa65ae4bfc9f5"><td class="memItemLeft" align="right" valign="top"><a id="aea91e5661440ef9eb2efa65ae4bfc9f5"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::TUNING_USE_EXISTING</b> = &quot;TUNING_USE_EXISTING&quot;</td></tr>
<tr class="separator:aea91e5661440ef9eb2efa65ae4bfc9f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c766b5a3b7e1a63894f249e727f2e1f"><td class="memItemLeft" align="right" valign="top"><a id="a0c766b5a3b7e1a63894f249e727f2e1f"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::TUNING_DISABLED</b> = &quot;TUNING_DISABLED&quot;</td></tr>
<tr class="separator:a0c766b5a3b7e1a63894f249e727f2e1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af65c57faa410f2dd1c56b311092c5ba4"><td class="memItemLeft" align="right" valign="top"><a id="af65c57faa410f2dd1c56b311092c5ba4"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#af65c57faa410f2dd1c56b311092c5ba4">InferenceEngine::PluginConfigParams::KEY_TUNING_FILE</a> = &quot;TUNING_FILE&quot;</td></tr>
<tr class="memdesc:af65c57faa410f2dd1c56b311092c5ba4"><td class="mdescLeft">&#160;</td><td class="mdescRight">This key defines the tuning data filename to be created/used. <br /></td></tr>
<tr class="separator:af65c57faa410f2dd1c56b311092c5ba4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ad8e81ea6681cb216494f308f353a1b"><td class="memItemLeft" align="right" valign="top"><a id="a0ad8e81ea6681cb216494f308f353a1b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a0ad8e81ea6681cb216494f308f353a1b">InferenceEngine::PluginConfigParams::KEY_LOG_LEVEL</a> = &quot;LOG_LEVEL&quot;</td></tr>
<tr class="memdesc:a0ad8e81ea6681cb216494f308f353a1b"><td class="mdescLeft">&#160;</td><td class="mdescRight">the key for setting desirable log level. This option should be used with values: PluginConfigParams::LOG_NONE (default), PluginConfigParams::LOG_WARNING, PluginConfigParams::LOG_INFO, PluginConfigParams::LOG_DEBUG <br /></td></tr>
<tr class="separator:a0ad8e81ea6681cb216494f308f353a1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1b4cc88b88790c04b96954d950b8925"><td class="memItemLeft" align="right" valign="top"><a id="ae1b4cc88b88790c04b96954d950b8925"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::LOG_NONE</b> = &quot;LOG_NONE&quot;</td></tr>
<tr class="separator:ae1b4cc88b88790c04b96954d950b8925"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f03215b4f83d352ccaa92f406f52ddb"><td class="memItemLeft" align="right" valign="top"><a id="a5f03215b4f83d352ccaa92f406f52ddb"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::LOG_WARNING</b> = &quot;LOG_WARNING&quot;</td></tr>
<tr class="separator:a5f03215b4f83d352ccaa92f406f52ddb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0433a005740f0f892bc854ae17ec373f"><td class="memItemLeft" align="right" valign="top"><a id="a0433a005740f0f892bc854ae17ec373f"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::LOG_INFO</b> = &quot;LOG_INFO&quot;</td></tr>
<tr class="separator:a0433a005740f0f892bc854ae17ec373f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3426ac77a15e2dcad755a6e497c2da81"><td class="memItemLeft" align="right" valign="top"><a id="a3426ac77a15e2dcad755a6e497c2da81"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>InferenceEngine::PluginConfigParams::LOG_DEBUG</b> = &quot;LOG_DEBUG&quot;</td></tr>
<tr class="separator:a3426ac77a15e2dcad755a6e497c2da81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f4163dbc2c805b6adcadb4b90033d0b"><td class="memItemLeft" align="right" valign="top"><a id="a5f4163dbc2c805b6adcadb4b90033d0b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a5f4163dbc2c805b6adcadb4b90033d0b">InferenceEngine::PluginConfigParams::KEY_DEVICE_ID</a> = &quot;DEVICE_ID&quot;</td></tr>
<tr class="memdesc:a5f4163dbc2c805b6adcadb4b90033d0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">the key for setting of required device to execute on values: device id starts from "0" - first device, "1" - second device, etc <br /></td></tr>
<tr class="separator:a5f4163dbc2c805b6adcadb4b90033d0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411b655991a73fdf759a52a8a8da80d7"><td class="memItemLeft" align="right" valign="top"><a id="a411b655991a73fdf759a52a8a8da80d7"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a411b655991a73fdf759a52a8a8da80d7">InferenceEngine::PluginConfigParams::KEY_EXCLUSIVE_ASYNC_REQUESTS</a> = &quot;EXCLUSIVE_ASYNC_REQUESTS&quot;</td></tr>
<tr class="memdesc:a411b655991a73fdf759a52a8a8da80d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">the key for enabling exclusive mode for async requests of different executable networks and the same plugin. Sometimes it's necessary to avoid oversubscription requests that are sharing the same device in parallel. E.g. There 2 task executors for CPU device: one - in the Hetero plugin, another - in pure CPU plugin. Parallel execution both of them might lead to oversubscription and not optimal CPU usage. More efficient to run the corresponding tasks one by one via single executor. By default, the option is set to YES for hetero cases, and to NO for conventional (single-plugin) cases Notice that setting YES disables the CPU streams feature (see another config key in this file) <br /></td></tr>
<tr class="separator:a411b655991a73fdf759a52a8a8da80d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02ac10820f3dc0b48358a343d54f3a52"><td class="memItemLeft" align="right" valign="top"><a id="a02ac10820f3dc0b48358a343d54f3a52"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1PluginConfigParams.html#a02ac10820f3dc0b48358a343d54f3a52">InferenceEngine::PluginConfigParams::KEY_DUMP_EXEC_GRAPH_AS_DOT</a> = &quot;DUMP_EXEC_GRAPH_AS_DOT&quot;</td></tr>
<tr class="memdesc:a02ac10820f3dc0b48358a343d54f3a52"><td class="mdescLeft">&#160;</td><td class="mdescRight">This key enables dumping of the internal primitive graph. Should be passed into LoadNetwork method to enable dumping of internal graph of primitives and corresponding configuration information. Value is a name of output dot file without extension. Files &lt;dot_file_name&gt;_init.dot and &lt;dot_file_name&gt;_perf.dot will be produced. <br /></td></tr>
<tr class="separator:a02ac10820f3dc0b48358a343d54f3a52"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>a header for advanced hardware related properties for clDNN plugin To use in SetConfig() method of plugins </p>
<p>a header for advanced hardware related properties for IE plugins To use in SetConfig() method of plugins LoadNetwork() method overloads that accept config as parameter</p>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>