<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Model Downloader and other automation tools - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Model Downloader and other automation tools </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This directory contains scripts that automate certain model-related tasks based on configuration files in the models' directories.</p>
<ul>
<li><code>downloader.py</code> (model downloader) downloads model files from online sources and, if necessary, patches them to make them more usable with Model Optimizer;</li>
<li><code>converter.py</code> (model converter) converts the models that are not in the Inference Engine IR format into that format using Model Optimizer.</li>
<li><code>info_dumper.py</code> (model information dumper) prints information about the models in a stable machine-readable format.</li>
</ul>
<p>Please use these tools instead of attempting to parse the configuration files directly. Their format is undocumented and may change in incompatible ways in future releases.</p>
<h2>Prerequisites </h2>
<ol type="1">
<li>Install Python (version 3.5.2 or higher)</li>
<li>Install the tools' dependencies with the following command:</li>
</ol>
<div class="fragment"><div class="line">python3 -mpip install --user -r ./requirements.in</div></div><!-- fragment --><p>For the model converter, you will also need to install the OpenVINO&trade; toolkit and the prerequisite libraries for Model Optimizer. See the <a href="https://docs.openvinotoolkit.org/">OpenVINO toolkit documentation</a> for details.</p>
<p>If you using models from PyTorch framework, you will also need to use intermediate conversion to ONNX format. To use automatic conversion install additional dependencies:</p>
<div class="fragment"><div class="line">python3 -mpip install --user -r ./requirements-pytorch.in</div></div><!-- fragment --><p>When running the model downloader with Python 3.5.x on macOS, you may encounter an error similar to the following:</p>
<blockquote class="doxtable">
<p>requests.exceptions.SSLError: [...] (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_PROTOCOL_VERSION] </p>
</blockquote>
<p>tlsv1 alert protocol version (_ssl.c:719)'),))</p>
<p>You can work around this by installing additional packages:</p>
<div class="fragment"><div class="line">python3 -mpip install --user &#39;requests[security]&#39;</div></div><!-- fragment --><p>Alternatively, upgrade to Python 3.6 or a later version.</p>
<h2>Model downloader usage </h2>
<p>The basic usage is to run the script like this:</p>
<div class="fragment"><div class="line">./downloader.py --all</div></div><!-- fragment --><p>This will download all models into a directory tree rooted in the current directory. To download into a different directory, use the <code>-o</code>/<code>--output_dir</code> option:</p>
<div class="fragment"><div class="line">./downloader.py --all --output_dir my/download/directory</div></div><!-- fragment --><p>The <code>--all</code> option can be replaced with other filter options to download only a subset of models. See the "Shared options" section.</p>
<p>You may use <code>--precisions</code> flag to specify comma separated precisions of weights to be downloaded.</p>
<div class="fragment"><div class="line">./downloader.py --name face-detection-retail-0004 --precisions FP16,INT8</div></div><!-- fragment --><p>By default, the script will attempt to download each file only once. You can use the <code>--num_attempts</code> option to change that and increase the robustness of the download process:</p>
<div class="fragment"><div class="line">./downloader.py --all --num_attempts 5 # attempt each download five times</div></div><!-- fragment --><p>You can use the <code>--cache_dir</code> option to make the script use the specified directory as a cache. The script will place a copy of each downloaded file in the cache, or, if it is already there, retrieve it from the cache instead of downloading it again.</p>
<div class="fragment"><div class="line">./downloader.py --all --cache_dir my/cache/directory</div></div><!-- fragment --><p>The cache format is intended to remain compatible in future Open Model Zoo versions, so you can use a cache to avoid redownloading most files when updating Open Model Zoo.</p>
<p>By default, the script outputs progress information as unstructured, human-readable text. If you want to consume progress information programmatically, use the <code>--progress_format</code> option:</p>
<div class="fragment"><div class="line">./downloader.py --all --progress_format=json</div></div><!-- fragment --><p>When this option is set to <code>json</code>, the script's standard output is replaced by a machine-readable progress report, whose format is documented in the "JSON progress report format" section. This option does not affect errors and warnings, which will still be printed to the standard error stream in a human-readable format.</p>
<p>You can also set this option to <code>text</code> to explicitly request the default text format.</p>
<p>See the "Shared options" section for information on other options accepted by the script.</p>
<h3>JSON progress report format</h3>
<p>This section documents the format of the progress report produced by the script when the <code>--progress_format=json</code> option is specified.</p>
<p>The report consists of a sequence of events, where each event is represented by a line containing a JSON-encoded object. Each event has a member with the name <code>$type</code> whose value determines the type of the event, as well as which additional members it contains.</p>
<p>The following event types are currently defined:</p>
<ul>
<li><p class="startli"><code>model_download_begin</code></p>
<p class="startli">Additional members: <code>model</code> (string), <code>num_files</code> (integer).</p>
<p class="startli">The script started downloading the model named by <code>model</code>. <code>num_files</code> is the number of files that will be downloaded for this model.</p>
<p class="startli">This event will always be followed by a corresponding <code>model_download_end</code> event.</p>
</li>
<li><p class="startli"><code>model_download_end</code></p>
<p class="startli">Additional members: <code>model</code> (string), <code>successful</code> (boolean).</p>
<p class="startli">The script stopped downloading the model named by <code>model</code>. <code>successful</code> is true if every file was downloaded successfully.</p>
</li>
<li><p class="startli"><code>model_file_download_begin</code></p>
<p class="startli">Additional members: <code>model</code> (string), <code>model_file</code> (string), <code>size</code> (integer).</p>
<p class="startli">The script started downloading the file named by <code>model_file</code> of the model named by <code>model</code>. <code>size</code> is the size of the file in bytes.</p>
<p class="startli">This event will always occur between <code>model_download_begin</code> and <code>model_download_end</code> events for the model, and will always be followed by a corresponding <code>model_file_download_end</code> event.</p>
</li>
<li><p class="startli"><code>model_file_download_end</code></p>
<p class="startli">Additional members: <code>model</code> (string), <code>model_file</code> (string), <code>successful</code> (boolean).</p>
<p class="startli">The script stopped downloading the file named by <code>model_file</code> of the model named by <code>model</code>. <code>successful</code> is true if the file was downloaded successfully.</p>
</li>
<li><p class="startli"><code>model_file_download_progress</code></p>
<p class="startli">Additional members: <code>model</code> (string), <code>model_file</code> (string), <code>size</code> (integer).</p>
<p class="startli">The script downloaded <code>size</code> bytes of the file named by <code>model_file</code> of the model named by <code>model</code> so far. Note that <code>size</code> can decrease in a subsequent event if the download is interrupted and retried.</p>
<p class="startli">This event will always occur between <code>model_file_download_begin</code> and <code>model_file_download_end</code> events for the file.</p>
</li>
<li><p class="startli"><code>model_postprocessing_begin</code></p>
<p class="startli">Additional members: <code>model</code>.</p>
<p class="startli">The script started post-download processing on the model named by <code>model</code>.</p>
<p class="startli">This event will always be followed by a corresponding <code>model_postprocessing_end</code> event.</p>
</li>
<li><p class="startli"><code>model_postprocessing_end</code></p>
<p class="startli">Additional members: <code>model</code>.</p>
<p class="startli">The script stopped post-download processing on the model named by <code>model</code>.</p>
</li>
</ul>
<p>Additional event types and members may be added in the future.</p>
<p>Tools parsing the machine-readable format should avoid relying on undocumented details. In particular:</p>
<ul>
<li>Tools should not assume that any given event will occur for a given model/file (unless specified otherwise above) or will only occur once.</li>
<li>Tools should not assume that events will occur in a certain order beyond the ordering constraints specified above. Note that future versions of the script may interleave the downloading of different files or models.</li>
</ul>
<h2>Model converter usage </h2>
<p>The basic usage is to run the script like this:</p>
<div class="fragment"><div class="line">./converter.py --all</div></div><!-- fragment --><p>This will convert all models into the Inference Engine IR format. Models that were originally in that format are ignored. Models in PyTorch's format will be converted in ONNX format first.</p>
<p>The current directory must be the root of a download tree created by the model downloader. To specify a different download tree path, use the <code>-d</code>/<code>--download_dir</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --download_dir my/download/directory</div></div><!-- fragment --><p>By default, the converted models are placed into the download tree. To place them into a different directory tree, use the <code>-o</code>/<code>--output_dir</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --output_dir my/output/directory</div></div><!-- fragment --><p> &gt;Note: models in intermediate format are placed to this directory too.</p>
<p>The <code>--all</code> option can be replaced with other filter options to convert only a subset of models. See the "Shared options" section.</p>
<p>By default, the script will produce models in every precision that is supported for conversion. To only produce models in a specific precision, use the <code>--precisions</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --precisions=FP16</div></div><!-- fragment --><p>If the specified precision is not supported for a model, that model will be skipped.</p>
<p>The script will attempt to locate Model Optimizer using the environment variables set by the OpenVINO&trade; toolkit's <code>setupvars.sh</code>/<code>setupvars.bat</code> script. You can override this heuristic with the <code>--mo</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --mo my/openvino/path/model_optimizer/mo.py</div></div><!-- fragment --><p>You can add extra Model Optimizer arguments to the ones specified in the model configuration by using the <code>--add-mo-arg</code> option. The option can be repeated to add multiple arguments:</p>
<div class="fragment"><div class="line">./converter.py --name=caffenet --add-mo-arg=--reverse_input_channels --add-mo-arg=--silent</div></div><!-- fragment --><p>By default, the script will run Model Optimizer using the same Python executable that was used to run the script itself. To use a different Python executable, use the <code>-p</code>/<code>--python</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --python my/python</div></div><!-- fragment --><p>The script can run multiple conversion commands concurrently. To enable this, use the <code>-j</code>/<code>--jobs</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all -j8 # run up to 8 commands at a time</div></div><!-- fragment --><p>The argument to the option must be either a maximum number of concurrently executed commands, or "auto", in which case the number of CPUs in the system is used. By default, all commands are run sequentially.</p>
<p>The script can print the conversion commands without actually running them. To do this, use the <code>--dry-run</code> option:</p>
<div class="fragment"><div class="line">./converter.py --all --dry-run</div></div><!-- fragment --><p>See the "Shared options" section for information on other options accepted by the script.</p>
<h2>Model information dumper usage </h2>
<p>The basic usage is to run the script like this:</p>
<div class="fragment"><div class="line">./info_dumper.py --all</div></div><!-- fragment --><p>This will print to standard output information about all models.</p>
<p>The only options accepted by the script are those described in the "Shared options" section.</p>
<p>The script's output is a JSON array, each element of which is a JSON object describing a single model. Each such object has the following keys:</p>
<ul>
<li><code>name</code>: the identifier of the model, as accepted by the <code>--name</code> option.</li>
<li><code>description</code>: text describing the model. Paragraphs are separated by line feed characters.</li>
<li><code>framework</code>: a string identifying the framework whose format the model is downloaded in. Current possible values are <code>dldt</code> (Inference Engine IR), <code>caffe</code>, <code>mxnet</code>, <code>pytorch</code> and <code>tf</code> (TensorFlow). Additional possible values might be added in the future.</li>
<li><code>license_url</code>: an URL for the license that the model is distributed under.</li>
<li><code>precisions</code>: the list of precisions that the model has IR files for. For models downloaded in a format other than the Inference Engine IR format, these are the precisions that the model converter can produce IR files in. Current possible values are <code>FP16</code>, <code>FP32</code>, <code>INT1</code>, <code>INT8</code>; more might be added in the future.</li>
<li><code>subdirectory</code>: the subdirectory of the output tree into which the downloaded or converted files will be placed by the downloader or the converter, respectively.</li>
<li><p class="startli"><code>task_type</code>: a string identifying the type of task that the model performs. Current possible values are:</p><ul>
<li><code>action_recognition</code></li>
<li><code>classification</code></li>
<li><code>detection</code></li>
<li><code>face_recognition</code></li>
<li><code>head_pose_estimation</code></li>
<li><code>human_pose_estimation</code></li>
<li><code>image_processing</code></li>
<li><code>instance_segmentation</code></li>
<li><code>object_attributes</code></li>
<li><code>optical_character_recognition</code></li>
<li><code>semantic_segmentation</code></li>
</ul>
<p class="startli">Additional possible values might be added in the future.</p>
</li>
</ul>
<h2>Shared options </h2>
<p>The are certain options that both tools accept.</p>
<p><code>-h</code>/<code>--help</code> can be used to print a help message:</p>
<div class="fragment"><div class="line">./TOOL.py --help</div></div><!-- fragment --><p>There are several mutually exclusive filter options that select the models the tool will process:</p>
<ul>
<li><code>--all</code> selects all models.</li>
</ul>
<div class="fragment"><div class="line">./TOOL.py --all</div></div><!-- fragment --><ul>
<li><code>--name</code> takes a comma-separated list of patterns and selects models that match at least one of these patterns. The patterns may contain shell-style wildcards.</li>
</ul>
<div class="fragment"><div class="line">./TOOL.py --name &#39;mtcnn-p,densenet-*&#39;</div></div><!-- fragment --><p>See <a href="https://docs.python.org/3/library/fnmatch.html">https://docs.python.org/3/library/fnmatch.html</a> for a full description of the pattern syntax.</p>
<ul>
<li><code>--list</code> takes a path to a file that must contain a list of patterns and selects models that match at least one of those patterns.</li>
</ul>
<div class="fragment"><div class="line">./TOOL.py --list my.lst</div></div><!-- fragment --><p>The file must contain one pattern per line. The pattern syntax is the same as for the <code>--name</code> option. Blank lines and comments starting with <code>#</code> are ignored. For example:</p>
<div class="fragment"><div class="line">mtcnn-p</div><div class="line">densenet-* # get all DenseNet variants</div></div><!-- fragment --><p>To see the available models, you can use the <code>--print_all</code> option. When this option is specified, the tool will print all model names defined in the configuration file and exit:</p>
<div class="fragment"><div class="line">$ ./TOOL.py --print_all</div><div class="line">action-recognition-0001-decoder</div><div class="line">action-recognition-0001-encoder</div><div class="line">age-gender-recognition-retail-0013</div><div class="line">driver-action-recognition-adas-0002-decoder</div><div class="line">driver-action-recognition-adas-0002-encoder</div><div class="line">emotions-recognition-retail-0003</div><div class="line">face-detection-adas-0001</div><div class="line">face-detection-adas-binary-0001</div><div class="line">face-detection-retail-0004</div><div class="line">face-detection-retail-0005</div><div class="line">[...]</div></div><!-- fragment --><p>Either <code>--print_all</code> or one of the filter options must be specified.</p>
<h2>Deprecated options </h2>
<p>In earlier releases, the tools used a single configuration file instead of per-model configuration files. For compatibility, loading such a file is still supported. However, this feature is deprecated and will be removed in a future release.</p>
<p>To load a configuration file in the old format, use the <code>-c</code>/<code>--config</code> option:</p>
<div class="fragment"><div class="line">./TOOL.py --all --config my-config.yml</div></div><!-- fragment --> <hr/>
<p>OpenVINO is a trademark of Intel Corporation or its subsidiaries in the U.S. and/or other countries.</p>
<p>Copyright &copy; 2018-2019 Intel Corporation</p>
<p>Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at </p><pre class="fragment"> http://www.apache.org/licenses/LICENSE-2.0
</pre><p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. </p>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>