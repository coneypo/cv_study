<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VPU Plugins - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">VPU Plugins </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This chapter provides information on the Inference Engine plugins that enable inferencing of deep learning models on the supported VPU devices:</p>
<ul>
<li>Intel® Movidius™ Neural Compute Stick powered by the Intel® Movidius™ Myriad™ 2 — Supported by the <a class="el" href="_docs_IE_DG_supported_plugins_MYRIAD.html">MYRIAD Plugin</a></li>
<li>Intel® Neural Compute Stick 2 powered by the Intel® Movidius™ Myriad™ X — Supported by the <a class="el" href="_docs_IE_DG_supported_plugins_MYRIAD.html">MYRIAD Plugin</a></li>
<li>Intel® Vision Accelerator Design with Intel® Movidius™ VPUs — Supported by the <a class="el" href="_docs_IE_DG_supported_plugins_HDDL.html">HDDL Plugin</a></li>
</ul>
<h2>Known Layers Limitations</h2>
<ul>
<li><code>'ScaleShift'</code> layer is supported for zero value of <code>'broadcast'</code> attribute only.</li>
<li><code>'CTCGreedyDecoder'</code> layer works with <code>'ctc_merge_repeated'</code> attribute equal 1.</li>
<li><code>'DetectionOutput'</code> layer works with zero values of <code>'interpolate_orientation'</code> and <code>'num_orient_classes'</code> parameters only.</li>
<li><code>'MVN'</code> layer uses fixed value for <code>'eps'</code> parameters (1e-9).</li>
<li><code>'Normalize'</code> layer uses fixed value for <code>'eps'</code> parameters (1e-9) and is supported for zero value of <code>'across_spatial'</code> only.</li>
<li><code>'Pad'</code> layer works only with 4D tensors.</li>
</ul>
<h2>VPU Common Configuration Parameters</h2>
<p>The VPU plugins supports the configuration parameters listed below. The parameters are passed as <code>std::map&lt;std::string, std::string&gt;</code> on <code><a class="el" href="classInferenceEngine_1_1Core.html#afcd1cc386d0ef3d2d33c6bf7d447d5ff" title="Creates an executable network from a network object. Users can create as many networks as they need a...">InferenceEngine::Core::LoadNetwork</a></code> or <code><a class="el" href="classInferenceEngine_1_1Core.html#a268e2d24595061e9d804460cc6ca9ad3" title="Sets configuration for device, acceptable keys can be found in ie_plugin_config.hpp. ">InferenceEngine::Core::SetConfig</a></code></p>
<table class="doxtable">
<tr>
<th align="left">Parameter Name </th><th align="left">Parameter Values </th><th align="left">Default </th><th align="left">Description  </th></tr>
<tr>
<td align="left"><code>KEY_VPU_HW_STAGES_OPTIMIZATION</code> </td><td align="left"><code>YES</code>/<code>NO</code> </td><td align="left"><code>YES</code> </td><td align="left">Turn on HW stages usage<br />
 Applicable for Intel Movidius Myriad X and Intel Vision Accelerator Design devices only. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_NETWORK_CONFIG</code> </td><td align="left"><a href="#VPU_Network_Config">VPU Network Configuration</a> </td><td align="left">empty string </td><td align="left">Extra configuration for network compilation and optimization. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_COMPUTE_LAYOUT</code> </td><td align="left"><code>VPU_AUTO</code>, <code>VPU_NCHW</code>, <code>VPU_NHWC</code> </td><td align="left"><code>VPU_AUTO</code> </td><td align="left">Specify internal input and output layouts for network layers. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_LOG_LEVEL</code> </td><td align="left"><code>LOG_WARNING</code>, <code>LOG_INFO</code>, <code>LOG_DEBUG</code> </td><td align="left"><code>LOG_NONE</code> </td><td align="left">Set log level for device side. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_PRINT_RECEIVE_TENSOR_TIME</code> </td><td align="left"><code>YES</code>/<code>NO</code> </td><td align="left"><code>NO</code> </td><td align="left">Add device-side time spent waiting for input to PerformanceCounts.<br />
See <a href="#VPU_DATA_TRANSFER_PIPELINING">Data Transfer Pipelining</a> section for details. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_IGNORE_IR_STATISTIC</code> </td><td align="left"><code>YES</code>/<code>NO</code> </td><td align="left"><code>NO</code> </td><td align="left">VPU plugin could use statistic present in IR in order to try to improve calculations precision.<br />
 If you don't want statistic to be used enable this option. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_CUSTOM_LAYERS</code> </td><td align="left">path to XML file </td><td align="left">empty string </td><td align="left">This option allows to pass XML file with custom layers binding.<br />
If layer is present in such file, it would be used during inference even if the layer is natively supported. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_INPUT_NORM</code> </td><td align="left">Real number </td><td align="left">1.0 </td><td align="left"><b>Deprecated</b>* <br />
Define normalization coefficient for the network input. </td></tr>
<tr>
<td align="left"><code>KEY_VPU_INPUT_BIAS</code> </td><td align="left">Real number </td><td align="left">0.0 </td><td align="left"><b>Deprecated</b>* <br />
Specify Bias value that is added to each element of the network input. </td></tr>
</table>
<ul>
<li>- Instead, use Model Optimizer options.<br />
</li>
</ul>
<h2>VPU Network Configuration <a class="anchor" id="VPU_Network_Config"></a>&#160;</h2>
<p>The VPU network configuration mechanism allows to override VPU network compiler behavior and tune its optimizations. This mechanism is optional and by default the VPU network compile will use automatic heuristics for network optimizations. The <code>KEY_VPU_NETWORK_CONFIG</code> configuration parameter allows user to specify exact behavior for compiler.</p>
<p>Terminology used for VPU network configuration:</p>
<ul>
<li>VPU network compiler - entity that translates network IR into special representation that is used for execution on the device.</li>
<li>Compiler pass - compiler step, that performs some dedicated optimization.</li>
<li>Layer - network layer from original IR.</li>
<li>Data - object that is used as input or output of network layers.</li>
<li>Stage - execution entity for device. Network layers are mapped to stages, but there is no 1-to-1 correspondence between them, one layer might be represented as several stages, several layers might be merged into single stage, additional stages might be added to executable network.</li>
</ul>
<p>The <code>KEY_VPU_NETWORK_CONFIG</code> parameter is a list of key/value pairs separated by <code>,</code>:</p>
<div class="fragment"><div class="line">&lt;key&gt;=&lt;value&gt;,&lt;key&gt;=&lt;value&gt;,&lt;key&gt;=&lt;value&gt;,...</div></div><!-- fragment --><p>Supported <code>&lt;key&gt;</code> options:</p>
<ul>
<li><code>file</code> - <code>&lt;value&gt;</code> is path to XML file with configuration, the format of the file is described below.</li>
<li><code>data</code> - <code>&lt;value&gt;</code> is a name of Data object, next options are applied to this Data:<ul>
<li><code>scale</code> - <code>&lt;value&gt;</code> is a SCALE factor. See <a href="#VPU_Network_Config_Data">Data section</a>.</li>
</ul>
</li>
</ul>
<p>The VPU network compiler threats the configuration as hard requirement and fails if it can't satisfy it.</p>
<h3>Network Configuration File</h3>
<p>The <code>KEY_VPU_NETWORK_CONFIG</code> parameter allows to use separate file with network configuration. The file is an XML file and must have the following format:</p>
<div class="fragment"><div class="line">&lt;?<span class="keyword">xml</span> <span class="keyword">version</span>=<span class="stringliteral">&quot;1.0&quot;</span> ?&gt;</div><div class="line">&lt;<span class="keywordtype">vpu_net_config</span> <span class="keyword">version</span>=<span class="stringliteral">&quot;1&quot;</span>&gt;</div><div class="line">    [<span class="keyword">data</span> <span class="keyword">section</span>]</div><div class="line"></div><div class="line">    [<span class="keyword">layers</span> <span class="keyword">section</span>]</div><div class="line">&lt;/<span class="keywordtype">vpu_net_config</span>&gt;</div></div><!-- fragment --><p>The <code>version</code> attribute specifies the file format version (currently only <code>1</code> is supported). Configuration is divided onto sections for passes, data, layers and stages. Each section is optional.</p>
<h4>Data Section <a class="anchor" id="VPU_Network_Config_Data"></a>&#160;</h4>
<p>The data section allows to configure properties for data objects. Example of such section:</p>
<div class="fragment"><div class="line">&lt;<span class="keywordtype">data</span>&gt;</div><div class="line">    &lt;<span class="keywordtype">data</span> <span class="keyword">name</span>=<span class="stringliteral">&quot;input&quot;</span>&gt;</div><div class="line">        &lt;<span class="keywordtype">scale</span>&gt;64&lt;/<span class="keywordtype">scale</span>&gt;</div><div class="line">    &lt;/<span class="keywordtype">data</span>&gt;</div><div class="line">&lt;/<span class="keywordtype">data</span>&gt;</div></div><!-- fragment --><p>The data name corresponds to its producer layer from the original IR (the layer that declares this data as output). If the original layer has the only one output, the output data name will be equal to the layer name. If the original layer has more than one output, each output data will have the following name <code>&lt;layer name&gt;.&lt;port id&gt;</code>, where the <code>&lt;port id&gt;</code> corresponds to <code>&lt;port id="3"&gt;</code> XML node in the IR.</p>
<p><code>scale</code> property allows to apply SCALE factor to specified data object. The SCALE factor is used to increase the data range to avoid floating math errors on HW. The SCALE factor is propagating across the network until its end or until the layer, that can't propagate it.</p>
<p>If the data section is missing in network configuration file, the network compiler will try to estimate such SCALE factor automatically based on layer's weights range. The manual configuration might be used in case if automatic one didn't work or didn't give desired accuracy.</p>
<p><b>Hint:</b> it is better to use power-of-two values for SCALE factors.</p>
<h4>Layers Section</h4>
<p>The layers section allows to configure compiler behavior for layers optimization. Per-layer configuration is applied to all stages implementing selected layer. Example of such section:</p>
<div class="fragment"><div class="line">&lt;<span class="keywordtype">layers</span>&gt;</div><div class="line">    &lt;<span class="keywordtype">layer</span> <span class="keyword">name</span>=<span class="stringliteral">&quot;conv1&quot;</span>&gt;</div><div class="line">        &lt;<span class="keywordtype">hw</span>&gt;</div><div class="line">            [<span class="keyword">HW</span> <span class="keyword">options</span>]</div><div class="line">        &lt;/<span class="keywordtype">hw</span>&gt;</div><div class="line">    &lt;/<span class="keywordtype">layer</span>&gt;</div><div class="line">&lt;/<span class="keywordtype">layers</span>&gt;</div></div><!-- fragment --><p>The layer name corresponds to the original IR.</p>
<p>For now <code>layer</code> configuration support only HW section, which controls HW optimizations. The HW section make sense only for Convolution, Pooling and FullyConnected layers.</p>
<h5>Layer HW Section</h5>
<p>The HW optimization configuration section consists of the following options:</p>
<ul>
<li><code>enable</code> - turns on/off HW optimization of the selected layer.</li>
</ul>
<p>The <code>enable</code> option has the following syntax:</p>
<div class="fragment"><div class="line">&lt;<span class="keywordtype">enable</span>&gt;<span class="keyword">true</span>&lt;/<span class="keywordtype">enable</span>&gt;</div><div class="line"></div><div class="line">&lt;<span class="keywordtype">enable</span>&gt;<span class="keyword">false</span>&lt;/<span class="keywordtype">enable</span>&gt;</div></div><!-- fragment --><p>By default HW optimization is turned on for all supported layers.</p>
<h2>Data Transfer Pipelining <a class="anchor" id="VPU_DATA_TRANSFER_PIPELINING"></a>&#160;</h2>
<p>MYRIAD plugin tries to pipeline data transfer to/from device with computations. While one infer request is executed the data for next infer request can be uploaded to device in parallel. Same applicable for result downloading.</p>
<p><code>KEY_VPU_PRINT_RECEIVE_TENSOR_TIME</code> configuration parameter can be used to check the efficiency of current pipelining. The new record in performance counters will show the time that device spent waiting for input before starting the inference. In perfect pipeline this time should be near to zero, which means that the data was already transfered when new inference started.</p>
<h2>Troubleshooting</h2>
<p><b>Get the following message when running inference with the VPU plugin: "[VPU] Cannot convert layer &lt;layer_name&gt; due to unsupported layer type &lt;layer_type&gt;"</b></p>
<p>This means that your topology has a layer that is unsupported by your target VPU plugin. To resolve this issue, you can implement the custom layer for the target device using the <a class="el" href="_docs_IE_DG_Integrate_your_kernels_into_IE.html">Inference Engine Kernels Extensibility mechanism</a>. Or, to quickly get a working prototype, you can use the heterogeneous scenario with the default fallback policy (see the <a class="el" href="_docs_IE_DG_supported_plugins_HETERO.html">HETERO Plugin</a> section). Use the HETERO plugin with a fallback device that supports this layer, for example, CPU: <code>HETERO:MYRIAD,CPU</code>. For a list of VPU supported layers, see the Supported Layers section of the <a class="el" href="_docs_IE_DG_supported_plugins_Supported_Devices.html">Supported Devices</a> topic.</p>
<blockquote class="doxtable">
<p><b>NOTE:</b> Using heterogeneous scenario with VPU usage may cause accuracy issues on the VPU side. You can use the Collect Statistics Tool to collect statistic and save it in IR. This statistics can be used by the VPU plugin in order to restore accuracy. </p>
</blockquote>
<h2>See Also</h2>
<ul>
<li><a class="el" href="_docs_IE_DG_supported_plugins_Supported_Devices.html">Supported Devices</a></li>
<li><a href="https://software.intel.com/en-us/neural-compute-stick/get-started">Intel® Neural Compute Stick 2 Get Started</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>