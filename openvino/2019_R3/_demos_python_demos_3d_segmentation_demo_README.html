<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>3D Segmentation Python* Demo - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">3D Segmentation Python* Demo </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This topic demonstrates how to run the 3D Segmentation Demo, which segments 3D images using 3D convolutional networks.</p>
<h2>How It Works</h2>
<p>Upon the start-up, the demo reads command-line parameters and loads a network and images to the Inference Engine plugin.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: By default, Open Model Zoo demos expect input with BGR channels order. If you trained your model to work with RGB order, you need to manually rearrange the default channels order in the demo application or reconvert your model using the Model Optimizer tool with <code>--reverse_input_channels</code> argument specified. For more information about the argument, refer to <b>When to Reverse Input Channels</b> section of <a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">Converting a Model Using General Conversion Parameters</a>. </p>
</blockquote>
<h2>Running</h2>
<p>Run the application with the <code>-h</code> or <code>--help</code> option to see the usage message: </p><div class="fragment"><div class="line">python3 3d_segmentation_demo.py -h</div></div><!-- fragment --><p> The command yields the following usage message: </p><div class="fragment"><div class="line">usage: 3d_segmentation_demo.py [-h] -i PATH_TO_INPUT_DATA -m PATH_TO_MODEL -o</div><div class="line">                               PATH_TO_OUTPUT [-d TARGET_DEVICE]</div><div class="line">                               [-l PATH_TO_EXTENSION] [-nii]</div><div class="line">                               [-nthreads NUMBER_THREADS]</div><div class="line">                               [-s [SHAPE [SHAPE ...]]]</div><div class="line">                               [-c PATH_TO_CLDNN_CONFIG]</div><div class="line"></div><div class="line">Options:</div><div class="line">  -h, --help            Show this help message and exit.</div><div class="line">  -i PATH_TO_INPUT_DATA, --path_to_input_data PATH_TO_INPUT_DATA</div><div class="line">                        Required. Path to an input folder with NIfTI data/TIFF</div><div class="line">                        file</div><div class="line">  -m PATH_TO_MODEL, --path_to_model PATH_TO_MODEL</div><div class="line">                        Required. Path to an .xml file with a trained model</div><div class="line">  -o PATH_TO_OUTPUT, --path_to_output PATH_TO_OUTPUT</div><div class="line">                        Required. Path to a folder where output files will be</div><div class="line">                        saved</div><div class="line">  -d TARGET_DEVICE, --target_device TARGET_DEVICE</div><div class="line">                        Optional. Specify a target device to infer on: CPU, GPU.</div><div class="line">                        Use &quot;-d HETERO:&lt;comma separated devices list&gt;&quot; format</div><div class="line">                        to specify HETERO plugin.</div><div class="line">  -l PATH_TO_EXTENSION, --path_to_extension PATH_TO_EXTENSION</div><div class="line">                        Required for CPU custom layers. Absolute path to a</div><div class="line">                        shared library with the kernels implementations.</div><div class="line">  -nii, --output_nifti  Show output inference results as raw values</div><div class="line">  -nthreads NUMBER_THREADS, --number_threads NUMBER_THREADS</div><div class="line">                        Optional. Number of threads to use for inference on</div><div class="line">                        CPU (including HETERO cases).</div><div class="line">  -s [SHAPE [SHAPE ...]], --shape [SHAPE [SHAPE ...]]</div><div class="line">                        Optional. Specify shape for a network</div><div class="line">  -c PATH_TO_CLDNN_CONFIG, --path_to_cldnn_config PATH_TO_CLDNN_CONFIG</div><div class="line">                        Required for GPU custom kernels. Absolute path to an</div><div class="line">                        .xml file with the kernels description.</div></div><!-- fragment --><p>Running the application with the empty list of options yields the usage message and an error message. To run the demo, use public or pre-trained models that support 3D convolution, for example, UNet3D. You can download the pre-trained models using the OpenVINO <a class="el" href="_tools_downloader_README.html">Model Downloader</a> or from <a href="https://download.01.org/opencv/">https://download.01.org/opencv/</a>.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: Before running the demo with a trained model, make sure the model is converted to the Inference Engine format (*.xml + *.bin) using the <a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer tool</a>. </p>
</blockquote>
<p>For example, to do inference on a 3D TIFF image using a trained network with multiple outputs on CPU, run the following command:</p>
<div class="fragment"><div class="line">python3 3d_segmentation_demo.py -i &lt;path_to_image&gt;/inputImage.tiff -m &lt;path_to_model&gt;/multiple-output.xml -d CPU -o &lt;path_to_output&gt;</div></div><!-- fragment --><p>For example, to do inference on an 3D NIfTI image using a trained network with multiple outputs on CPU and save output TIFF and NIFTI images, run the following command: </p><div class="fragment"><div class="line">python3 3d_segmentation_demo.py -i &lt;path_to_nifti_images&gt; -m &lt;path_to_model&gt;/multiple-output.xml -d CPU -o &lt;path_to_output&gt; -nii</div></div><!-- fragment --><h2>Demo Output</h2>
<p>The demo outputs a multipage TIFF image and a NIFTI archive.</p>
<h2>See Also</h2>
<ul>
<li><a class="el" href="_demos_README.html">Using Open Model Zoo demos</a></li>
<li><a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a></li>
<li><a class="el" href="_tools_downloader_README.html">Model Downloader</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>