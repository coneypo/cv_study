<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Using extgen Tool for Automatic Generation of Model Optimizer and Inference Engine Extensions - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Using extgen Tool for Automatic Generation of Model Optimizer and Inference Engine Extensions </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>OpenVINO&trade; toolkit provides the <code>extgen</code> tool that facilitates creating Model Optimizer and Inference Engine extensions. The tool generates extension source files with stubs for the core functions. To get the workable extension, you should only add your implementation of these functions to the generated files.</p>
<h2>Generating Extension Files</h2>
<p>To generate extension files, run the <code>extgen</code> tool in one of the available modes:</p>
<ul>
<li>Interactive mode - the tool prompts you to input information. To run the interactive mode, use the <code>new</code> command line option. For example: <br />
 <div class="fragment"><div class="line">python extgen.py new --mo-op</div></div><!-- fragment --></li>
<li>Silent mode - the tool reads the input information from a configuration file. To run the silent mode, pass the configuration file as the only argument. For example: <br />
 <div class="fragment"><div class="line">python extgen.py config.extgen.json</div></div><!-- fragment --> You can find the sample configuration file in the <code>extgen</code> tool directory: <code>&lt;INSTALL_DIR&gt;/deployment_tools/extension_generator/config.extgen.json.example</code>.</li>
</ul>
<p>To run the tool in the interactive mode, specify the following parameters:</p>
<ul>
<li><code>mo-op</code> to generate a Model Optimizer operation</li>
<li><code>mo-caffe-ext</code> to generate a Model Optimizer Caffe* extractor</li>
<li><code>mo-tf-ext</code> to generate a Model Optimizer TensorFlow* extractor</li>
<li><code>mo-mxnet-ext</code> to generates a Model Optimizer MXNet* extractor</li>
<li><code>ie-cpu-ext</code> to generate an Inference Engine CPU extension</li>
<li><code>ie-gpu-ext</code> to generate an Inference Engine GPU extension</li>
<li><code>output_dir</code> to set an output directory. If not specified, the current directory is used by default.</li>
</ul>
<p>You can use any combination of the parameters to generate Model Optimizer and/or Inference Engine extension files. For example: </p><div class="fragment"><div class="line">python extgen.py new --mo-caffe-ext --mo-op --ie-cpu-ext</div></div><!-- fragment --><h3>Generating Model Optimizer Extension Files</h3>
<p>To generate Model Optimizer extension files, run the tool in the interactive mode with necessary parameters or in the silent mode with a configuration file. For example, to generate operation and extractor files for a Caffe model in the <code>&lt;output_directory&gt;</code> in the interactive mode, run the following command:</p>
<div class="fragment"><div class="line">python extgen.py new --mo-op --mo-caffe-ext --output_dir &lt;output_dir&gt;</div></div><!-- fragment --><p>The extension stub files are generated in the <code>&lt;output_dir&gt;/user_mo_extensions</code> directory, which has the following structure:</p>
<ul>
<li><code>/front</code><ul>
<li><code>/caffe</code> - Folder with Caffe extractors</li>
<li><code>/mxnet</code> - Folder with MXNet extractors</li>
<li><code>/tf</code> - Folder with TensorFlow extractors</li>
</ul>
</li>
<li><code>/ops</code> - Folder with operation files</li>
</ul>
<p>Specific paths to the generated files appear on the screen. For example, for the Caffe* <code>Proposal</code> layer, the files are <code>&lt;output_dir&gt;/user_mo_extensions/front/caffe/proposal_ext.py</code> and <code>&lt;output_dir&gt;/user_mo_extensions/ops/proposal.py</code>.</p>
<p>Usually, you can use an extractor file without changes. Exceptions are the cases when you want to transform parameters from a input file in the IR. In this case, you should add these transformations to the <code>extract</code> method. Do not forget to add parameter names to the <code>supported_attrs</code> and <code>backend_attrs</code> methods to the operation file.</p>
<p>An operation file can be used without changes if your layer does not change the shape. Otherwise, you should implement the shape calculation in the <code>&lt;op_name&gt;_infer</code> method. Also, you can add default values to the <code>__init__</code> method. You can find more details in the <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_with_New_Primitives.html">Extending Model Optimizer with New Primitives</a>.</p>
<h3>Generating Inference Engine Extension Files</h3>
<p>To generate stub files for GPU and CPU Inference Engine extensions, run the tool and provide input information interactively or in the configuration file. For example, to generate an Inference Engine CPU extension files in the <code>&lt;output_directory&gt;</code> in the interactive mode:</p>
<div class="fragment"><div class="line">python extgen.py new --mo-op --mo-caffe-ext --output_dir &lt;output_dir&gt;</div></div><!-- fragment --><p>The extension stub files are generated in the <code>&lt;output_dir&gt;/user_ie_extensions</code> directory.</p>
<p>For CPU, several files are generated in the <code>cpu</code> subdirectory. You must change only <code>&lt;output_dir&gt;/user_ie_extensions/cpu/ext_&lt;op_name&gt;.cpp</code> with adding inference implementation.</p>
<p>For GPU, <code>&lt;op_name&gt;.cl</code> and <code>&lt;op_name&gt;.xml</code> are generated in the <code>gpu</code> subdirectory. You must update both:</p>
<ul>
<li>In <code>&lt;op_name&gt;.cl</code>, implement an OpenCL&trade; kernel to infer the model.</li>
<li>In <code>&lt;op_name&gt;.xml</code>, fill information about input/output buffers and worksize for your kernel.</li>
</ul>
<p>More details about implementing Inference Engine extensions see in <a class="el" href="_docs_IE_DG_Integrate_your_kernels_into_IE.html">Inference Engine Kernels Extensibility</a>.</p>
<h2>Examples of Creating a Custom Layer Extension Using extgen</h2>
<p>This section provides step-by-step examples of extension generation for conversion Caffe* and TensorFlow* models. The Caffe* example describes the Inference Engine extension creation. The TensorFlow* example uses existing Inference Engine operation. If you need Inference Engine extension to infer a TensorFlow-based model, look at steps 6-7 in Caffe* example, because Inference Engine extension generation does not depend on the framework is it based on.</p>
<h3>Caffe* Example</h3>
<p>This section provides a sample for generating and implementing Model Optimizer and Inference Engine custom layer extensions for the <code>Proposal</code> layer of a Caffe* example model. The model (<code>.prototxt</code> and <code>.caffemodel</code>) used in the example is described in the <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_with_New_Primitives.html">Extending Model Optimizer with New Primitives</a> chapter.</p>
<ol type="1">
<li>Go to folder with <code>extgen</code>: <br />
 <div class="fragment"><div class="line">cd &lt;INSTALL_DIR&gt;\deployment_tools\extension_generator\</div></div><!-- fragment --></li>
<li>Running the <code>extgen.py</code> file with the following parameters to generate extension stub files: <br />
 <div class="fragment"><div class="line">python extgen.py new --mo-caffe-ext --mo-op --ie-cpu-ext</div></div><!-- fragment --> The tool asks you to provide input information to generate accurate stub files for extensions. Questions and sample answers are the following:<br />
 a. For generating stub files for Caffe extractor file: <br />
 <div class="fragment"><div class="line">Do you use this operation with Caffe Pythonic layer extractor? (y/n)   y</div><div class="line">Please enter module name:   rpn.proposal_layer</div><div class="line">Please enter layer name:   ProposalLayer</div></div><!-- fragment --> <br />
 b. For generating a Model Optimizer operation file: <br />
 <div class="fragment"><div class="line">Please enter operation name:    Proposal</div><div class="line">Does your operation change shape? (y/n)    y</div><div class="line">Do you want to implement shape calculation? (y/n)</div><div class="line">    If you choose &#39;n&#39; framework fallback will be used for shape calculation    y</div></div><!-- fragment --> <br />
 c. For generating an Inference Engine CPU extension: <br />
 <div class="fragment"><div class="line">Please enter operation name:    Proposal</div><div class="line">Please enter all parameters in format</div><div class="line">&lt;param1&gt; &lt;type&gt;</div><div class="line">&lt;param2&gt; &lt;type&gt;</div><div class="line">etc</div><div class="line">Supported cpu types: int, bool, listint, float, listfloat, string</div><div class="line">When you finish please enter &#39;q&#39;</div><div class="line">feat_stride int</div><div class="line">post_nms_topn int</div><div class="line">q</div></div><!-- fragment --></li>
<li>Find the generated files in the <code>./user_mo_extensions</code> and <code>./user_ie_extensions</code> directories, which have the following structure:<ul>
<li><code>/user_mo_extensions</code><ul>
<li><code>__init__.py</code></li>
<li><code>/front</code><ul>
<li><code>/caffe</code><ul>
<li><code>__init__.py</code></li>
<li><code>proposallayer_ext.py</code></li>
</ul>
</li>
<li><code>/mxnet</code><ul>
<li><code>__init__.py</code></li>
</ul>
</li>
</ul>
</li>
<li><code>/ops</code><ul>
<li><code>__init__.py</code></li>
<li><code>proposal.py</code></li>
</ul>
</li>
</ul>
</li>
<li><code>/user_ie_extensions</code><ul>
<li><code>/cpu</code><ul>
<li><code>CMakeLists.txt</code></li>
<li><code>ext_base.cpp</code></li>
<li><code>ext_base.hpp</code></li>
<li><code>ext_lists.cpp</code></li>
<li><code>ext_lists.hpp</code></li>
<li><code>ext_proposal.cpp</code></li>
</ul>
</li>
<li><code>/gpu</code></li>
</ul>
</li>
</ul>
</li>
<li><p class="startli">Implement extension functions in the generated files:</p>
<p class="startli">a. Extractor <code>proposallayer_ext.py</code> can be used without changes.</p>
<p class="startli">b. Add the shape calculation logic to the operation file <code>proposal.py</code>. According to <a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">IR catalog</a>, the 'Proposal' layer shape dynamically depends on the <em>post_nms_topn</em> parameter. <br />
 Add this parameter with the default value in <code>__init__</code> method: </p><div class="fragment"><div class="line"><span class="keyword">def </span>__init__(self, graph, attrs):</div><div class="line">    mandatory_props = dict(</div><div class="line">        type=__class__.op,</div><div class="line">        op=__class__.op,</div><div class="line">        post_nms_topn=300,</div><div class="line">        infer=ProposalPythonOp.infer</div><div class="line">    )</div><div class="line">    super().__init__(graph, mandatory_props, attrs)</div></div><!-- fragment --><p> <br />
 Then add supported attributes in the method <code>supported_attrs</code>: </p><div class="fragment"><div class="line"><span class="keyword">def </span>supported_attrs(self):</div><div class="line">    <span class="comment"># =====================================</span></div><div class="line">    <span class="comment"># List all attributes of the layer</span></div><div class="line">    <span class="comment"># all other attributes that are not in</span></div><div class="line">    <span class="comment"># the list are ignored</span></div><div class="line">    <span class="comment"># =====================================</span></div><div class="line">    <span class="keywordflow">return</span> [</div><div class="line">        <span class="stringliteral">&#39;feat_stride&#39;</span>,</div><div class="line">        <span class="stringliteral">&#39;post_nms_topn&#39;</span></div><div class="line">    ]</div></div><!-- fragment --><p> <br />
 Now add shape calculation in <code>infer</code> function: </p><div class="fragment"><div class="line">@staticmethod</div><div class="line"><span class="keyword">def </span>infer(node):</div><div class="line">    input_shape = node.in_node(0).shape</div><div class="line">    out_shape = np.array([0, 0], dtype=np.int64)</div><div class="line">    <span class="comment"># rois blob: holds R regions of interest, each is a 5 - tuple</span></div><div class="line">    <span class="comment"># (n, x1, y1, x2, y2) specifying an image batch index n and a</span></div><div class="line">    <span class="comment"># rectangle(x1, y1, x2, y2)</span></div><div class="line">    out_shape[0] = input_shape[0] * node.post_nms_topn</div><div class="line">    out_shape[1] = 5</div><div class="line">    node.out_node(0).shape = out_shape</div></div><!-- fragment --><p> <br />
</p>
</li>
<li>Once you complete these steps, the Model Optimizer extension is ready to use. To run the Model Optimizer with this extension, use the command line below: <div class="fragment"><div class="line">cd ../model_optimizer</div><div class="line">python mo.py --input_model ZF_faster_rcnn_final.caffemodel --input_proto test.prototxt --extensions ../extension_generator/user_mo_extensions/</div></div><!-- fragment --></li>
<li>To complete the CPU Inference Engine extension creation, add the implementation of the <code>Proposal</code> layer inference to the <code>execute</code> method in the <code>ext_proposal.cpp</code> file. You can find sample code for this extension in the <code>&lt;INSTALL_DIR&gt;/deployment_tools/inference_engine/samples/extension/ext_proposal.cpp</code> file. For more information about implementation of Inference Engine extensions, refer to <a class="el" href="_docs_IE_DG_Integrate_your_kernels_into_IE.html">Inference Engine Kernels Extensibility</a>.</li>
<li><p class="startli">Build a library with CPU extension to use it with the Inference Engine:</p>
<p class="startli">a. Create a new build directory: <br />
 </p><div class="fragment"><div class="line">mkdir build</div></div><!-- fragment --><p> b. Go to the created build directory: <br />
 </p><div class="fragment"><div class="line">cd ./build</div></div><!-- fragment --><p> c. Set the environment variables: <br />
 </p><div class="fragment"><div class="line">#on Linux OS:</div><div class="line">source &lt;INSTALL_DIR&gt;/bin/setupvars.sh</div><div class="line"></div><div class="line">#on Windows OS:</div><div class="line">&lt;INSTALL_DIR&gt;/bin/setupvars.bat</div></div><!-- fragment --><p> d. Run CMake to generate the Make files: <br />
 </p><div class="fragment"><div class="line">#on Linux OS:</div><div class="line">cmake ..</div><div class="line"></div><div class="line">#on Windows OS:</div><div class="line">cmake -G &quot;&lt;VisualStudio* version&gt;&quot;..</div></div><!-- fragment --><p> e. Build the library: <br />
 </p><div class="fragment"><div class="line">#on Linux OS:</div><div class="line">make</div><div class="line"></div><div class="line">#on Windows OS: use the generated Microsoft Visual Studio* project</div></div><!-- fragment --></li>
</ol>
<h3>TensorFlow* Example</h3>
<p>This section provides an example for generating and implementing Model Optimizer extension on TensorFlow* example model.</p>
<p>If you already have a model with unrecognized operation, you can omit Model Preparation and go to <a href="#ExtGenTF">Extension Generation</a> chapter.</p>
<p>In example the <code>Pooling</code> layer will be used to illustrate extension generation. ModelOptimizer already supports this layer but we will remove it and show how it can be created with <code>extgen</code> tool. This process described in Model Preparation chapter.</p>
<p>Operation and Inference engine extension generation does not depend on framework and was demonstrated already in Caffe example, so here only TensorFlow extractor generation will be done.</p>
<h4>Model Preparation</h4>
<ol type="1">
<li>Downlowad the pre-trained model <code>ResNet-50</code> from <a href="https://github.com/tensorflow/models/tree/master/official/resnet">TensorFlow* Model Zoo</a>. Follow the instructions in <a class="el" href="_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">Convert Model From TensorFlow*</a> to prepare the model for converting.</li>
<li>If you try to convert the <code>ResNet-50</code> model, it will be converted successfully. To demonstrate extension generation, remove the existing implementation of <code>Pooling</code> layer from the Model Optimizer: <br />
 <div class="fragment"><div class="line">cd &lt;INSTALL_DIR&gt;/deploymment_tools/model_optimizer</div><div class="line">move extensions/front/tf/pooling_ext.py extensions/front/tf/pooling_ext.py_del</div></div><!-- fragment --></li>
<li>Run ModelOptimizer to be sure that MaxPool become unrecognized operation: <br />
 <div class="fragment"><div class="line">python mo.py --input_model resnet50.pb --input_shape [1,3,224,224]</div></div><!-- fragment --> You should see an error: <br />
 <div class="fragment"><div class="line">[ ERROR ]  List of operations that cannot be converted to IE IR:</div><div class="line">[ ERROR ]      MaxPool (4)</div><div class="line">[ ERROR ]          resnet50/pool1/MaxPool</div><div class="line">[ ERROR ]          resnet50/block1/unit_3/bottleneck_v1/shortcut/MaxPool</div><div class="line">[ ERROR ]          resnet50/block2/unit_4/bottleneck_v1/shortcut/MaxPool</div><div class="line">[ ERROR ]          resnet50/block3/unit_6/bottleneck_v1/shortcut/MaxPool</div><div class="line">[ ERROR ]  Part of the nodes was not translated to IE. Stopped.</div><div class="line"> For more information please refer to Model Optimizer FAQ (&lt;INSTALL_DIR&gt;/deployment_tools/documentation/docs/MO_FAQ.html), question #24.</div></div><!-- fragment --></li>
</ol>
<p>Now the sample model is ready for extension generation.</p>
<h4>Extension Generation <a class="anchor" id="ExtGenTF"></a></h4>
<ol type="1">
<li>Go to extension generator directory: <br />
 <div class="fragment"><div class="line">cd &lt;INSTALL_DIR&gt;/deployment_tools/extension_generator</div></div><!-- fragment --></li>
<li>Run the <code>extgen.py</code> file with the following parameters to generate extension stub files : <br />
 <div class="fragment"><div class="line">python extgen.py new --mo-tf-ext</div></div><!-- fragment --> <br />
The tool asks you to provide input information to generate accurate stub files for extensions. Questions and sample answers are the following:<br />
 a. For generating stub files for TensorFlow* extractor file: <br />
 <div class="fragment"><div class="line">Please enter layer name:       Pooling</div><div class="line">Do you want automatically parse all parameters from proto file</div><div class="line">   (parameters will be parsed as is, without any renaming or omitting) (y/n)       n</div><div class="line">Please enter all parameters in format</div><div class="line">   &lt;param1&gt; &lt;new name1&gt; &lt;type1&gt;</div><div class="line">   &lt;param2&gt; &lt;new name2&gt; &lt;type2&gt;</div><div class="line">   etc</div><div class="line">   where type is one of the following types:</div><div class="line">   s - String, i - Int, f - Float, b - Bool, type - DataType, shape - TensorShapeProto,</div><div class="line">   padding - Padding type, spatial - Get spatial from dataFormat, channel - Get channel from dataFormat,</div><div class="line">   batch - Get batch from dataFormat, list.s - List of strings, list.i - List of ints, list.f - List of floats,</div><div class="line">   list.b - list of bools, list.type - list of DataType, list.shape - list of TensorShapeProto,</div><div class="line">   if your attribute type is not in list or you want implement your own attribute parsing just omit &lt;type&gt;</div><div class="line">   When you finish please enter &#39;q&#39;</div><div class="line">padding auto_pad padding</div><div class="line">ksize window list.i</div><div class="line">data_format spatial_dims spatial</div><div class="line">strides stride list.i</div><div class="line">q</div><div class="line">Please enter operation name to use with this extractor:       MaxPool</div><div class="line">Please enter class with operation to use with this extractor:       Pooling</div><div class="line">Please enter import path to class with operation:       extensions.ops.pooling</div></div><!-- fragment --> <br />
</li>
<li>Find the generated files in the <code>user_mo_extensions</code> directory, which has the following structure:<ul>
<li><code>/user_mo_extensions</code><ul>
<li><code>__init__.py</code></li>
<li><code>/front</code><ul>
<li><code>/caffe</code><ul>
<li><code>__init__.py</code></li>
</ul>
</li>
<li><code>/mxnet</code><ul>
<li><code>__init__.py</code></li>
</ul>
</li>
<li><code>/tf</code><ul>
<li><code>__init__.py</code></li>
<li><code>pooling_ext.py</code></li>
</ul>
</li>
</ul>
</li>
<li><code>/ops</code><ul>
<li><code>__init__.py</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p class="startli">Implement extension functions in the generated files:</p>
<p class="startli">a. The extractor <code>pooling_ext.py</code> requires additional attribute conversion. Several attributes should be initialized by constants, real values will be calculated during inference. These changes are needed because we use existing operation that was written for several frameworks. <br />
 </p><div class="fragment"><div class="line">@staticmethod</div><div class="line"><span class="keyword">def </span>extract(node):</div><div class="line">    proto_layer = node.pb</div><div class="line">    param = proto_layer.attr</div><div class="line">    attrs = {</div><div class="line">        <span class="stringliteral">&#39;auto_pad&#39;</span>:convert_tf_padding_to_str(param[<span class="stringliteral">&quot;padding&quot;</span>]),</div><div class="line">        <span class="stringliteral">&#39;window&#39;</span>:param[<span class="stringliteral">&quot;ksize&quot;</span>].list.i,</div><div class="line">        <span class="stringliteral">&#39;spatial_dims&#39;</span>:tf_data_format_spatial(param[<span class="stringliteral">&quot;data_format&quot;</span>]),</div><div class="line">        <span class="stringliteral">&#39;stride&#39;</span>:param[<span class="stringliteral">&quot;strides&quot;</span>].list.i,</div><div class="line">        <span class="stringliteral">&#39;op&#39;</span>: __class__.op</div><div class="line">    }</div><div class="line">    attrs[<span class="stringliteral">&#39;window&#39;</span>] = np.array(attrs[<span class="stringliteral">&#39;window&#39;</span>])</div><div class="line">    attrs[<span class="stringliteral">&#39;pad&#39;</span>] = <span class="keywordtype">None</span></div><div class="line">    attrs[<span class="stringliteral">&#39;stride&#39;</span>] = np.array(attrs[<span class="stringliteral">&#39;stride&#39;</span>])</div><div class="line">    attrs[<span class="stringliteral">&#39;pad_spatial_shape&#39;</span>] = <span class="keywordtype">None</span></div><div class="line">    attrs[<span class="stringliteral">&#39;output_spatial_shape&#39;</span>] = <span class="keywordtype">None</span></div><div class="line">    attrs[<span class="stringliteral">&#39;pool_method&#39;</span>]=<span class="stringliteral">&#39;max&#39;</span></div><div class="line">    attrs[<span class="stringliteral">&#39;type&#39;</span>] = <span class="stringliteral">&#39;Pooling&#39;</span></div><div class="line">    attrs[<span class="stringliteral">&#39;exclude_pad&#39;</span>] = <span class="stringliteral">&#39;true&#39;</span></div><div class="line"></div><div class="line">    <span class="comment"># update the attributes of the node</span></div><div class="line">    Op.get_op_class_by_name(__class__.op).update_node_stat(node, attrs)</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> __class__.enabled</div></div><!-- fragment --></li>
<li>Once you complete these steps, the Model Optimizer extension is ready to use. To run the Model Optimizer with this extension, use the command line below: <br />
 <div class="fragment"><div class="line">cd ../model_optimizer</div><div class="line">python mo.py --input_model resnet50.pb --input_shape [1,3,224,224] --extensions ../extension_generator/user_mo_extensions</div></div><!-- fragment --></li>
</ol>
<p>Conversion should finish successfully. </p>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>