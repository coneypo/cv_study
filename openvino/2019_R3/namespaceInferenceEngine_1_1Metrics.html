<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>InferenceEngine::Metrics Namespace Reference - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceInferenceEngine.html">InferenceEngine</a></li><li class="navelem"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html">Metrics</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">InferenceEngine::Metrics Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Metrics  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a04ce5d4fb24fde259b329caffa358fa5"><td class="memItemLeft" align="right" valign="top"><a id="a04ce5d4fb24fde259b329caffa358fa5"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a04ce5d4fb24fde259b329caffa358fa5">METRIC_AVAILABLE_DEVICES</a> = &quot;AVAILABLE_DEVICES&quot;</td></tr>
<tr class="memdesc:a04ce5d4fb24fde259b329caffa358fa5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of available device IDs. String value is "AVAILABLE_DEVICES". <br /></td></tr>
<tr class="separator:a04ce5d4fb24fde259b329caffa358fa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a67a2c5ea1cb1ea7d42c71b8bf0d0b97d">METRIC_SUPPORTED_METRICS</a> = &quot;SUPPORTED_METRICS&quot;</td></tr>
<tr class="memdesc:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of supported metrics. String value is "SUPPORTED_METRICS" This can be used as an executable network metric as well.  <a href="#a67a2c5ea1cb1ea7d42c71b8bf0d0b97d">More...</a><br /></td></tr>
<tr class="separator:a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a41d90ac79d73d8706ae2e9eb46a673a1">METRIC_SUPPORTED_CONFIG_KEYS</a> = &quot;SUPPORTED_CONFIG_KEYS&quot;</td></tr>
<tr class="memdesc:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of supported config keys. String value is "SUPPORTED_CONFIG_KEYS" This can be used as an executable network metric as well.  <a href="#a41d90ac79d73d8706ae2e9eb46a673a1">More...</a><br /></td></tr>
<tr class="separator:a41d90ac79d73d8706ae2e9eb46a673a1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33c5772e0e22fab7b981cb33c2820f32"><td class="memItemLeft" align="right" valign="top"><a id="a33c5772e0e22fab7b981cb33c2820f32"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a33c5772e0e22fab7b981cb33c2820f32">METRIC_FULL_DEVICE_NAME</a> = &quot;FULL_DEVICE_NAME&quot;</td></tr>
<tr class="memdesc:a33c5772e0e22fab7b981cb33c2820f32"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::string value representing a full device name. String value is "FULL_DEVICE_NAME". <br /></td></tr>
<tr class="separator:a33c5772e0e22fab7b981cb33c2820f32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54ebc63520c179a5854f5a199d24e1d2"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a54ebc63520c179a5854f5a199d24e1d2">METRIC_OPTIMIZATION_CAPABILITIES</a> = &quot;OPTIMIZATION_CAPABILITIES&quot;</td></tr>
<tr class="memdesc:a54ebc63520c179a5854f5a199d24e1d2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a std::vector&lt;std::string&gt; of optimization options per device. String value is "OPTIMIZATION_CAPABILITIES" The possible values:  <a href="#a54ebc63520c179a5854f5a199d24e1d2">More...</a><br /></td></tr>
<tr class="separator:a54ebc63520c179a5854f5a199d24e1d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a33f8ec1373b4a3550b87abf3a7773aa2"><td class="memItemLeft" align="right" valign="top"><a id="a33f8ec1373b4a3550b87abf3a7773aa2"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>FP32</b> = &quot;FP32&quot;</td></tr>
<tr class="separator:a33f8ec1373b4a3550b87abf3a7773aa2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45ef215735092ccc913e9d6c54cfb226"><td class="memItemLeft" align="right" valign="top"><a id="a45ef215735092ccc913e9d6c54cfb226"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>FP16</b> = &quot;FP16&quot;</td></tr>
<tr class="separator:a45ef215735092ccc913e9d6c54cfb226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad31c07cfba5d2d2859af67742ca5a89b"><td class="memItemLeft" align="right" valign="top"><a id="ad31c07cfba5d2d2859af67742ca5a89b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>INT8</b> = &quot;INT8&quot;</td></tr>
<tr class="separator:ad31c07cfba5d2d2859af67742ca5a89b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a888cf88b6ec040a80dc63b4995be2b0a"><td class="memItemLeft" align="right" valign="top"><a id="a888cf88b6ec040a80dc63b4995be2b0a"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>BIN</b> = &quot;BIN&quot;</td></tr>
<tr class="separator:a888cf88b6ec040a80dc63b4995be2b0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a765ae7767f0eca6abc8dfaa67ce5d2ee"><td class="memItemLeft" align="right" valign="top"><a id="a765ae7767f0eca6abc8dfaa67ce5d2ee"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>WINOGRAD</b> = &quot;WINOGRAD&quot;</td></tr>
<tr class="separator:a765ae7767f0eca6abc8dfaa67ce5d2ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39f21cea314e4a122b857d4112be2eb1"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a39f21cea314e4a122b857d4112be2eb1">METRIC_RANGE_FOR_STREAMS</a> = &quot;RANGE_FOR_STREAMS&quot;</td></tr>
<tr class="memdesc:a39f21cea314e4a122b857d4112be2eb1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to provide information about a range for streams on platforms where streams are supported. Metric returns a value of std::tuple&lt;unsigned int, unsigned int&gt; type, where:  <a href="#a39f21cea314e4a122b857d4112be2eb1">More...</a><br /></td></tr>
<tr class="separator:a39f21cea314e4a122b857d4112be2eb1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4335554dc78de02b95418bb29ade2831"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a4335554dc78de02b95418bb29ade2831">METRIC_RANGE_FOR_ASYNC_INFER_REQUESTS</a> = &quot;RANGE_FOR_ASYNC_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a4335554dc78de02b95418bb29ade2831"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to provide a hint for a range for number of async infer requests. If device supports streams, the metric provides range for number of IRs per stream. Metric returns a value of std::tuple&lt;unsigned int, unsigned int, unsigned int&gt; type, where:  <a href="#a4335554dc78de02b95418bb29ade2831">More...</a><br /></td></tr>
<tr class="separator:a4335554dc78de02b95418bb29ade2831"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="memItemLeft" align="right" valign="top"><a id="a4cc6b8c1b548fad1e03ea2a897b15400"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a4cc6b8c1b548fad1e03ea2a897b15400">METRIC_NUMBER_OF_WAITING_INFER_REQUESTS</a> = &quot;NUMBER_OF_WAITING_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned int value of number of waiting infer request. String value is "NUMBER_OF_WAITNING_INFER_REQUESTS". This can be used as an executable network metric as well. <br /></td></tr>
<tr class="separator:a4cc6b8c1b548fad1e03ea2a897b15400"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="memItemLeft" align="right" valign="top"><a id="a8bb4bb50ecf459e83f2dec54e5506e0b"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a8bb4bb50ecf459e83f2dec54e5506e0b">METRIC_NUMBER_OF_EXEC_INFER_REQUESTS</a> = &quot;NUMBER_OF_EXEC_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned int value of number of infer request in execution stage. String value is "NUMBER_OF_EXEC_INFER_REQUESTS". This can be used as an executable network metric as well. <br /></td></tr>
<tr class="separator:a8bb4bb50ecf459e83f2dec54e5506e0b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8a47d4063517a77764b632962d4cc8d"><td class="memItemLeft" align="right" valign="top"><a id="ac8a47d4063517a77764b632962d4cc8d"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#ac8a47d4063517a77764b632962d4cc8d">METRIC_NETWORK_NAME</a> = &quot;NETWORK_NAME&quot;</td></tr>
<tr class="memdesc:ac8a47d4063517a77764b632962d4cc8d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a name of network. String value is "NETWORK_NAME". <br /></td></tr>
<tr class="separator:ac8a47d4063517a77764b632962d4cc8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="memItemLeft" align="right" valign="top"><a id="a2f746c0fabfb75a6fced6cf394cb9b2e"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a2f746c0fabfb75a6fced6cf394cb9b2e">METRIC_DEVICE_THERMAL</a> = &quot;DEVICE_THERMAL&quot;</td></tr>
<tr class="memdesc:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get a float of device thermal. String value is "DEVICE_THERMAL". <br /></td></tr>
<tr class="separator:a2f746c0fabfb75a6fced6cf394cb9b2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57a821fbccfb015f161e00b805415a58"><td class="memItemLeft" align="right" valign="top"><a id="a57a821fbccfb015f161e00b805415a58"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceInferenceEngine_1_1Metrics.html#a57a821fbccfb015f161e00b805415a58">METRIC_OPTIMAL_NUMBER_OF_INFER_REQUESTS</a> = &quot;OPTIMAL_NUMBER_OF_INFER_REQUESTS&quot;</td></tr>
<tr class="memdesc:a57a821fbccfb015f161e00b805415a58"><td class="mdescLeft">&#160;</td><td class="mdescRight">Metric to get an unsigned integer value of optimal number of executable network infer requests. <br /></td></tr>
<tr class="separator:a57a821fbccfb015f161e00b805415a58"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Metrics </p>
</div><h2 class="groupheader">Variable Documentation</h2>
<a id="a54ebc63520c179a5854f5a199d24e1d2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54ebc63520c179a5854f5a199d24e1d2">&sect;&nbsp;</a></span>METRIC_OPTIMIZATION_CAPABILITIES</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr auto InferenceEngine::Metrics::METRIC_OPTIMIZATION_CAPABILITIES = &quot;OPTIMIZATION_CAPABILITIES&quot;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Metric to get a std::vector&lt;std::string&gt; of optimization options per device. String value is "OPTIMIZATION_CAPABILITIES" The possible values: </p>
<ul>
<li>"FP32" - device can support FP32 models</li>
<li>"FP16" - device can support FP16 models</li>
<li>"INT8" - device can support models with INT8 layers</li>
<li>"BIN" - device can support models with BIN layers</li>
<li>"WINOGRAD" - device can support models where convolution implemented via Winograd transformations </li>
</ul>

</div>
</div>
<a id="a4335554dc78de02b95418bb29ade2831"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4335554dc78de02b95418bb29ade2831">&sect;&nbsp;</a></span>METRIC_RANGE_FOR_ASYNC_INFER_REQUESTS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr auto InferenceEngine::Metrics::METRIC_RANGE_FOR_ASYNC_INFER_REQUESTS = &quot;RANGE_FOR_ASYNC_INFER_REQUESTS&quot;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Metric to provide a hint for a range for number of async infer requests. If device supports streams, the metric provides range for number of IRs per stream. Metric returns a value of std::tuple&lt;unsigned int, unsigned int, unsigned int&gt; type, where: </p>
<ul>
<li>First value is bottom bound.</li>
<li>Second value is upper bound.</li>
<li>Third value is step inside this range. String value for metric name is "RANGE_FOR_ASYNC_INFER_REQUESTS". </li>
</ul>

</div>
</div>
<a id="a39f21cea314e4a122b857d4112be2eb1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39f21cea314e4a122b857d4112be2eb1">&sect;&nbsp;</a></span>METRIC_RANGE_FOR_STREAMS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr auto InferenceEngine::Metrics::METRIC_RANGE_FOR_STREAMS = &quot;RANGE_FOR_STREAMS&quot;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Metric to provide information about a range for streams on platforms where streams are supported. Metric returns a value of std::tuple&lt;unsigned int, unsigned int&gt; type, where: </p>
<ul>
<li>First value is bottom bound.</li>
<li>Second value is upper bound. String value for metric name is "RANGE_FOR_STREAMS". </li>
</ul>

</div>
</div>
<a id="a41d90ac79d73d8706ae2e9eb46a673a1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41d90ac79d73d8706ae2e9eb46a673a1">&sect;&nbsp;</a></span>METRIC_SUPPORTED_CONFIG_KEYS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr auto InferenceEngine::Metrics::METRIC_SUPPORTED_CONFIG_KEYS = &quot;SUPPORTED_CONFIG_KEYS&quot;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Metric to get a std::vector&lt;std::string&gt; of supported config keys. String value is "SUPPORTED_CONFIG_KEYS" This can be used as an executable network metric as well. </p>
<p>Each of the returned device configuration keys can be passed to <a class="el" href="classInferenceEngine_1_1Core.html#a268e2d24595061e9d804460cc6ca9ad3" title="Sets configuration for device, acceptable keys can be found in ie_plugin_config.hpp. ">Core::SetConfig</a>, <a class="el" href="classInferenceEngine_1_1Core.html#a415077386694f95b57e4cccb0d334a55" title="Gets configuration dedicated to device behaviour. The method is targeted to extract information which...">Core::GetConfig</a>, and <a class="el" href="classInferenceEngine_1_1Core.html#afcd1cc386d0ef3d2d33c6bf7d447d5ff" title="Creates an executable network from a network object. Users can create as many networks as they need a...">Core::LoadNetwork</a>, configuration keys for executable networks can be passed to <a class="el" href="classInferenceEngine_1_1ExecutableNetwork.html#aa1ed6418b25be96a413c452ca8c1480a">ExecutableNetwork::SetConfig</a> and <a class="el" href="classInferenceEngine_1_1ExecutableNetwork.html#af43953e9d84965914d1ce50f90480145" title="Gets configuration for current executable network. ">ExecutableNetwork::GetConfig</a>. </p>

</div>
</div>
<a id="a67a2c5ea1cb1ea7d42c71b8bf0d0b97d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a67a2c5ea1cb1ea7d42c71b8bf0d0b97d">&sect;&nbsp;</a></span>METRIC_SUPPORTED_METRICS</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">constexpr auto InferenceEngine::Metrics::METRIC_SUPPORTED_METRICS = &quot;SUPPORTED_METRICS&quot;</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Metric to get a std::vector&lt;std::string&gt; of supported metrics. String value is "SUPPORTED_METRICS" This can be used as an executable network metric as well. </p>
<p>Each of the returned device metrics can be passed to <a class="el" href="classInferenceEngine_1_1Core.html#ada42cbc50479ccab13bd16d3c6eba885" title="Gets general runtime metric for dedicated hardware. The method is needed to request common device pro...">Core::GetMetric</a>, executable network metrics can be passed to <a class="el" href="classInferenceEngine_1_1ExecutableNetwork.html#a5b38590cad3a68144c679af5f5a6090d">ExecutableNetwork::GetMetric</a>. </p>

</div>
</div>
</div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>