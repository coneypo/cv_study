<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>INT8 Quantization - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">INT8 Quantization </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The ability to lower the precision of a model from FP32 to INT8 is built into the DL Workbench application. This process is called quantization and it is a great practice to accelerate the performance of certain models on hardware that supports INT8. An INT8 model takes up less memory footprint and speeds up inference time. However, this comes at the cost of a small reduction in accuracy.</p>
<p>When INT8 is selected from the <b>Optimize</b> tab, DL Workbench automatically quantizes the selected model to INT8 by running a calibration procedure and then generating a quantized version of the model.</p>
<p>To read more about INT8 inference, refer to <a class="el" href="_docs_IE_DG_Int8Inference.html">Using Low-Precision INT8 Integer Inference</a> and <a class="el" href="_inference_engine_tools_calibration_tool_README.html">DLDT Calibration Tool</a> (the tool calibrates a model prior to quantization to INT8).</p>
<blockquote class="doxtable">
<p><b>NOTE:</b> INT8 quantization is <b>not</b> available for projects that use a generated dataset, or either a generic or an OpenVINO&trade; model. </p>
</blockquote>
<p>The overall flow for converting a model from FP32 to INT8 is:</p>
<ol type="1">
<li><a class="el" href="_docs_Workbench_DG_Select_Models.html">Select an FP32 model</a></li>
<li><a class="el" href="_docs_Workbench_DG_Select_Datasets.html">Select an appropriate dataset</a></li>
<li><a class="el" href="_docs_Workbench_DG_Work_with_Models_and_Sample_Datasets.html">Run a baseline inference</a></li>
<li><a href="#8-bit-config">Configure INT8 calibration settings</a></li>
<li><a class="el" href="_docs_Workbench_DG_Run_Single_Inference.html">Configure inference settings for a calibrated model</a></li>
<li><a href="#review-calibration-progess">View INT8 calibration</a></li>
<li><a class="el" href="_docs_Workbench_DG_View_Inference_Results.html">View inference results</a></li>
<li><a class="el" href="_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">Compare the calibrated model with the original FP32 model</a></li>
</ol>
<p>Only some convolution models in the FP32 format can be quantized to INT8. If your model is incompatible, you will receive an error message. You can find more details on error conditions and solution paths in <a class="el" href="_docs_Workbench_DG_Troubleshooting.html">Troubleshooting</a>.</p>
<p>Use the links above to walk through the steps and workflow for creating a calibrated model. Topics specific <b>only</b> to the INT8 calibration process (steps 4 and 6, above) are described below.</p>
<blockquote class="doxtable">
<p><b>Note</b>: There are command-line alternatives to calibrating and quantizing models. For more information, refer to the <a class="el" href="_inference_engine_tools_calibration_tool_README.html">Calibration tool</a> documentation. </p>
</blockquote>
<h2><a class="anchor" id="8-bit-config"></a> Configure INT8 Calibration Settings </h2>
<p>Once a model has been profiled by the DL Workbench, you can convert it from FP32 to to INT8. For non-FP32 models, the INT8 option will be grayed out.</p>
<div class="image">
<img src="int8_config-b.jpeg" alt="int8_config-b.jpeg"/>
</div>
<blockquote class="doxtable">
<p><b>NOTE:</b> Using INT8 quantization, you can tune only an original (top-level) model. </p>
</blockquote>
<p>Select the <b>Optimize</b> tab, and then check <b>Int 8</b> .</p>
<p>Specify the following parameters:</p><ul>
<li><b>Maximum Accuracy Drop</b>: You can instruct the application to only convert layers that do not exceed the maximum amount of accuracy drop you are willing to sacrifice. If a layer is estimated to exceed this value, it will remain at the original precision and not be quantized.</li>
<li><b>Subset of Images</b>: Specify the percent of images you will use during the calibration procedure. The default value is 100%.</li>
</ul>
<h2><a class="anchor" id="review-calibration-progess"></a> View INT8 Calibration </h2>
<p>Click <b>Optimize</b> and a new row appears for your model.</p>
<div class="image">
<img src="int8_status-b.png" alt="int8_status-b.png"/>
</div>
<h2><a class="anchor" id="review-calibration-progess"></a> View INT8 Calibration Results </h2>
<p>Once the job is done, you can compare an optimized model with the original model. For more details, go to <a class="el" href="_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">Compare Performance between Two Versions of Models</a>.</p>
<p>The value of the <b>outputPrecisions</b> parameter in the <b>Layer Name</b> table for layers of INT8 optimized model is U8 (INT8 unsigned integer value):</p>
<div class="image">
<img src="int8_results-b.png" alt="int8_results-b.png"/>
</div>
 </div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>