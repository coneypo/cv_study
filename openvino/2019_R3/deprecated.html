<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Deprecated List - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Deprecated List </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><dl class="reflist">
<dt><a class="anchor" id="_deprecated000023"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a748b0f06cb8766ae1ef1d9c1647b6048">InferenceEngine::Blob::Blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#ae66c8ccdfa63fd8554c431437fcf15d1" title="Constructor. Creates an empty Blob object with the specified precision. ">Blob::Blob(const TensorDesc &amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000024"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a5b10c2d757486e3f9b3e7528fa2e8b98">InferenceEngine::Blob::Blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#ae66c8ccdfa63fd8554c431437fcf15d1" title="Constructor. Creates an empty Blob object with the specified precision. ">Blob::Blob(const TensorDesc &amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000025"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a65d4f220cce320c1474af8d2b703944d">InferenceEngine::Blob::Blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, const SizeVector &amp;dims)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#ae66c8ccdfa63fd8554c431437fcf15d1" title="Constructor. Creates an empty Blob object with the specified precision. ">Blob::Blob(const TensorDesc &amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000026"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a516e9df025258899e67f7b627bf896d7">InferenceEngine::Blob::Blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#ae66c8ccdfa63fd8554c431437fcf15d1" title="Constructor. Creates an empty Blob object with the specified precision. ">Blob::Blob(const TensorDesc &amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000029"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a42424b05bbe1a95160fe531397c0edce">InferenceEngine::Blob::dims</a>  () const noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#accdd939c62592f28a0ceb64cd60eb62e" title="Returns the tensor description. ">Blob::getTensorDesc</a> and <a class="el" href="classInferenceEngine_1_1TensorDesc.html#aba4c616b6e9ba449da351066dbbf67f6" title="Returns the vector of dimensions. ">InferenceEngine::TensorDesc::getDims</a>.  </dd>
<dt><a class="anchor" id="_deprecated000022"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#ae48f4e76179557852bade76862f26134">InferenceEngine::Blob::layout</a>  () const noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#accdd939c62592f28a0ceb64cd60eb62e" title="Returns the tensor description. ">Blob::getTensorDesc</a> and <a class="el" href="classInferenceEngine_1_1TensorDesc.html#a15364592fc9e6e5d6ddc82b8a9ec7c64" title="Returns the memory layout. ">InferenceEngine::TensorDesc::getLayout</a> to get the current layout  </dd>
<dt><a class="anchor" id="_deprecated000021"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a1025036e79df819deb667f7e89efc244">InferenceEngine::Blob::precision</a>  () const noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#accdd939c62592f28a0ceb64cd60eb62e" title="Returns the tensor description. ">Blob::getTensorDesc</a> and <a class="el" href="classInferenceEngine_1_1TensorDesc.html#aecf8293d63866dc29951153478501105" title="Returns the memory precision. ">InferenceEngine::TensorDesc::getPrecision</a> to get the precision  </dd>
<dt><a class="anchor" id="_deprecated000028"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a27f75ca59de5f9fd5dd6c4f7e455e4a9">InferenceEngine::Blob::Reshape</a>  (const SizeVector &amp;dims, Layout layout=Layout::ANY) noexcept</dt>
<dd>The method works with reversed dimensions. Use <a class="el" href="classInferenceEngine_1_1Blob.html#accdd939c62592f28a0ceb64cd60eb62e" title="Returns the tensor description. ">Blob::getTensorDesc</a> and <a class="el" href="classInferenceEngine_1_1TensorDesc.html#a166e977b7416c755f1a7d6496fc04a7f" title="Reshapes the tensor descriptor. ">InferenceEngine::TensorDesc::reshape</a>.  </dd>
<dt><a class="anchor" id="_deprecated000027"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#a93a3c1e844bf4d757fea920ae309526e">InferenceEngine::Blob::Resize</a>  (const SizeVector &amp;dims, Layout layout=Layout::ANY) noexcept</dt>
<dd>The method works with reversed dimensions. Create a new blob if you want to change a size.  </dd>
<dt><a class="anchor" id="_deprecated000020"></a>Global <a class="el" href="classInferenceEngine_1_1Blob.html#adc2f6fc7702f436c0ea0e481302b0dc6">InferenceEngine::Blob::type</a>  () const noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Blob.html#accdd939c62592f28a0ceb64cd60eb62e" title="Returns the tensor description. ">Blob::getTensorDesc</a> and <a class="el" href="classInferenceEngine_1_1TensorDesc.html#aecf8293d63866dc29951153478501105" title="Returns the memory precision. ">InferenceEngine::TensorDesc::getPrecision</a> to get the precision  </dd>
<dt><a class="anchor" id="_deprecated000068"></a>Global <a class="el" href="classInferenceEngine_1_1CNNLayer.html#a0f6e1da6858f707ee56024232db0397f">InferenceEngine::CNNLayer::GetParamsAsBool</a>  (const char *param, bool def) const</dt>
<dd>Use GetParamAsBool function for that functionality  </dd>
<dt><a class="anchor" id="_deprecated000001"></a>Global <a class="el" href="classInferenceEngine_1_1CNNNetwork.html#a2a50347b2518f6319c17de23ff11de46">InferenceEngine::CNNNetwork::CNNNetwork</a>  (<a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> *actual)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1CNNNetwork.html#a65d11914bffbce3db04dc42ac0b373dd" title="Allows helper class to manage lifetime of network object. ">CNNNetwork::CNNNetwork(std::shared_ptr&lt;ICNNNetwork&gt;)</a> to construct a network  </dd>
<dt><a class="anchor" id="_deprecated000002"></a>Global <a class="el" href="classInferenceEngine_1_1CNNNetwork.html#a80fbfb862936435bab7f8acac12cb4a2">InferenceEngine::CNNNetwork::setTargetDevice</a>  (TargetDevice device)</dt>
<dd>No needs to specify target device to the network. Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> with target device directly  </dd>
<dt><a class="anchor" id="_deprecated000074"></a>Global <a class="el" href="namespaceInferenceEngine.html#af506a3239abdef996709ad0f65d372e1">InferenceEngine::ConvertLayout</a>  (Layout sourceLayout, Layout destLayout, const T *sourceBuffer, T *destBuffer, SizeVector dims)</dt>
<dd>Please use <a class="el" href="classInferenceEngine_1_1TensorDesc.html" title="This class defines Tensor description. ">TensorDesc</a> for conversion  </dd>
<dt><a class="anchor" id="_deprecated000038"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a22b9e7f34d940304ebb76eddbb878891">InferenceEngine::Data::creatorLayer</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#ab1022f52977f1ecb5845425799e706b0">Data::getCreatorLayer</a>  </dd>
<dt><a class="anchor" id="_deprecated000037"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a22beb6fec19c44d4747759dbb886e507">InferenceEngine::Data::dims</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#afb164ba11a7d23143f0fe56620e3e1ad">Data::getDims</a>  </dd>
<dt><a class="anchor" id="_deprecated000040"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a10098f1512e9fdec72e35ec6ada6f9c7">InferenceEngine::Data::inputTo</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#a88d2ca7ea8d141e4706793668d60f745" title="returns child layers in di-graph ">Data::getInputTo</a>  </dd>
<dt><a class="anchor" id="_deprecated000036"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#aea3b125b5618450e64fa509caa90a08d">InferenceEngine::Data::layout</a>  </dt>
<dd>Use Data::getFormat  </dd>
<dt><a class="anchor" id="_deprecated000039"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a1db203f40de7e9cb7e50281e7dd4bce2">InferenceEngine::Data::name</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#a2d9b571389fc77e659f7583cd2436d21">Data::getName</a>  </dd>
<dt><a class="anchor" id="_deprecated000035"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a79c4e40319d6b67d86cfdfac968eccac">InferenceEngine::Data::precision</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#a385ca58fa66dd27a573b00bb3fbb6909" title="Gets a precision type of this Data instance. ">Data::getPrecision</a>  </dd>
<dt><a class="anchor" id="_deprecated000042"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a869fde45d50969fbce8cf009468b119c">InferenceEngine::Data::setBatchSize</a>  (size_t batch_size)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#ae04e2471c0bb9052ebc240ecf4452c48" title="Sets the data dimensions. After the current node is marked as resolved. ">Data::setDims</a> to set batch size.  </dd>
<dt><a class="anchor" id="_deprecated000041"></a>Global <a class="el" href="classInferenceEngine_1_1Data.html#a05ccc8b4379ab65b85482bc3b2270513">InferenceEngine::Data::userObject</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Data.html#a81716bfbcb5ad4221ad7c9be8a616570">Data::getUserObject</a>  </dd>
<dt><a class="anchor" id="_deprecated000048"></a>Global <a class="el" href="namespaceInferenceEngine.html#a65cce715ab48d20c53f4eb570e66bcb9">InferenceEngine::findPlugin</a>  (const <a class="el" href="structInferenceEngine_1_1FindPluginRequest.html" title="Defines a message that contains the InferenceEngine::TargetDevice object to find a plugin for...">FindPluginRequest</a> &amp;req)</dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000049"></a>Global <a class="el" href="namespaceInferenceEngine.html#a4ddd9d5d6a53cefe1d57ddb291b929d5">InferenceEngine::findPlugin</a>  (const <a class="el" href="structInferenceEngine_1_1FindPluginRequest.html" title="Defines a message that contains the InferenceEngine::TargetDevice object to find a plugin for...">FindPluginRequest</a> &amp;req, <a class="el" href="structInferenceEngine_1_1FindPluginResponse.html" title="Defines a message that contains a list of appropriate plugin names. ">FindPluginResponse</a> &amp;result, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept</dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000046"></a>Class <a class="el" href="structInferenceEngine_1_1FindPluginRequest.html">InferenceEngine::FindPluginRequest</a>  </dt>
<dd><p class="startdd">Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated</p>
<p class="enddd"></p>
</dd>
<dt><a class="anchor" id="_deprecated000047"></a>Class <a class="el" href="structInferenceEngine_1_1FindPluginResponse.html">InferenceEngine::FindPluginResponse</a>  </dt>
<dd><p class="startdd">Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated</p>
<p class="enddd"></p>
</dd>
<dt><a class="anchor" id="_deprecated000045"></a>Global <a class="el" href="namespaceInferenceEngine.html#a0f8aa7b7692492425f94a0c5d2b05592">InferenceEngine::getDeviceName</a>  (TargetDevice device)</dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000070"></a>Global <a class="el" href="namespaceInferenceEngine.html#a8094f72bf759c368feda7919ce8ef1d6">InferenceEngine::I_C</a>  </dt>
<dd>Deprecated since provides dims in reverse order  </dd>
<dt><a class="anchor" id="_deprecated000071"></a>Global <a class="el" href="namespaceInferenceEngine.html#a339223ecfcce8b43223fd8c4afff3b57">InferenceEngine::I_H</a>  </dt>
<dd>Deprecated since provides dims in reverse order  </dd>
<dt><a class="anchor" id="_deprecated000069"></a>Global <a class="el" href="namespaceInferenceEngine.html#a5dee71b1ace705d01a7f870ca3e3e0bd">InferenceEngine::I_N</a>  </dt>
<dd>Deprecated since provides dims in reverse order  </dd>
<dt><a class="anchor" id="_deprecated000072"></a>Global <a class="el" href="namespaceInferenceEngine.html#ab49e5f757631ca69371b2056613aad1c">InferenceEngine::I_W</a>  </dt>
<dd>Deprecated since provides dims in reverse order  </dd>
<dt><a class="anchor" id="_deprecated000053"></a>Global <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#a0ac8ac85442ca15673a9e7865a578364">InferenceEngine::ICNNNetwork::getTargetDevice</a>  () const noexcept=0</dt>
<dd>Deprecated since TargetDevice is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000054"></a>Global <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#abe649d332d99d5c6abda004cfe659ad1">InferenceEngine::ICNNNetwork::setBatchSize</a>  (const size_t size) noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac29fc798d8a318f380624bd350b28501" title="Changes the inference batch size. ">ICNNNetwork::setBatchSize(size_t, ResponseDesc*)</a>  </dd>
<dt><a class="anchor" id="_deprecated000052"></a>Global <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html#ac1896dd3645734522b8f2b68a40d3f8e">InferenceEngine::ICNNNetwork::setTargetDevice</a>  (TargetDevice device) noexcept=0</dt>
<dd>Deprecated since TargetDevice is deprecated. Specify target device in <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> directly.  </dd>
<dt><a class="anchor" id="_deprecated000057"></a>Class <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html">InferenceEngine::IHeteroDeviceLoader</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> to work with HETERO device  </dd>
<dt><a class="anchor" id="_deprecated000059"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#a8c73517be3fa58e292f250326de98757">InferenceEngine::IHeteroDeviceLoader::LoadNetwork</a>  (const std::string &amp;device, <a class="el" href="classInferenceEngine_1_1IExecutableNetwork.html#ac04ef0e735335e1e62f6cfcaec533ad2" title="A smart pointer to the current IExecutableNetwork object. ">IExecutableNetwork::Ptr</a> &amp;ret, <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, const std::map&lt; std::string, std::string &gt; &amp;config, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> with HETERO device in <a class="el" href="classInferenceEngine_1_1Core.html#afcd1cc386d0ef3d2d33c6bf7d447d5ff" title="Creates an executable network from a network object. Users can create as many networks as they need a...">InferenceEngine::Core::LoadNetwork</a>.  </dd>
<dt><a class="anchor" id="_deprecated000060"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#abdc5c26fa4da03ae0e82516a469bef4f">InferenceEngine::IHeteroDeviceLoader::QueryNetwork</a>  (const std::string &amp;device, const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html" title="Responce structure encapsulating information about supported layer. ">QueryNetworkResult</a> &amp;res) noexcept</dt>
<dd>Use the <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#abdc5c26fa4da03ae0e82516a469bef4f" title="This function calls plugin function QueryNetwork for the plugin being instantiated in the implementat...">IHeteroDeviceLoader::QueryNetwork</a>  </dd>
<dt><a class="anchor" id="_deprecated000061"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#ab41f0c2fc09361ca3133636f7256a569">InferenceEngine::IHeteroDeviceLoader::QueryNetwork</a>  (const std::string &amp;device, const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, const std::map&lt; std::string, std::string &gt; &amp;config, <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html" title="Responce structure encapsulating information about supported layer. ">QueryNetworkResult</a> &amp;res) noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> with HETERO device in <a class="el" href="classInferenceEngine_1_1Core.html#a4cf4df5766f45bdabd5d9dc85cc82e4b" title="Query device if it supports specified network with specified configuration. ">InferenceEngine::Core::QueryNetwork</a>.  </dd>
<dt><a class="anchor" id="_deprecated000062"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#a661b7f1092480747ee1b6318dd16c519">InferenceEngine::IHeteroDeviceLoader::SetLogCallback</a>  (<a class="el" href="classInferenceEngine_1_1IErrorListener.html" title="This class represents a custom error listener. Plugin consumers can provide it via InferenceEngine::S...">IErrorListener</a> &amp;listener)=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> with HETERO device in <a class="el" href="classInferenceEngine_1_1Core.html#a4cf4df5766f45bdabd5d9dc85cc82e4b" title="Query device if it supports specified network with specified configuration. ">InferenceEngine::Core::QueryNetwork</a>.  </dd>
<dt><a class="anchor" id="_deprecated000058"></a>Class <a class="el" href="classInferenceEngine_1_1IHeteroInferencePlugin.html">InferenceEngine::IHeteroInferencePlugin</a>  </dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> with HETERO mode in LoadNetwork, QueryNetwork, etc  </dd>
<dt><a class="anchor" id="_deprecated000064"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroInferencePlugin.html#a553ac66307ba39c06f645db8d855ba6b">InferenceEngine::IHeteroInferencePlugin::SetAffinity</a>  (<a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, const std::map&lt; std::string, std::string &gt; &amp;config, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html#a4cf4df5766f45bdabd5d9dc85cc82e4b" title="Query device if it supports specified network with specified configuration. ">InferenceEngine::Core::QueryNetwork</a> with HETERO device and <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html#aff431e5d7451f364dee1c1c54ca78333" title="A map of supported layers: ">QueryNetworkResult::supportedLayersMap</a> to set affinities to a network  </dd>
<dt><a class="anchor" id="_deprecated000063"></a>Global <a class="el" href="classInferenceEngine_1_1IHeteroInferencePlugin.html#a82f29da7b5b746fa7d40f094e750d06a">InferenceEngine::IHeteroInferencePlugin::SetDeviceLoader</a>  (const std::string &amp;device, <a class="el" href="classInferenceEngine_1_1IHeteroDeviceLoader.html#ac59c09a8badaa9bd55ed04d6b324bdaa" title="Shared pointer to IHeteroDeviceLoader instance. ">IHeteroDeviceLoader::Ptr</a> loader) noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> to work with HETERO device Registers device loader for the device  </dd>
<dt><a class="anchor" id="_deprecated000079"></a>Global <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#ae49088f17b7a3c48342ded0590f447d2">InferenceEngine::IInferencePlugin::GetPerformanceCounts</a>  (std::map&lt; std::string, InferenceEngineProfileInfo &gt; &amp;perfMap, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) const noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IInferRequest.html" title="This is an interface of asynchronous infer request. ">IInferRequest</a> to get performance measures  </dd>
<dt><a class="anchor" id="_deprecated000077"></a>Global <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a9d2f325d953d4f7fea65ae9f3188022b">InferenceEngine::IInferencePlugin::Infer</a>  (const <a class="el" href="classInferenceEngine_1_1Blob.html" title="This class represents a universal container in the Inference Engine. ">Blob</a> &amp;input, <a class="el" href="classInferenceEngine_1_1Blob.html" title="This class represents a universal container in the Inference Engine. ">Blob</a> &amp;result, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept=0</dt>
<dd>Load <a class="el" href="classInferenceEngine_1_1IExecutableNetwork.html" title="This is an interface of an executable network. ">IExecutableNetwork</a> to create <a class="el" href="classInferenceEngine_1_1IInferRequest.html" title="This is an interface of asynchronous infer request. ">IInferRequest</a>  </dd>
<dt><a class="anchor" id="_deprecated000078"></a>Global <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a250c56d6fdea13fbeab3e11e185f014f">InferenceEngine::IInferencePlugin::Infer</a>  (const BlobMap &amp;input, BlobMap &amp;result, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept=0</dt>
<dd>Load <a class="el" href="classInferenceEngine_1_1IExecutableNetwork.html" title="This is an interface of an executable network. ">IExecutableNetwork</a> to create <a class="el" href="classInferenceEngine_1_1IInferRequest.html" title="This is an interface of asynchronous infer request. ">IInferRequest</a>.  </dd>
<dt><a class="anchor" id="_deprecated000076"></a>Global <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a1f750b4c49d009ad7b59bbcf1b63a489">InferenceEngine::IInferencePlugin::LoadNetwork</a>  (<a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *resp) noexcept=0</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a40b91aacb10c2edc43e450956ec454e9" title="Creates an executable network from a network object. User can create as many networks as they need an...">IInferencePlugin::LoadNetwork(IExecutableNetwork::Ptr &amp;, ICNNNetwork &amp;, const std::map&lt;std::string, std::string&gt; &amp;, ResponseDesc *)</a>  </dd>
<dt><a class="anchor" id="_deprecated000080"></a>Global <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a72f596a132004abfa98c8fabc1b0fc9f">InferenceEngine::IInferencePlugin::QueryNetwork</a>  (const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html" title="Responce structure encapsulating information about supported layer. ">QueryNetworkResult</a> &amp;res) const noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IInferencePlugin.html#a486349ac16cd0f055c27d620c9d1e078" title="Query plugin if it supports specified network with specified configuration. ">IInferencePlugin::QueryNetwork(const ICNNNetwork&amp;, const std::map&lt;std::string, std::string&gt; &amp;, QueryNetworkResult&amp;) const</a>  </dd>
<dt><a class="anchor" id="_deprecated000055"></a>Global <a class="el" href="classInferenceEngine_1_1ILayerImplFactory.html#a8e06d653a84f05bf252cb4d8fa3c8222">InferenceEngine::ILayerImplFactory::getShapes</a>  (const std::vector&lt; TensorDesc &gt; &amp;, std::vector&lt; TensorDesc &gt; &amp;, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *) noexcept</dt>
<dd>Implement <a class="el" href="classInferenceEngine_1_1IShapeInferImpl.html" title="This class provides interface for the implementation with the custom execution code. ">IShapeInferImpl</a> extension for shape inference.  </dd>
<dt><a class="anchor" id="_deprecated000005"></a>Global <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#a0b709d4cb7c70474191cf98a7f82a0b4">InferenceEngine::InferencePlugin::GetPerformanceCounts</a>  () const</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IInferRequest.html" title="This is an interface of asynchronous infer request. ">IInferRequest</a> to get performance counters  </dd>
<dt><a class="anchor" id="_deprecated000004"></a>Global <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#a70d4e46ade4bc580c7c69e7eeb92274d">InferenceEngine::InferencePlugin::Infer</a>  (const BlobMap &amp;input, BlobMap &amp;result)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IExecutableNetwork.html" title="This is an interface of an executable network. ">IExecutableNetwork</a> to create <a class="el" href="classInferenceEngine_1_1IInferRequest.html" title="This is an interface of asynchronous infer request. ">IInferRequest</a>.  </dd>
<dt><a class="anchor" id="_deprecated000003"></a>Global <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#a0ca00d832aa35ecdefdfb456b62e51d4">InferenceEngine::InferencePlugin::LoadNetwork</a>  (<a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#ac1febcf31acce04c92a62cb1c7bd3796" title="Wraps original method IInferencePlugin::LoadNetwork(IExecutableNetwork::Ptr&amp;, ICNNNetwork&amp;, const std::map&lt;std::string, std::string&gt; &amp;, ResponseDesc*). ">InferencePlugin::LoadNetwork(ICNNNetwork &amp;, const std::map&lt;std::string, std::string&gt; &amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000007"></a>Global <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#a597b087940df09d952ba3ca8aadeaeb4">InferenceEngine::InferencePlugin::operator InferenceEngine::HeteroPluginPtr</a>  ()</dt>
<dd>Deprecated since HeteroPluginPtr is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000006"></a>Global <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#ae830df73582b71b65443e9fb6143323d">InferenceEngine::InferencePlugin::QueryNetwork</a>  (const <a class="el" href="classInferenceEngine_1_1ICNNNetwork.html" title="This is the main interface to describe the NN topology. ">ICNNNetwork</a> &amp;network, <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html" title="Responce structure encapsulating information about supported layer. ">QueryNetworkResult</a> &amp;res) const</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1InferencePlugin.html#ae933ed4acff812ecf67141600eb297b3" title="Wraps original method IInferencePlugin::QueryNetwork(const ICNNNetwork&amp;, const std::map&lt;std::string, std::string&gt; &amp;, QueryNetworkResult&amp;) const. ">InferencePlugin::QueryNetwork(const ICNNNetwork &amp;, const std::map&lt;std::string, std::string&gt; &amp;, QueryNetworkResult &amp;) const</a>  </dd>
<dt><a class="anchor" id="_deprecated000067"></a>Global <a class="el" href="classInferenceEngine_1_1InputInfo.html#a2b9ec898d5b5b1044dd8deb9153c58de">InferenceEngine::InputInfo::getDims</a>  () const</dt>
<dd>Please use <a class="el" href="classInferenceEngine_1_1InputInfo.html#a65c4a49509159dd42cc2de2b49ad2aaf" title="Returns the tensor descriptor. ">InputInfo::getTensorDesc</a> for working with layouts and dimensions  </dd>
<dt><a class="anchor" id="_deprecated000065"></a>Global <a class="el" href="classInferenceEngine_1_1InputInfo.html#a21eddb418455fc69b440aeaf73ed8770">InferenceEngine::InputInfo::getInputPrecision</a>  () const</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1InputInfo.html#a91fce5e01a9601edddb3d1cfe25376b8" title="Gets a precision of the input data provided by user. ">InputInfo::getPrecision</a>  </dd>
<dt><a class="anchor" id="_deprecated000066"></a>Global <a class="el" href="classInferenceEngine_1_1InputInfo.html#a3fe7b3d2c6b80b65d0cfa25d63974957">InferenceEngine::InputInfo::setInputPrecision</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1InputInfo.html#adf907f3c369602287d96e9732b541752" title="Changes the precision of the input data provided by the user. This function should be called before l...">InputInfo::setPrecision</a>  </dd>
<dt><a class="anchor" id="_deprecated000056"></a>Global <a class="el" href="classInferenceEngine_1_1IShapeInferImpl.html#a3a60a8308d33864a1f221eebc4410b62">InferenceEngine::IShapeInferImpl::inferShapes</a>  (const std::vector&lt; SizeVector &gt; &amp;, const std::map&lt; std::string, std::string &gt; &amp;, const std::map&lt; std::string, Blob::Ptr &gt; &amp;, std::vector&lt; SizeVector &gt; &amp;, <a class="el" href="structInferenceEngine_1_1ResponseDesc.html" title="Represents detailed information for an error. ">ResponseDesc</a> *) noexcept</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1IShapeInferImpl.html#a2a50ceecd9eee8a66ea904ffde182abf" title="check that reshape can be applied, that parameters and shapes are valid ">IShapeInferImpl::inferShapes</a>(const std::vector&lt;Blob::CPtr&gt;&amp;, const std::map&lt;std::string, std::string&gt;&amp;, const std::map&lt;std::string, Blob::Ptr&gt;&amp;, std::vector&lt;SizeVector&gt;&amp;, ResponseDesc* ) noexcept.  </dd>
<dt><a class="anchor" id="_deprecated000073"></a>Class <a class="el" href="classInferenceEngine_1_1LayoutOffsetCounter.html">InferenceEngine::LayoutOffsetCounter</a>  </dt>
<dd>Uses <a class="el" href="classInferenceEngine_1_1TensorDesc.html" title="This class defines Tensor description. ">TensorDesc</a> working with layouts  </dd>
<dt><a class="anchor" id="_deprecated000014"></a>Global <a class="el" href="namespaceInferenceEngine.html#a4bcf841606cfca0b3952d7f4ba4eb4fc">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l=NCHW)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000015"></a>Global <a class="el" href="namespaceInferenceEngine.html#ab36fc1a3db9d786437947b8c01c3ee51">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, SizeVector dims, const std::vector&lt; TypeTo &gt; &amp;arg)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000018"></a>Global <a class="el" href="namespaceInferenceEngine.html#a09c7d81ebd136670bd0dd3327dd3d6c4">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims, TypeTo *ptr, size_t size=0)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000012"></a>Global <a class="el" href="namespaceInferenceEngine.html#a9e304dc78c6eb323278abd6e5acf35e0">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, const TArg &amp;arg)</dt>
<dd>Use the make_shared_blob signature which accepts <a class="el" href="classInferenceEngine_1_1TensorDesc.html" title="This class defines Tensor description. ">TensorDesc</a>  </dd>
<dt><a class="anchor" id="_deprecated000013"></a>Global <a class="el" href="namespaceInferenceEngine.html#ad04b877a25d3ac3493465cbe68a2abde">InferenceEngine::make_shared_blob</a>  (TBlob&lt; TypeTo &gt; &amp;&amp;arg)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000011"></a>Global <a class="el" href="namespaceInferenceEngine.html#a0a6f953bacd234e4d73b764d8193d799">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const TArg &amp;arg)</dt>
<dd>Use the make_shared_blob signature which accepts <a class="el" href="classInferenceEngine_1_1TensorDesc.html" title="This class defines Tensor description. ">TensorDesc</a>  </dd>
<dt><a class="anchor" id="_deprecated000009"></a>Global <a class="el" href="namespaceInferenceEngine.html#ad9bb08c6ea48c086cec356d10151d44e">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000019"></a>Global <a class="el" href="namespaceInferenceEngine.html#a073cf5a871f359f365e2a5c4d10fd0cf">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, const SizeVector &amp;dims, TypeTo *ptr, size_t size=0)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000017"></a>Global <a class="el" href="namespaceInferenceEngine.html#a60d1508cad5c45bb06374858271e443e">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, const std::vector&lt; TypeTo &gt; &amp;arg)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000010"></a>Global <a class="el" href="namespaceInferenceEngine.html#a6006dce98d23aaba065fbb4ee61e88a5">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, const SizeVector &amp;dims)</dt>
<dd>Use the make_shared_blob signature which accepts <a class="el" href="classInferenceEngine_1_1TensorDesc.html" title="This class defines Tensor description. ">TensorDesc</a>  </dd>
<dt><a class="anchor" id="_deprecated000016"></a>Global <a class="el" href="namespaceInferenceEngine.html#afb63fa8ff7bd64fa395a3a019d3e41eb">InferenceEngine::make_shared_blob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const std::vector&lt; TypeTo &gt; &amp;arg)</dt>
<dd>Use <a class="el" href="namespaceInferenceEngine.html#a2173cee0e7f2522ffbc55c97d6e05ac5" title="Creates a blob with the given tensor descriptor. ">InferenceEngine::make_shared_blob(const TensorDesc&amp;)</a>  </dd>
<dt><a class="anchor" id="_deprecated000081"></a>Global <a class="el" href="classInferenceEngine_1_1PluginDispatcher.html#a60c86bfa7ed4fbcf65372f37d49e69d5">InferenceEngine::PluginDispatcher::getPluginByDevice</a>  (const std::string &amp;deviceName) const</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> to work with devices by name  </dd>
<dt><a class="anchor" id="_deprecated000082"></a>Global <a class="el" href="classInferenceEngine_1_1PluginDispatcher.html#ae6ab327fcd6e8141fef1591a2486e2ca">InferenceEngine::PluginDispatcher::getSuitablePlugin</a>  (TargetDevice device) const</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1Core.html" title="This class represents Inference Engine Core entity. It can throw exceptions safely for the applicatio...">InferenceEngine::Core</a> to work with devices by name  </dd>
<dt><a class="anchor" id="_deprecated000075"></a>Global <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html#a81e1efbc2b538ebb049bc62aedb18fa6">InferenceEngine::QueryNetworkResult::supportedLayers</a>  </dt>
<dd>Use <a class="el" href="structInferenceEngine_1_1QueryNetworkResult.html#aff431e5d7451f364dee1c1c54ca78333" title="A map of supported layers: ">QueryNetworkResult::supportedLayersMap</a> which provides layer -&gt; device mapping  </dd>
<dt><a class="anchor" id="_deprecated000044"></a>Class <a class="el" href="classInferenceEngine_1_1TargetDeviceInfo.html">InferenceEngine::TargetDeviceInfo</a>  </dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000050"></a>Global <a class="el" href="classInferenceEngine_1_1TargetDeviceInfo.html#ae0ad05b7dd5927d651611d27bd638f00">InferenceEngine::TargetDeviceInfo::fromStr</a>  (const std::string &amp;deviceName)</dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000051"></a>Global <a class="el" href="classInferenceEngine_1_1TargetDeviceInfo.html#aa602f7b625334859c6e7c606bbdc58b7">InferenceEngine::TargetDeviceInfo::name</a>  (TargetDevice device)</dt>
<dd>Deprecated since <a class="el" href="namespaceInferenceEngine.html#ad053545315ac52b96eaac05ad8def796" title="Describes known device types. ">InferenceEngine::TargetDevice</a> is deprecated  </dd>
<dt><a class="anchor" id="_deprecated000034"></a>Global <a class="el" href="classInferenceEngine_1_1TBlob.html#a9fbc7cc30941f4702c9eaddec10bbb67">InferenceEngine::TBlob&lt; T, typename &gt;::set</a>  (const std::vector&lt; T &gt; &amp;that)</dt>
<dd>Deprecated to avoid memcpy() calls. Use <a class="el" href="classInferenceEngine_1_1TBlob.html#a33b98d132e397ff24f1d307ea63fafb3" title="Creates a new LockedMemory instance holding void pointer. ">TBlob::buffer</a> to get raw pointer and set data  </dd>
<dt><a class="anchor" id="_deprecated000031"></a>Global <a class="el" href="classInferenceEngine_1_1TBlob.html#ab06700639b9ccf99c677eb42652f87ea">InferenceEngine::TBlob&lt; T, typename &gt;::TBlob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1TBlob.html#a60ad3422771c2c4c79a07afecf12024a" title="Creates a TBlob object with the specified dimensions and layout but does not allocate the memory...">TBlob::TBlob(const TensorDesc&amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000030"></a>Global <a class="el" href="classInferenceEngine_1_1TBlob.html#a02059b45d25c5c8b7129d00ca3e4ebe0">InferenceEngine::TBlob&lt; T, typename &gt;::TBlob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1TBlob.html#a60ad3422771c2c4c79a07afecf12024a" title="Creates a TBlob object with the specified dimensions and layout but does not allocate the memory...">TBlob::TBlob(const TensorDesc&amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000032"></a>Global <a class="el" href="classInferenceEngine_1_1TBlob.html#a2f31cd0b74eeff909f2dcafcc7b32ee4">InferenceEngine::TBlob&lt; T, typename &gt;::TBlob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims, T *ptr, size_t data_size=0)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1TBlob.html#a60ad3422771c2c4c79a07afecf12024a" title="Creates a TBlob object with the specified dimensions and layout but does not allocate the memory...">TBlob::TBlob(const TensorDesc&amp;)</a>.  </dd>
<dt><a class="anchor" id="_deprecated000033"></a>Global <a class="el" href="classInferenceEngine_1_1TBlob.html#aab97cf11457b816513359609889226cc">InferenceEngine::TBlob&lt; T, typename &gt;::TBlob</a>  (<a class="el" href="classInferenceEngine_1_1Precision.html" title="This class holds precision value and provides precision related operations. ">Precision</a> p, Layout l, const SizeVector &amp;dims, std::shared_ptr&lt; IAllocator &gt; alloc)</dt>
<dd>Use <a class="el" href="classInferenceEngine_1_1TBlob.html#a60ad3422771c2c4c79a07afecf12024a" title="Creates a TBlob object with the specified dimensions and layout but does not allocate the memory...">TBlob::TBlob(const TensorDesc&amp;)</a>. </dd>
</dl>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>