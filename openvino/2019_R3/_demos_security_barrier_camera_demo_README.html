<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Security Barrier Camera ะก++ Demo - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Security Barrier Camera ะก++ Demo </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This demo showcases Vehicle and License Plate Detection network followed by the Vehicle Attributes Recognition and License Plate Recognition networks applied on top of the detection results. You can use a set of the following pre-trained models with the demo:</p><ul>
<li><code>vehicle-license-plate-detection-barrier-0106</code>, which is a primary detection network to find the vehicles and license plates</li>
<li><code>vehicle-attributes-recognition-barrier-0039</code>, which is executed on top of the results from the first network and reports general vehicle attributes, for example, vehicle type (car/van/bus/track) and color</li>
<li><code>license-plate-recognition-barrier-0001</code>, which is executed on top of the results from the first network and reports a string per recognized license plate</li>
</ul>
<p>For more information about the pre-trained models, refer to the <a class="el" href="_models_intel_index.html">model documentation</a>.</p>
<p>Other demo objectives are:</p><ul>
<li>Video/Camera as inputs, via OpenCV*</li>
<li>Example of complex asynchronous networks pipelining: Vehicle Attributes and License Plate Recognition networks are executed on top of the Vehicle Detection results</li>
<li>Visualization of Vehicle Attributes and License Plate information for each detected object</li>
</ul>
<h2>How It Works</h2>
<p>On the start-up, the application reads command line parameters and loads the specified networks. The Vehicle and License Plate Detection network is required, the other two are optional.</p>
<p>The core component of the application pipeline is the Worker class, which executes incoming instances of a <code>Task</code> class. <code>Task</code> is an abstract class that describes data to process and how to process the data. For example, a <code>Task</code> can be to read a frame or to get detection results. There is a pool of <code>Task</code> instances. These <code>Task</code>s are awaiting to be executed. When a <code>Task</code> from the pool is being executed, it may create and/or submit another <code>Task</code> to the pool. Each <code>Task</code> stores a smart pointer to an instance of <code>VideoFrame</code>, which represents an image the <code>Task</code> works with. When the sequence of <code>Task</code>s is completed and none of the <code>Task</code>s require a <code>VideoFrame</code> instance, the <code>VideoFrame</code> is destroyed. This triggers creation of a new sequence of <code>Task</code>s. The pipeline of this demo executes the following sequence of <code>Task</code>s:</p><ul>
<li><code>Reader</code>, which reads a new frame</li>
<li><code>InferTask</code>, which starts detection inference</li>
<li><code>RectExtractor</code>, which waits for detection inference to complete and runs a classifier and a recognizer</li>
<li><code>ResAggregator</code>, which draws the results of the inference on the frame</li>
<li><code>Drawer</code>, which shows the frame with the inference results</li>
</ul>
<p>At the end of the sequence, the <code>VideoFrame</code> is destroyed and the sequence starts again for the next frame.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: By default, Open Model Zoo demos expect input with BGR channels order. If you trained your model to work with RGB order, you need to manually rearrange the default channels order in the demo application or reconvert your model using the Model Optimizer tool with <code>--reverse_input_channels</code> argument specified. For more information about the argument, refer to <b>When to Reverse Input Channels</b> section of <a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">Converting a Model Using General Conversion Parameters</a> </p>
</blockquote>
<h2>Running</h2>
<p>Running the application with the <code>-h</code> option yields the following usage message: </p><div class="fragment"><div class="line">[ INFO ] InferenceEngine:</div><div class="line">    API version ............ &lt;version&gt;</div><div class="line">    Build .................. &lt;number&gt;</div><div class="line"></div><div class="line">interactive_vehicle_detection [OPTION]</div><div class="line">Options:</div><div class="line"></div><div class="line">    -h                         Print a usage message.</div><div class="line">    -i &quot;&lt;path1&gt;&quot; &quot;&lt;path2&gt;&quot;     Required for video or image files input. Path to video or image files.</div><div class="line">    -m &quot;&lt;path&gt;&quot;                Required. Path to the Vehicle and License Plate Detection model .xml file.</div><div class="line">    -m_va &quot;&lt;path&gt;&quot;             Optional. Path to the Vehicle Attributes model .xml file.</div><div class="line">    -m_lpr &quot;&lt;path&gt;&quot;            Optional. Path to the License Plate Recognition model .xml file.</div><div class="line">      -l &quot;&lt;absolute_path&gt;&quot;     Required for CPU custom layers. Absolute path to a shared library with the kernels implementation.</div><div class="line">          Or</div><div class="line">      -c &quot;&lt;absolute_path&gt;&quot;     Required for GPU custom kernels. Absolute path to an .xml file with the kernels description.</div><div class="line">    -d &quot;&lt;device&gt;&quot;              Optional. Specify the target device for Vehicle Detection (the list of available devices is shown below). Default value is CPU. Use &quot;-d HETERO:&lt;comma-separated_devices_list&gt;&quot; format to specify HETERO plugin. The application looks for a suitable plugin for the specified device.</div><div class="line">    -d_va &quot;&lt;device&gt;&quot;           Optional. Specify the target device for Vehicle Attributes (the list of available devices is shown below). Default value is CPU. Use &quot;-d HETERO:&lt;comma-separated_devices_list&gt;&quot; format to specify HETERO plugin. The application looks for a suitable plugin for the specified device.</div><div class="line">    -d_lpr &quot;&lt;device&gt;&quot;          Optional. Specify the target device for License Plate Recognition (the list of available devices is shown below). Default value is CPU. Use &quot;-d HETERO:&lt;comma-separated_devices_list&gt;&quot; format to specify HETERO plugin. The application looks for a suitable plugin for the specified device.</div><div class="line">    -pc                        Optional. Enables per-layer performance statistics.</div><div class="line">    -r                         Optional. Output inference results as raw values.</div><div class="line">    -t                         Optional. Probability threshold for vehicle and license plate detections.</div><div class="line">    -no_show                   Optional. Do not show processed video.</div><div class="line">    -auto_resize               Optional. Enable resizable input with support of ROI crop and auto resize.</div><div class="line">    -nireq                     Optional. Number of infer requests. 0 sets the number of infer requests equal to the number of inputs.</div><div class="line">    -nc                        Required for web camera input. Maximum number of processed camera inputs (web cameras).</div><div class="line">    -fpga_device_ids           Optional. Specify FPGA device IDs (0,1,n).</div><div class="line">    -loop_video                Optional. Enable playing video on a loop.</div><div class="line">    -n_iqs                     Optional. Number of allocated frames. It is a multiplier of the number of inputs.</div><div class="line">    -ni                        Optional. Specify the number of channels generated from provided inputs (with -i and -nc keys). For example, if only one camera is provided, but -ni is set to 2, the demo will process frames as if they are captured from two cameras. 0 sets the number of input channels equal to the number of provided inputs.</div><div class="line">    -fps                       Optional. Set the playback speed not faster than the specified FPS. 0 removes the upper bound.</div><div class="line">    -n_wt                      Optional. Set the number of threads including the main thread a Worker class will use.</div><div class="line">    -display_resolution        Optional. Specify the maximum output window resolution.</div><div class="line">    -tag                       Required for HDDL plugin only. If not set, the performance on Intel(R) Movidius(TM) X VPUs will not be optimal. Running each network on a set of Intel(R) Movidius(TM) X VPUs with a specific tag. You must specify the number of VPUs for each network in the hddl_service.config file. Refer to the corresponding README file for more information.</div><div class="line">    -nstreams &quot;&lt;integer&gt;&quot;      Optional. Number of streams to use for inference on the CPU or/and GPU in throughput mode (for HETERO and MULTI device cases use format &lt;device1&gt;:&lt;nstreams1&gt;,&lt;device2&gt;:&lt;nstreams2&gt; or just &lt;nstreams&gt;)</div><div class="line">    -nthreads &quot;&lt;integer&gt;&quot;      Optional. Number of threads to use for inference on the CPU (including HETERO and MULTI cases).</div></div><!-- fragment --><p>Running the application with an empty list of options yields an error message.</p>
<p>To run the demo, you can use public or pre-trained models. To download the pre-trained models, use the OpenVINO <a class="el" href="_tools_downloader_README.html">Model Downloader</a> or go to <a href="https://download.01.org/opencv/">https://download.01.org/opencv/</a>.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: Before running the demo with a trained model, make sure the model is converted to the Inference Engine format (*.xml + *.bin) using the <a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer tool</a>. </p>
</blockquote>
<p>For example, to do inference on a GPU with the OpenVINO toolkit pre-trained models, run the following command:</p>
<div class="fragment"><div class="line">./security_barrier_camera_demo -i &lt;path_to_video&gt;/inputVideo.mp4 -m &lt;path_to_model&gt;/vehicle-license-plate-detection-barrier-0106.xml -m_va &lt;path_to_model&gt;/vehicle-attributes-recognition-barrier-0039.xml -m_lpr &lt;path_to_model&gt;/license-plate-recognition-barrier-0001.xml -d GPU</div></div><!-- fragment --><p>To do inference for two video inputs using two asynchronous infer request on FPGA with the OpenVINO toolkit pre-trained models, run the following command: </p><div class="fragment"><div class="line">./security_barrier_camera_demo -i &lt;path_to_video&gt;/inputVideo_0.mp4 &lt;path_to_video&gt;/inputVideo_1.mp4 -m &lt;path_to_model&gt;/vehicle-license-plate-detection-barrier-0106.xml -m_va &lt;path_to_model&gt;/vehicle-attributes-recognition-barrier-0039.xml -m_lpr &lt;path_to_model&gt;/license-plate-recognition-barrier-0001.xml -d HETERO:FPGA,CPU -d_va HETERO:FPGA,CPU -d_lpr HETERO:FPGA,CPU -nireq 2</div></div><!-- fragment --><blockquote class="doxtable">
<p><b>NOTE</b>: For the <code>-tag</code> option (HDDL plugin only), you must specify the number of VPUs for each network in the <code>hddl_service.config</code> file located in the <code>&lt;INSTALL_DIR&gt;/deployment_tools/inference_engine/external/hddl/config/</code> direcrtory using the following tags:</p><ul>
<li><code>tagDetect</code> for the Vehicle and License Plate Detection network</li>
<li><code>tagAttr</code> for the Vehicle Attributes Recognition network</li>
<li><code>tagLPR</code> for the License Plate Recognition network</li>
</ul>
<p>For example, to run the sample on one Intelยฎ Vision Accelerator Design with Intelยฎ Movidiusโข VPUs Compact R card with eight Intel&reg; Movidius&trade; X VPUs: </p><div class="fragment"><div class="line">&quot;service_settings&quot;:</div><div class="line">{</div><div class="line"> &quot;graph_tag_map&quot;:{&quot;tagDetect&quot;: 6, &quot;tagAttr&quot;: 1, &quot;tagLPR&quot;: 1}</div><div class="line">}</div></div><!-- fragment --> </blockquote>
<h3>Optimization Hints for Heterogeneous Scenarios with FPGA</h3>
<p>If you build the Inference Engine with the OMP, you can use the following parameters for Heterogeneous scenarois:</p>
<ul>
<li><code>OMP_NUM_THREADS</code>: Specifies number of threads to use. For heterogeneous scenarios with FPGA, when several inference requests are used asynchronously, limiting the number of CPU threads with <code>OMP_NUM_THREADS</code> allows to avoid competing for resources between threads. For the Security Barrier Camera Demo, recommended value is <code>OMP_NUM_THREADS=1</code>.</li>
<li><code>KMP_BLOCKTIME</code>: Sets the time, in milliseconds, that a thread should wait, after completing the execution of a parallel region, before sleeping. The default value is 200ms, which is not optimal for the demo. Recommended value is <code>KMP_BLOCKTIME=1</code>.</li>
</ul>
<h2>Demo Output</h2>
<p>The demo uses OpenCV to display the resulting frame with detections rendered as bounding boxes and text.</p>
<blockquote class="doxtable">
<p><b>NOTE</b>: On VPU devices (Intelยฎ Movidiusโข Neural Compute Stick, Intelยฎ Neural Compute Stick 2, and Intelยฎ Vision Accelerator Design with Intelยฎ Movidiusโข VPUs) this demo has been tested on the following Model Downloader available topologies: &gt;* <code>license-plate-recognition-barrier-0001</code> &gt;* <code>vehicle-attributes-recognition-barrier-0039</code> &gt;* <code>vehicle-license-plate-detection-barrier-0106</code> Other models may produce unexpected results on these devices. </p>
</blockquote>
<h2>See Also</h2>
<ul>
<li><a class="el" href="_demos_README.html">Using Open Model Zoo demos</a></li>
<li><a href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a></li>
<li><a class="el" href="_tools_downloader_README.html">Model Downloader</a> </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>