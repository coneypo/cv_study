<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting a TensorFlow* Model - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting a TensorFlow* Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>A summary of the steps for optimizing and deploying a model that was trained with the TensorFlow* framework:</p>
<ol type="1">
<li><a class="el" href="_docs_MO_DG_prepare_model_Config_Model_Optimizer.html">Configure the Model Optimizer</a> for TensorFlow* (TensorFlow was used to train your model).</li>
<li><a href="#freeze-the-tensorflow-model">Freeze the TensorFlow model</a> if your model is not already frozen or skip this step and use the <a href="#loading-nonfrozen-models">instruction</a> to a convert a non-frozen model.</li>
<li><a href="#Convert_From_TF">Convert a TensorFlow* model</a> to produce an optimized <a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">Intermediate Representation (IR)</a> of the model based on the trained network topology, weights, and biases values.</li>
<li>Test the model in the Intermediate Representation format using the <a class="el" href="_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html">Inference Engine</a> in the target environment via provided <a class="el" href="_docs_IE_DG_Samples_Overview.html">sample applications</a>.</li>
<li><a class="el" href="_docs_IE_DG_Samples_Overview.html">Integrate</a> the Inference Engine in your application to deploy the model in the target environment.</li>
</ol>
<h2>Supported Topologies</h2>
<p><b>Supported Unfrozen Topologies with Links to the Associated Slim Model Classification Download Files</b></p>
<p>Detailed information on how to convert models from the <a href="https://github.com/tensorflow/models/tree/master/research/slim/README.md">TensorFlow*-Slim Image Classification Model Library</a> is available in the <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Slim_Library_Models.html">Converting TensorFlow*-Slim Image Classification Model Library Models</a> chapter. The table below contains list of supported TensorFlow*-Slim Image Classification Model Library models and required mean/scale values. The mean values are specified as if the input image is read in BGR channels order layout like Inference Engine classification sample does.</p>
<table class="doxtable">
<tr>
<th>Model Name</th><th>Slim Model Checkpoint File</th><th>--mean_values </th><th align="right">--scale  </th></tr>
<tr>
<td>Inception v1</td><td><a href="http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz">inception_v1_2016_08_28.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>Inception v2</td><td><a href="http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz">inception_v1_2016_08_28.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>Inception v3</td><td><a href="http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz">inception_v3_2016_08_28.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>Inception V4</td><td><a href="http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz">inception_v4_2016_09_09.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>Inception ResNet v2</td><td><a href="http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz">inception_resnet_v2_2016_08_30.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>MobileNet v1 128</td><td><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.25_128.tgz">mobilenet_v1_0.25_128.tgz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>MobileNet v1 160</td><td><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.5_160.tgz">mobilenet_v1_0.5_160.tgz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>MobileNet v1 224</td><td><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz">mobilenet_v1_1.0_224.tgz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>NasNet Large</td><td><a href="https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz">nasnet-a_large_04_10_2017.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>NasNet Mobile</td><td><a href="https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_mobile_04_10_2017.tar.gz">nasnet-a_mobile_04_10_2017.tar.gz</a></td><td>[127.5,127.5,127.5]</td><td align="right">127.5 </td></tr>
<tr>
<td>ResidualNet-50 v1</td><td><a href="http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz">resnet_v1_50_2016_08_28.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>ResidualNet-50 v2</td><td><a href="http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz">resnet_v2_50_2017_04_14.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>ResidualNet-101 v1</td><td><a href="http://download.tensorflow.org/models/resnet_v1_101_2016_08_28.tar.gz">resnet_v1_101_2016_08_28.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>ResidualNet-101 v2</td><td><a href="http://download.tensorflow.org/models/resnet_v2_101_2017_04_14.tar.gz">resnet_v2_101_2017_04_14.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>ResidualNet-152 v1</td><td><a href="http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz">resnet_v1_152_2016_08_28.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>ResidualNet-152 v2</td><td><a href="http://download.tensorflow.org/models/resnet_v2_152_2017_04_14.tar.gz">resnet_v2_152_2017_04_14.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>VGG-16</td><td><a href="http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz">vgg_16_2016_08_28.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
<tr>
<td>VGG-19</td><td><a href="http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz">vgg_19_2016_08_28.tar.gz</a></td><td>[103.94,116.78,123.68] </td><td align="right">1 </td></tr>
</table>
<p><b>Supported Frozen Topologies from TensorFlow Object Detection Models Zoo</b></p>
<p>Detailed information on how to convert models from the <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">Object Detection Models Zoo</a> is available in the <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">Converting TensorFlow Object Detection API Models</a> chapter. The table below contains models from the Object Detection Models zoo that are supported.</p>
<table class="doxtable">
<tr>
<th align="left">Model Name</th><th align="right">TensorFlow Object Detection API Models (Frozen)  </th></tr>
<tr>
<td align="left">SSD MobileNet V1 COCO*</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz">ssd_mobilenet_v1_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD MobileNet V1 0.75 Depth COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz">ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync_2018_07_03.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD MobileNet V1 PPN COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz">ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD MobileNet V1 FPN COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz">ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD ResNet50 FPN COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz">ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD MobileNet V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz">ssd_mobilenet_v2_coco_2018_03_29.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD Lite MobileNet V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz">ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz</a> </td></tr>
<tr>
<td align="left">SSD Inception V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz">ssd_inception_v2_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">RFCN ResNet 101 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2018_01_28.tar.gz">rfcn_resnet101_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN Inception V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz">faster_rcnn_inception_v2_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 50 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz">faster_rcnn_resnet50_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 50 Low Proposals COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz">faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 101 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz">faster_rcnn_resnet101_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 101 Low Proposals COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz">faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN Inception ResNet V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz">faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN Inception ResNet V2 Low Proposals COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN NasNet COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2018_01_28.tar.gz">faster_rcnn_nas_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN NasNet Low Proposals COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz">faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Mask R-CNN Inception ResNet V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz">mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Mask R-CNN Inception V2 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz">mask_rcnn_inception_v2_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Mask R-CNN ResNet 101 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz">mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Mask R-CNN ResNet 50 COCO</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz">mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 101 Kitti*</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_kitti_2018_01_28.tar.gz">faster_rcnn_resnet101_kitti_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN Inception ResNet V2 Open Images*</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28.tar.gz">faster_rcnn_inception_resnet_v2_atrous_oid_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN Inception ResNet V2 Low Proposals Open Images*</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid_2018_01_28.tar.gz">faster_rcnn_inception_resnet_v2_atrous_lowproposals_oid_2018_01_28.tar.gz</a> </td></tr>
<tr>
<td align="left">Faster R-CNN ResNet 101 AVA v2.1*</td><td align="right"><a href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_ava_v2.1_2018_04_30.tar.gz">faster_rcnn_resnet101_ava_v2.1_2018_04_30.tar.gz</a> </td></tr>
</table>
<p><b>Supported Frozen Quantized Topologies</b></p>
<p>The topologies hosted on the TensorFlow* Lite <a href="https://www.tensorflow.org/lite/guide/hosted_models">site</a>. The frozen model file (<code>.pb</code> file) should be fed to the Model Optimizer.</p>
<table class="doxtable">
<tr>
<th align="left">Model Name </th><th align="right">Frozen Model File  </th></tr>
<tr>
<td align="left">Mobilenet V1 0.25 128 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_128_quant.tgz">mobilenet_v1_0.25_128_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.25 160 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_160_quant.tgz">mobilenet_v1_0.25_160_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.25 192 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_192_quant.tgz">mobilenet_v1_0.25_192_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.25 224 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_224_quant.tgz">mobilenet_v1_0.25_224_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.50 128 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_128_quant.tgz">mobilenet_v1_0.5_128_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.50 160 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_160_quant.tgz">mobilenet_v1_0.5_160_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.50 192 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_192_quant.tgz">mobilenet_v1_0.5_192_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.50 224 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_224_quant.tgz">mobilenet_v1_0.5_224_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.75 128 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_128_quant.tgz">mobilenet_v1_0.75_128_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.75 160 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_160_quant.tgz">mobilenet_v1_0.75_160_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.75 192 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_192_quant.tgz">mobilenet_v1_0.75_192_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 0.75 224 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz">mobilenet_v1_0.75_224_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 1.0 128 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_128_quant.tgz">mobilenet_v1_1.0_128_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 1.0 160 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_160_quant.tgz">mobilenet_v1_1.0_160_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 1.0 192 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_192_quant.tgz">mobilenet_v1_1.0_192_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V1 1.0 224 </td><td align="right"><a href="http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224_quant.tgz">mobilenet_v1_1.0_224_quant.tgz</a> </td></tr>
<tr>
<td align="left">Mobilenet V2 1.0 224 </td><td align="right"><a href="http://download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz">mobilenet_v2_1.0_224_quant.tgz</a> </td></tr>
<tr>
<td align="left">Inception V1 </td><td align="right"><a href="http://download.tensorflow.org/models/inception_v1_224_quant_20181026.tgz">inception_v1_224_quant_20181026.tgz</a> </td></tr>
<tr>
<td align="left">Inception V2 </td><td align="right"><a href="http://download.tensorflow.org/models/inception_v2_224_quant_20181026.tgz">inception_v2_224_quant_20181026.tgz</a> </td></tr>
<tr>
<td align="left">Inception V3 </td><td align="right"><a href="http://download.tensorflow.org/models/tflite_11_05_08/inception_v3_quant.tgz">inception_v3_quant.tgz</a> </td></tr>
<tr>
<td align="left">Inception V4 </td><td align="right"><a href="http://download.tensorflow.org/models/inception_v4_299_quant_20181026.tgz">inception_v4_299_quant_20181026.tgz</a> </td></tr>
</table>
<p>It is necessary to specify the following command line parameters for the Model Optimizer to convert some of the models from the list above: <code>--input input --input_shape [1,HEIGHT,WIDTH,3]</code>. Where <code>HEIGHT</code> and <code>WIDTH</code> are the input images height and width for which the model was trained.</p>
<p><b>Other supported topologies</b></p>
<table class="doxtable">
<tr>
<th align="left">Model Name</th><th align="right">Repository  </th></tr>
<tr>
<td align="left">ResNext </td><td align="right"><a href="https://github.com/taki0112/ResNeXt-Tensorflow">Repo</a> </td></tr>
<tr>
<td align="left">DenseNet </td><td align="right"><a href="https://github.com/taki0112/Densenet-Tensorflow">Repo</a> </td></tr>
<tr>
<td align="left">CRNN </td><td align="right"><a href="https://github.com/MaybeShewill-CV/CRNN_Tensorflow">Repo</a> </td></tr>
<tr>
<td align="left">NCF </td><td align="right"><a href="https://github.com/tensorflow/models/tree/master/official/recommendation">Repo</a> </td></tr>
<tr>
<td align="left">lm_1b </td><td align="right"><a href="https://github.com/tensorflow/models/tree/master/research/lm_1b">Repo</a> </td></tr>
<tr>
<td align="left">DeepSpeech </td><td align="right"><a href="https://github.com/mozilla/DeepSpeech">Repo</a> </td></tr>
<tr>
<td align="left">A3C </td><td align="right"><a href="https://github.com/miyosuda/async_deep_reinforce">Repo</a> </td></tr>
<tr>
<td align="left">VDCNN </td><td align="right"><a href="https://github.com/WenchenLi/VDCNN">Repo</a> </td></tr>
<tr>
<td align="left">Unet </td><td align="right"><a href="https://github.com/kkweon/UNet-in-Tensorflow">Repo</a> </td></tr>
</table>
<ul>
<li>YOLO topologies from DarkNet* can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">instruction</a>,</li>
<li>FaceNet topologies can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">instruction</a>.</li>
<li>CRNN topologies can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html">instruction</a>.</li>
<li>NCF topologies can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html">instruction</a></li>
<li><a href="https://github.com/tensorflow/nmt">GNMT</a> topology can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">instruction</a></li>
<li><a href="https://github.com/google-research/bert">BERT</a> topology can be converted using <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_BERT_From_Tensorflow.html">this instruction</a>.</li>
</ul>
<h2>Loading Non-Frozen Models to the Model Optimizer <a class="anchor" id="loading-nonfrozen-models"></a></h2>
<p>There are three ways to store non-frozen TensorFlow models and load them to the Model Optimizer:</p>
<ol type="1">
<li><p class="startli">Checkpoint:</p>
<p class="startli">In this case, a model consists of two files:</p><ul>
<li><code>inference_graph.pb</code> or <code>inference_graph.pbtxt</code></li>
<li><code>checkpoint_file.ckpt</code></li>
</ul>
<p class="startli">If you do not have an inference graph file, refer to <a href="#freeze-the-tensorflow-model">Freezing Custom Models in Python</a>.</p>
<p class="startli">To convert such TensorFlow model:</p><ol type="a">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory</li>
<li>Run the <code>mo_tf.py</code> script with the path to the checkpoint file to convert a model:</li>
</ol>
<ul>
<li>If input model is in <code>.pb</code> format:<br />
 <div class="fragment"><div class="line">python3 mo_tf.py --input_model &lt;INFERENCE_GRAPH&gt;.pb --input_checkpoint &lt;INPUT_CHECKPOINT&gt;</div></div><!-- fragment --></li>
<li>If input model is in <code>.pbtxt</code> format:<br />
 <div class="fragment"><div class="line">python3 mo_tf.py --input_model &lt;INFERENCE_GRAPH&gt;.pbtxt --input_checkpoint &lt;INPUT_CHECKPOINT&gt; --input_model_is_text</div></div><!-- fragment --></li>
</ul>
</li>
<li><p class="startli">MetaGraph:</p>
<p class="startli">In this case, a model consists of three or four files stored in the same directory:</p><ul>
<li><code>model_name.meta</code></li>
<li><code>model_name.index</code></li>
<li><code>model_name.data-00000-of-00001</code> (digit part may vary)</li>
<li><code>checkpoint</code> (optional)</li>
</ul>
<p class="startli">To convert such TensorFlow model:</p><ol type="a">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory</li>
<li>Run the <code>mo_tf.py</code> script with a path to the MetaGraph <code>.meta</code> file to convert a model:<br />
 <div class="fragment"><div class="line">python3 mo_tf.py --input_meta_graph &lt;INPUT_META_GRAPH&gt;.meta</div></div><!-- fragment --></li>
</ol>
</li>
<li><p class="startli">SavedModel:</p>
<p class="startli">In this case, a model consists of a special directory with a <code>.pb</code> file and several subfolders: <code>variables</code>, <code>assets</code>, and <code>assets.extra</code>. For more information about the SavedModel directory, refer to the <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/saved_model#components">README</a> file in the TensorFlow repository.</p>
<p class="startli">To convert such TensorFlow model:</p><ol type="a">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory</li>
<li>Run the <code>mo_tf.py</code> script with a path to the SavedModel directory to convert a model:<br />
 <div class="fragment"><div class="line">python3 mo_tf.py --saved_model_dir &lt;SAVED_MODEL_DIRECTORY&gt;</div></div><!-- fragment --></li>
</ol>
</li>
</ol>
<h2>Freezing Custom Models in Python* <a class="anchor" id="freeze-the-tensorflow-model"></a></h2>
<p>When a network is defined in Python* code, you have to create an inference graph file. Usually graphs are built in a form that allows model training. That means that all trainable parameters are represented as variables in the graph. To be able to use such graph with Model Optimizer such graph should be frozen. The graph is frozen and dumped to a file with the following code: </p><div class="fragment"><div class="line">import tensorflow as tf</div><div class="line">from tensorflow.python.framework import graph_io</div><div class="line">frozen = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [&quot;name_of_the_output_node&quot;])</div><div class="line">graph_io.write_graph(frozen, &#39;./&#39;, &#39;inference_graph.pb&#39;, as_text=False)</div></div><!-- fragment --><p>Where:</p>
<ul>
<li><code>sess</code> is the instance of the TensorFlow* Session object where the network topology is defined.</li>
<li><code>["name_of_the_output_node"]</code> is the list of output node names in the graph; <code>frozen</code> graph will include only those nodes from the original <code>sess.graph_def</code> that are directly or indirectly used to compute given output nodes. <code>'name_of_the_output_node'</code> here is an example of possible output node name. You should derive the names based on your own graph.</li>
<li><code>./</code> is the directory where the inference graph file should be generated.</li>
<li><code>inference_graph.pb</code> is the name of the generated inference graph file.</li>
<li><code>as_text</code> specifies whether the generated file should be in human readable text format or binary.</li>
</ul>
<h2>Convert a TensorFlow* Model <a class="anchor" id="Convert_From_TF"></a></h2>
<p>To convert a TensorFlow model:</p>
<ol type="1">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory</li>
<li>Use the <code>mo_tf.py</code> script to simply convert a model with the path to the input model <code>.pb</code> file: <div class="fragment"><div class="line">python3 mo_tf.py --input_model &lt;INPUT_MODEL&gt;.pb</div></div><!-- fragment --></li>
</ol>
<p>Two groups of parameters are available to convert your model:</p>
<ul>
<li><a class="el" href="_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">Framework-agnostic parameters</a>: These parameters are used to convert any model trained in any supported framework.</li>
<li><a href="#tensorflow_specific_conversion_params">TensorFlow-specific parameters</a>: : Parameters used to convert only TensorFlow models</li>
</ul>
<blockquote class="doxtable">
<p><b>NOTE:</b> The Model Optimizer does not revert input channels from RGB to BGR by default, as it did in the 2017 R3 Beta release. Manually specify the command-line parameter to perform this reversion: <code>--reverse_input_channels</code>. </p>
</blockquote>
<h3>Using TensorFlow*-Specific Conversion Parameters <a class="anchor" id="tensorflow_specific_conversion_params"></a></h3>
<p>The following list provides the TensorFlow*-specific parameters.</p>
<div class="fragment"><div class="line">TensorFlow*-specific parameters:</div><div class="line">  --input_model_is_text</div><div class="line">                        TensorFlow*: treat the input model file as a text</div><div class="line">                        protobuf format. If not specified, the Model Optimizer</div><div class="line">                        treats it as a binary file by default.</div><div class="line">  --input_checkpoint INPUT_CHECKPOINT</div><div class="line">                        TensorFlow*: variables file to load.</div><div class="line">  --input_meta_graph INPUT_META_GRAPH</div><div class="line">                        Tensorflow*: a file with a meta-graph of the model</div><div class="line">                        before freezing</div><div class="line">  --saved_model_dir SAVED_MODEL_DIR</div><div class="line">                        TensorFlow*: directory representing non frozen model</div><div class="line">  --saved_model_tags SAVED_MODEL_TAGS</div><div class="line">                        Group of tag(s) of the MetaGraphDef to load, in string</div><div class="line">                        format, separated by &#39;,&#39;. For tag-set contains</div><div class="line">                        multiple tags, all tags must be passed in.</div><div class="line">  --offload_unsupported_operations_to_tf</div><div class="line">                        TensorFlow*: automatically offload unsupported</div><div class="line">                        operations to TensorFlow*</div><div class="line">  --tensorflow_subgraph_patterns TENSORFLOW_SUBGRAPH_PATTERNS</div><div class="line">                        TensorFlow*: a list of comma separated patterns that</div><div class="line">                        will be applied to TensorFlow* node names to infer a</div><div class="line">                        part of the graph using TensorFlow*.</div><div class="line">  --tensorflow_operation_patterns TENSORFLOW_OPERATION_PATTERNS</div><div class="line">                        TensorFlow*: a list of comma separated patterns that</div><div class="line">                        will be applied to TensorFlow* node type (ops) to</div><div class="line">                        infer these operations using TensorFlow*.</div><div class="line">  --tensorflow_custom_operations_config_update TENSORFLOW_CUSTOM_OPERATIONS_CONFIG_UPDATE</div><div class="line">                        TensorFlow*: update the configuration file with node</div><div class="line">                        name patterns with input/output nodes information.</div><div class="line">  --tensorflow_use_custom_operations_config TENSORFLOW_USE_CUSTOM_OPERATIONS_CONFIG</div><div class="line">                        TensorFlow*: use the configuration file with custom</div><div class="line">                        operation description.</div><div class="line">  --tensorflow_object_detection_api_pipeline_config TENSORFLOW_OBJECT_DETECTION_API_PIPELINE_CONFIG</div><div class="line">                        TensorFlow*: path to the pipeline configuration file</div><div class="line">                        used to generate model created with help of Object</div><div class="line">                        Detection API.</div><div class="line">  --tensorboard_logdir TENSORBOARD_LOGDIR</div><div class="line">                        TensorFlow*: dump the input graph to a given directory</div><div class="line">                        that should be used with TensorBoard.</div><div class="line">  --tensorflow_custom_layer_libraries TENSORFLOW_CUSTOM_LAYER_LIBRARIES</div><div class="line">                        TensorFlow*: comma separated list of shared libraries</div><div class="line">                        with TensorFlow* custom operations implementation.</div><div class="line">  --disable_nhwc_to_nchw</div><div class="line">                        Disables default translation from NHWC to NCHW</div></div><!-- fragment --><blockquote class="doxtable">
<p><b>NOTE:</b> Models produces with TensorFlow* usually have not fully defined shapes (contain <code>-1</code> in some dimensions). It is necessary to pass explicit shape for the input using command line parameter <code>--input_shape</code> or <code>-b</code> to override just batch dimension. If the shape is fully defined, then there is no need to specify either <code>-b</code> or <code>--input_shape</code> options. </p>
</blockquote>
<h4>Command-Line Interface (CLI) Examples Using TensorFlow*-Specific Parameters</h4>
<ul>
<li>Launching the Model Optimizer for Inception V1 frozen model when model file is a plain text protobuf: <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pbtxt --input_model_is_text -b 1</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and automatically offload unsupported operations to TensorFlow*. Model Optimizer saves part of the model GraphDef into the generated <code>.xml</code>. For more information about this feature, refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Offloading_Sub_Graph_Inference.html">Offloading Sub-Graph Inference to TensorFlow</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb --offload_unsupported_operations_to_tf -b 1</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and offload two sub-graphs of the model defined by scope (node name regular expressions) to TensorFlow*: <code>.\*InceptionV1/Conv2d_2b_1x1.\*</code> and <code>.\*InceptionV1/Conv2d_2c_3x3.\*</code>. Model Optimizer saves part of the model GraphDef into the generated <code>.xml</code>. For more information about this feature, refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Offloading_Sub_Graph_Inference.html">Offloading Sub-Graph Inference to TensorFlow</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb -b 1 --tensorflow_subgraph_patterns .*InceptionV1/Conv2d_2b_1x1.*,.*InceptionV1/Conv2d_2c_3x3.*</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and offload operations those type match specific regular expressions: <code>Relu,Softm.\*</code>. In this case, all operations of type <code>Relu</code> and <code>Softmax</code> are matched. Model Optimizer saves part of the model GraphDef into the generated XML. For more information about this feature, refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Offloading_Sub_Graph_Inference.html">Offloading Sub-Graph Inference to TensorFlow</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb -b 1 --tensorflow_operation_patterns Relu,Soft.*</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and update custom sub-graph replacement file <code>transform.json</code> with information about input and output nodes of the matched sub-graph. For more information about this feature, refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Subgraph_Replacement_Model_Optimizer.html">Sub-Graph Replacement in the Model Optimizer</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb -b 1 --tensorflow_custom_operations_config_update transform.json</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and use custom sub-graph replacement file <code>transform.json</code> for model conversion. For more information about this feature, refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Subgraph_Replacement_Model_Optimizer.html">Sub-Graph Replacement in the Model Optimizer</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb -b 1 --tensorflow_use_custom_operations_config transform.json</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for Inception V1 frozen model and dump information about the graph to TensorBoard log dir <code>/tmp/log_dir</code> <div class="fragment"><div class="line">python3 mo_tf.py --input_model inception_v1.pb -b 1 --tensorboard_logdir /tmp/log_dir</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for a model with custom TensorFlow operations (refer to the <a href="https://www.tensorflow.org/extend/adding_an_op">TensorFlow* documentation</a>) implemented in C++ and compiled into the shared library <code>my_custom_op.so</code>. Model Optimizer falls back to TensorFlow to infer output shape of operations implemented in the library if a custom TensorFlow operation library is provided. If it is not provided, a custom operation with an inference function is needed. For more information about custom operations, refer to the <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_with_New_Primitives.html">Extending the Model Optimizer with New Primitives</a>. <div class="fragment"><div class="line">python3 mo_tf.py --input_model custom_model.pb --tensorflow_custom_layer_libraries ./my_custom_op.so</div></div><!-- fragment --></li>
</ul>
<h2>Custom Layer Definition</h2>
<p>Internally, when you run the Model Optimizer, it loads the model, goes through the topology, and tries to find each layer type in a list of known layers. Custom layers are layers that are not included in the list of known layers. If your topology contains any layers that are not in this list of known layers, the Model Optimizer classifies them as custom.</p>
<p>See <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">Custom Layers in the Model Optimizer</a> for information about:</p>
<ul>
<li>Model Optimizer internal procedure for working with custom layers</li>
<li>How to convert a TensorFlow model that has custom layers</li>
<li>Custom layer implementation details</li>
</ul>
<h2>Supported TensorFlow* Layers</h2>
<p>Refer to <a class="el" href="_docs_MO_DG_prepare_model_Supported_Frameworks_Layers.html">Supported Framework Layers </a> for the list of supported standard layers.</p>
<h2>Frequently Asked Questions (FAQ)</h2>
<p>The Model Optimizer provides explanatory messages if it is unable to run to completion due to issues like typographical errors, incorrectly used options, or other issues. The message describes the potential cause of the problem and gives a link to the <a class="el" href="_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">Model Optimizer FAQ</a>. The FAQ has instructions on how to resolve most issues. The FAQ also includes links to relevant sections in the Model Optimizer Developer Guide to help you understand what went wrong.</p>
<h2>Summary</h2>
<p>In this document, you learned:</p>
<ul>
<li>Basic information about how the Model Optimizer works with TensorFlow* models</li>
<li>Which TensorFlow models are supported</li>
<li>How to freeze a TensorFlow model</li>
<li>How to convert a trained TensorFlow model using the Model Optimizer with both framework-agnostic and TensorFlow-specific command-line options </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>