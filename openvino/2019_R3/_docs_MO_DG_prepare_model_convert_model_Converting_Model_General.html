<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting a Model Using General Conversion Parameters - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting a Model Using General Conversion Parameters </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>To simply convert a model trained by any supported framework, run the Model Optimizer launch script <code>mo.py</code> with specifying a path to the input model file: </p><div class="fragment"><div class="line">python3 mo.py --input_model INPUT_MODEL</div></div><!-- fragment --><blockquote class="doxtable">
<p><b>NOTE:</b> Model Optimizer doesn't revert input channels from RGB to BGR by default as it was in 2017 R3 Beta release. The command line parameter <code>--reverse_input_channels</code> should be specified manually to perform reversion. For details, refer to <a href="#when_to_reverse_input_channels">When to Reverse Input Channels</a> </p>
</blockquote>
<p>To adjust the conversion process, you can also use the general (framework-agnostic) parameters:</p>
<div class="fragment"><div class="line">optional arguments:</div><div class="line">  -h, --help            show this help message and exit</div><div class="line">  --framework {tf,caffe,mxnet,kaldi,onnx}</div><div class="line">                        Name of the framework used to train the input model.</div><div class="line"></div><div class="line">Framework-agnostic parameters:</div><div class="line">  --input_model INPUT_MODEL, -w INPUT_MODEL, -m INPUT_MODEL</div><div class="line">                        Tensorflow*: a file with a pre-trained model (binary</div><div class="line">                        or text .pb file after freezing). Caffe*: a model</div><div class="line">                        proto file with model weights</div><div class="line">  --model_name MODEL_NAME, -n MODEL_NAME</div><div class="line">                        Model_name parameter passed to the final create_ir</div><div class="line">                        transform. This parameter is used to name a network in</div><div class="line">                        a generated IR and output .xml/.bin files.</div><div class="line">  --output_dir OUTPUT_DIR, -o OUTPUT_DIR</div><div class="line">                        Directory that stores the generated IR. By default, it</div><div class="line">                        is the directory from where the Model Optimizer is</div><div class="line">                        launched.</div><div class="line">  --input_shape INPUT_SHAPE</div><div class="line">                        Input shape(s) that should be fed to an input node(s)</div><div class="line">                        of the model. Shape is defined as a comma-separated</div><div class="line">                        list of integer numbers enclosed in parentheses or</div><div class="line">                        square brackets, for example [1,3,227,227] or</div><div class="line">                        (1,227,227,3), where the order of dimensions depends</div><div class="line">                        on the framework input layout of the model. For</div><div class="line">                        example, [N,C,H,W] is used for Caffe* models and</div><div class="line">                        [N,H,W,C] for TensorFlow* models. Model Optimizer</div><div class="line">                        performs necessary transformations to convert the</div><div class="line">                        shape to the layout required by Inference Engine</div><div class="line">                        (N,C,H,W). The shape should not contain undefined</div><div class="line">                        dimensions (? or -1) and should fit the dimensions</div><div class="line">                        defined in the input operation of the graph. If there</div><div class="line">                        are multiple inputs in the model, --input_shape should</div><div class="line">                        contain definition of shape for each input separated</div><div class="line">                        by a comma, for example: [1,3,227,227],[2,4] for a</div><div class="line">                        model with two inputs with 4D and 2D shapes.</div><div class="line">                        Alternatively, you can specify shapes with the</div><div class="line">                        --input option.</div><div class="line">  --scale SCALE, -s SCALE</div><div class="line">                        All input values coming from original network inputs</div><div class="line">                        will be divided by this value. When a list of inputs</div><div class="line">                        is overridden by the --input parameter, this scale is</div><div class="line">                        not applied for any input that does not match with the</div><div class="line">                        original input of the model.</div><div class="line">  --reverse_input_channels</div><div class="line">                        Switch the input channels order from RGB to BGR (or</div><div class="line">                        vice versa). Applied to original inputs of the model</div><div class="line">                        if and only if a number of channels equals 3. Applied</div><div class="line">                        after application of --mean_values and --scale_values</div><div class="line">                        options, so numbers in --mean_values and</div><div class="line">                        --scale_values go in the order of channels used in the</div><div class="line">                        original model.</div><div class="line">  --log_level {CRITICAL,ERROR,WARN,WARNING,INFO,DEBUG,NOTSET}</div><div class="line">                        Logger level</div><div class="line">  --input INPUT         Quoted list of comma-separated input nodes names with</div><div class="line">                        shapes and values for freezing. The shape and value are specified</div><div class="line">                        as space-separated lists.</div><div class="line">                        For example, use the following format to set input port 0</div><div class="line">                        of the node node_name1 with the shape [3 4] as an input node</div><div class="line">                        and freeze output port 1 of the node node_name2 with</div><div class="line">                        the value [20 15] and the shape [2]:</div><div class="line">                        &quot;0:node_name1[3 4],node_name2:1[2]-&gt;[20 15]&quot;.</div><div class="line">  --output OUTPUT       The name of the output operation of the model. For</div><div class="line">                        TensorFlow*, do not add :0 to this name.</div><div class="line">  --mean_values MEAN_VALUES, -ms MEAN_VALUES</div><div class="line">                        Mean values to be used for the input image per</div><div class="line">                        channel. Values to be provided in the (R,G,B) or</div><div class="line">                        [R,G,B] format. Can be defined for desired input of</div><div class="line">                        the model, for example: &quot;--mean_values</div><div class="line">                        data[255,255,255],info[255,255,255]&quot;. The exact</div><div class="line">                        meaning and order of channels depend on how the</div><div class="line">                        original model was trained.</div><div class="line">  --scale_values SCALE_VALUES</div><div class="line">                        Scale values to be used for the input image per</div><div class="line">                        channel. Values are provided in the (R,G,B) or [R,G,B]</div><div class="line">                        format. Can be defined for desired input of the model,</div><div class="line">                        for example: &quot;--scale_values</div><div class="line">                        data[255,255,255],info[255,255,255]&quot;. The exact</div><div class="line">                        meaning and order of channels depend on how the</div><div class="line">                        original model was trained.</div><div class="line">  --data_type {FP16,FP32,half,float}</div><div class="line">                        Data type for all intermediate tensors and weights. If</div><div class="line">                        original model is in FP32 and --data_type=FP16 is</div><div class="line">                        specified, all model weights and biases are quantized</div><div class="line">                        to FP16.</div><div class="line">  --disable_fusing      Turn off fusing of linear operations to Convolution</div><div class="line">  --disable_resnet_optimization</div><div class="line">                        Turn off resnet optimization</div><div class="line">  --finegrain_fusing FINEGRAIN_FUSING</div><div class="line">                        Regex for layers/operations that won&#39;t be fused.</div><div class="line">                        Example: --finegrain_fusing Convolution1,.*Scale.*</div><div class="line">  --disable_gfusing     Turn off fusing of grouped convolutions</div><div class="line">  --move_to_preprocess  Move mean values to IR preprocess section</div><div class="line">  --extensions EXTENSIONS</div><div class="line">                        Directory or a comma separated list of directories</div><div class="line">                        with extensions. To disable all extensions including</div><div class="line">                        those that are placed at the default location, pass an</div><div class="line">                        empty string.</div><div class="line">  --batch BATCH, -b BATCH</div><div class="line">                        Input batch size</div><div class="line">  --version             Version of Model Optimizer</div><div class="line">  --silent              Prevent any output messages except those that</div><div class="line">                        correspond to log level equals ERROR, that can be set</div><div class="line">                        with the following option: --log_level. By default,</div><div class="line">                        log level is already ERROR.</div><div class="line">  --freeze_placeholder_with_value FREEZE_PLACEHOLDER_WITH_VALUE</div><div class="line">                        Replaces input layer with constant node with provided</div><div class="line">                        value, for example: &quot;node_name-&gt;True&quot;. It will be DEPRECATED</div><div class="line">                        in future releases. Use --input option to specify</div><div class="line">                        values for freezing.</div><div class="line">  --generate_deprecated_IR_V2</div><div class="line">                        Force to generate legacy/deprecated IR V2 to work with</div><div class="line">                        previous versions of the Inference Engine. The</div><div class="line">                        resulting IR may or may not be correctly loaded by</div><div class="line">                        Inference Engine API (including the most recent and</div><div class="line">                        old versions of Inference Engine) and provided as a</div><div class="line">                        partially-validated backup option for specific</div><div class="line">                        deployment scenarios. Use it at your own discretion.</div><div class="line">                        By default, without this option, the Model Optimizer</div><div class="line">                        generates IR V3.</div><div class="line">  --keep_shape_ops      [ Experimental feature ] Enables `Shape` operation</div><div class="line">                        with all children keeping. This feature makes model</div><div class="line">                        reshapable in Inference Engine</div><div class="line">  --steps</div><div class="line">                        Enables model conversion steps display</div></div><!-- fragment --><p>The sections below provide details on using particular parameters and examples of CLI commands.</p>
<h2>When to Specify Mean and Scale Values</h2>
<p>Usually neural network models are trained with the normalized input data. This means that the input data values are converted to be in a specific range, for example, <code>[0, 1]</code> or <code>[-1, 1]</code>. Sometimes the mean values (mean images) are subtracted from the input data values as part of the pre-processing. There are two cases how the input data pre-processing is implemented.</p><ul>
<li>The input pre-processing operations are a part of a topology. In this case, the application that uses the framework to infer the topology does not pre-process the input.</li>
<li>The input pre-processing operations are not a part of a topology and the pre-processing is performed within the application which feeds the model with an input data.</li>
</ul>
<p>In the first case, the Model Optimizer generates the IR with required pre-processing layers and Inference Engine samples may be used to infer the model.</p>
<p>In the second case, information about mean/scale values should be provided to the Model Optimizer to embed it to the generated IR. Model Optimizer provides a number of command line parameters to specify them: <code>--scale</code>, <code>--scale_values</code>, <code>--mean_values</code>, <code>--mean_file</code>.</p>
<p>If both mean and scale values are specified, the mean is subtracted first and then scale is applied. Input values are <em>divided</em> by the scale value(s).</p>
<p>There is no a universal recipe for determining the mean/scale values for a particular model. The steps below could help to determine them:</p><ul>
<li>Read the model documentation. Usually the documentation describes mean/scale value if the pre-processing is required.</li>
<li>Open the example script/application executing the model and track how the input data is read and passed to the framework.</li>
<li>Open the model in a visualization tool and check for layers performing subtraction or multiplication (like <code>Sub</code>, <code>Mul</code>, <code>ScaleShift</code>, <code>Eltwise</code> etc) of the input data. If such layers exist, the pre-processing is most probably the part of the model.</li>
</ul>
<h2>When to Specify Input Shapes</h2>
<p>There are situations when the input data shape for the model is not fixed, like for the fully-convolutional neural networks. In this case, for example, TensorFlow* models contain <code>-1</code> values in the <code>shape</code> attribute of the <code>Placeholder</code> operation. Inference Engine does not support input layers with undefined size, so if the input shapes are not defined in the model, the Model Optimizer fails to convert the model. The solution is to provide the input shape(s) using the <code>--input</code> or <code>--input_shape</code> command line parameter for all input(s) of the model or provide the batch size using the <code>-b</code> command line parameter if the model contains just one input with undefined batch size only. In the latter case, the <code>Placeholder</code> shape for the TensorFlow* model looks like this <code>[-1, 224, 224, 3]</code>.</p>
<h2>When to Reverse Input Channels <a class="anchor" id="when_to_reverse_input_channels"></a></h2>
<p>Inference Engine samples load input images in BGR channels order. However, the model may be trained on images loaded with the RGB channels order (for example, most TensorFlow* models are trained with images in RGB order). In this case, inference results using the Inference Engine samples will be incorrect. The solution is to provide <code>--reverse_input_channels</code> command line parameter. Then the Model Optimizer performs first convolution or other channel dependent operation weights modification so these operations output will be like the image is passed with RGB channels order.</p>
<h2>When to Specify <code>--keep_shape_ops</code> Command Line Parameter</h2>
<p>The <code>--keep_shape_ops</code> is an <b>experimental</b> command line parameter, so the model conversion may fail if it is specified.</p>
<p>By default, the Model Optimizer evaluates shapes of all operations in the model (shape propagation) for a fixed input(s) shape(s). During the shape propagation the Model Optimizer evaluates operations <em>Shape</em> and removes them from the computation graph. With that approach, the initial model which can consume inputs of different shapes may be converted to IR working with the input of one fixed shape only. For example, consider the case when some blob is reshaped from 4D of a shape <em>[N, C, H, W]</em> to a shape <em>[N, C, H * W]</em>. During the model conversion the Model Optimize calculates output shape as a constant 1D blob with values <em>[N, C, H * W]</em>. So if the input shape changes to some other value <em>[N,C,H1,W1]</em> (it is possible scenario for a fully convolutional model) then the reshape layer becomes invalid.</p>
<p>If the <code>--keep_shape_ops</code> command line parameter is specified then the Model Optimizer keeps <em>Shape</em> operations in the model and inserts additional layers to convert the graph layout from NHWC to NCHW layout if necessary.</p>
<h2>Examples of CLI Commands</h2>
<p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with debug log level: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --log_level DEBUG</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with the output IR called <code>result.*</code> in the specified <code>output_dir</code>: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --model_name result --output_dir /../../models/</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with one input with scale values: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --scale_values [59,59,59]</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with multiple inputs with scale values: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --input data,rois --scale_values [59,59,59],[5,5,5]</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with multiple inputs with scale and mean values specified for the particular nodes: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --input data,rois --mean_values data[59,59,59] --scale_values rois[5,5,5]</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with specified input layer, overridden input shape, scale 5, batch 8 and specified name of an output operation: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --input &quot;data[1 3 224 224]&quot; --output pool5 -s 5 -b 8</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with disabled fusing for linear operations to Convolution and grouped convolutions: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --disable_fusing --disable_gfusing</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with reversed input channels order between RGB and BGR, specified mean values to be used for the input image per channel and specified data type for input tensor values: </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --reverse_input_channels --mean_values [255,255,255] --data_type FP16</div></div><!-- fragment --><p>Launch the Model Optimizer for the Caffe bvlc_alexnet model with extensions listed in specified directories, specified mean_images binaryproto. file For more information about extensions, please refer to <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_with_New_Primitives.html">this</a> page. </p><div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --extensions /home/,/some/other/path/ --mean_file /path/to/binaryproto</div></div><!-- fragment --><p>Launch the Model Optimizer for TensorFlow* FaceNet* model with a placeholder freezing value. It replaces the placeholder with a constant layer that contains the passed value. For more information about FaceNet conversion, please refer to <a class="el" href="_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">this</a> page </p><div class="fragment"><div class="line">python3 mo.py --input_model FaceNet.pb --input &quot;phase_train-&gt;False&quot;</div></div><!-- fragment --><p>Launch the Model Optimizer for any model with a placeholder freezing tensor of values. It replaces the placeholder with a constant layer that contains the passed values.</p>
<p>Tensor here is represented in square brackets with each value separated from another by a whitespace. If data type is set in the model, this tensor will be reshaped to a placeholder shape and casted to placeholder data type. Otherwise, it will be casted to data type passed to <code>--data_type</code> parameter (by default, it is FP32). </p><div class="fragment"><div class="line">python3 mo.py --input_model FaceNet.pb --input &quot;placeholder_layer_name-&gt;[0.1 1.2 2.3]&quot;</div></div><!-- fragment --> </div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>