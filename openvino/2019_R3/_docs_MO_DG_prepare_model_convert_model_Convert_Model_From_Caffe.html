<!DOCTYPE html>
<html lang="en">
<head>
<!-- HTML header for doxygen 1.8.12 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Converting a Caffe* Model - OpenVINO Toolkit</title>
<script type="text/javascript" src="jquery.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="dynsections.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../assets/versions_raw.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="../assets/openvino-versions.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
<script type="text/javascript" src="openvino-layout.js?v=061b82a77ebb139b894ce81faa5ba1f6"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
  <div id="projectalign">
   <div id="projectname"><a href="<domain_placeholder>" class="homelink-id">OpenVINO Toolkit</a></div>
  </div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js?v=e23bd1c8e92f867d90ca8af9d83669a3"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Converting a Caffe* Model </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>A summary of the steps for optimizing and deploying a model that was trained with Caffe*:</p>
<ol type="1">
<li><a class="el" href="_docs_MO_DG_prepare_model_Config_Model_Optimizer.html">Configure the Model Optimizer</a> for Caffe*.</li>
<li><a href="#Convert_From_Caffe">Convert a Caffe* Model</a> to produce an optimized <a class="el" href="_docs_MO_DG_prepare_model_convert_model_IRLayersCatalogSpec.html">Intermediate Representation (IR)</a> of the model based on the trained network topology, weights, and biases values</li>
<li>Test the model in the Intermediate Representation format using the <a class="el" href="_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html">Inference Engine</a> in the target environment via provided Inference Engine <a class="el" href="_docs_IE_DG_Samples_Overview.html">sample applications</a></li>
<li><a class="el" href="_docs_IE_DG_Samples_Overview.html">Integrate</a> the <a class="el" href="_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html">Inference Engine</a> in your application to deploy the model in the target environment</li>
</ol>
<h2>Supported Topologies</h2>
<ul>
<li><b>Classification models:</b><ul>
<li>AlexNet</li>
<li>VGG-16, VGG-19</li>
<li>SqueezeNet v1.0, SqueezeNet v1.1</li>
<li>ResNet-50, ResNet-101, Res-Net-152</li>
<li>Inception v1, Inception v2, Inception v3, Inception v4</li>
<li>CaffeNet</li>
<li>MobileNet</li>
<li>Squeeze-and-Excitation Networks: SE-BN-Inception, SE-Resnet-101, SE-ResNet-152, SE-ResNet-50, SE-ResNeXt-101, SE-ResNeXt-50</li>
<li>ShuffleNet v2</li>
</ul>
</li>
<li><b>Object detection models:</b><ul>
<li>SSD300-VGG16, SSD500-VGG16</li>
<li>Faster-RCNN</li>
<li>RefineDet (Myriad plugin only)</li>
</ul>
</li>
<li><b>Face detection models:</b><ul>
<li>VGG Face</li>
<li>SSH: Single Stage Headless Face Detector</li>
</ul>
</li>
<li><b>Semantic segmentation models:</b><ul>
<li>FCN8</li>
</ul>
</li>
</ul>
<blockquote class="doxtable">
<p><b>NOTE:</b> It is necessary to specify mean and scale values for most of the Caffe* models to convert them with the Model Optimizer. The exact values should be determined separately for each model. For example, for Caffe* models trained on ImageNet, the mean values usually are <code>123.68</code>, <code>116.779</code>, <code>103.939</code> for blue, green and red channels respectively. The scale value is usually <code>127.5</code>. Refer to <a class="el" href="_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">Framework-agnostic parameters</a> for the information on how to specify mean and scale values. </p>
</blockquote>
<h2>Convert a Caffe* Model <a class="anchor" id="Convert_From_Caffe"></a></h2>
<p>To convert a Caffe* model:</p>
<ol type="1">
<li>Go to the <code>&lt;INSTALL_DIR&gt;/deployment_tools/model_optimizer</code> directory.</li>
<li>Use the <code>mo.py</code> script to simply convert a model with the path to the input model <code>.caffemodel</code> file: <div class="fragment"><div class="line">python3 mo.py --input_model &lt;INPUT_MODEL&gt;.caffemodel</div></div><!-- fragment --></li>
</ol>
<p>Two groups of parameters are available to convert your model:</p>
<ul>
<li><a class="el" href="_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html">Framework-agnostic parameters</a>: These parameters are used to convert a model trained with any supported framework.</li>
<li><a href="#caffe_specific_conversion_params">Caffe-specific parameters</a>: Parameters used to convert only Caffe* models</li>
</ul>
<h3>Using Caffe*-Specific Conversion Parameters <a class="anchor" id="caffe_specific_conversion_params"></a></h3>
<p>The following list provides the Caffe*-specific parameters.</p>
<div class="fragment"><div class="line">Caffe*-specific parameters:</div><div class="line">  --input_proto INPUT_PROTO, -d INPUT_PROTO</div><div class="line">                        Deploy-ready prototxt file that contains a topology</div><div class="line">                        structure and layer attributes</div><div class="line">  --caffe_parser_path CAFFE_PARSER_PATH</div><div class="line">                        Path to python Caffe parser generated from caffe.proto</div><div class="line">  -k K                  Path to CustomLayersMapping.xml to register custom</div><div class="line">                        layers</div><div class="line">  --mean_file MEAN_FILE, -mf MEAN_FILE</div><div class="line">                        Mean image to be used for the input. Should be a</div><div class="line">                        binaryproto file</div><div class="line">  --mean_file_offsets MEAN_FILE_OFFSETS, -mo MEAN_FILE_OFFSETS</div><div class="line">                        Mean image offsets to be used for the input</div><div class="line">                        binaryproto file. When the mean image is bigger than</div><div class="line">                        the expected input, it is cropped. By default, centers</div><div class="line">                        of the input image and the mean image are the same and</div><div class="line">                        the mean image is cropped by dimensions of the input</div><div class="line">                        image. The format to pass this option is the</div><div class="line">                        following: &quot;-mo (x,y)&quot;. In this case, the mean file is</div><div class="line">                        cropped by dimensions of the input image with offset</div><div class="line">                        (x,y) from the upper left corner of the mean image</div><div class="line">  --disable_omitting_optional</div><div class="line">                        Disable omitting optional attributes to be used for</div><div class="line">                        custom layers. Use this option if you want to transfer</div><div class="line">                        all attributes of a custom layer to IR. Default</div><div class="line">                        behavior is to transfer the attributes with default</div><div class="line">                        values and the attributes defined by the user to IR.</div><div class="line">  --enable_flattening_nested_params</div><div class="line">                        Enable flattening optional params to be used for</div><div class="line">                        custom layers. Use this option if you want to transfer</div><div class="line">                        attributes of a custom layer to IR with flattened</div><div class="line">                        nested parameters. Default behavior is to transfer the</div><div class="line">                        attributes without flattening nested parameters.</div></div><!-- fragment --><h4>Command-Line Interface (CLI) Examples Using Caffe*-Specific Parameters</h4>
<ul>
<li>Launching the Model Optimizer for the <code>bvlc_alexnet.caffemodel</code> with a specified <code>prototxt</code> file. This is needed when the name of the Caffe* model and the <code>.prototxt</code> file are different or are placed in different directories. Otherwise, it is enough to provide only the path to the input <code>model.caffemodel</code> file. <div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel --input_proto bvlc_alexnet.prototxt</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for the <code>bvlc_alexnet.caffemodel</code> with a specified <code>CustomLayersMapping</code> file. This is the legacy method of quickly enabling model conversion if your model has custom layers. This requires system Caffe* on the computer. To read more about this, see <a class="el" href="_docs_MO_DG_prepare_model_customize_model_optimizer_Legacy_Mode_for_Caffe_Custom_Layers.html">Legacy Mode for Caffe* Custom Layers</a>. Optional parameters without default values and not specified by the user in the <code>.prototxt</code> file are removed from the Intermediate Representation, and nested parameters are flattened: <div class="fragment"><div class="line">python3 mo.py --input_model bvlc_alexnet.caffemodel -k CustomLayersMapping.xml --disable_omitting_optional --enable_flattening_nested_params</div></div><!-- fragment --> This example shows a multi-input model with input layers: <code>data</code>, <code>rois</code> <div class="fragment"><div class="line">layer {</div><div class="line">  name: &quot;data&quot;</div><div class="line">  type: &quot;Input&quot;</div><div class="line">  top: &quot;data&quot;</div><div class="line">  input_param {</div><div class="line">    shape { dim: 1 dim: 3 dim: 224 dim: 224 }</div><div class="line">  }</div><div class="line">}</div><div class="line">layer {</div><div class="line">  name: &quot;rois&quot;</div><div class="line">  type: &quot;Input&quot;</div><div class="line">  top: &quot;rois&quot;</div><div class="line">  input_param {</div><div class="line">    shape { dim: 1 dim: 5 dim: 1 dim: 1 }</div><div class="line">  }</div><div class="line">}</div></div><!-- fragment --></li>
<li>Launching the Model Optimizer for a multi-input model with two inputs and providing a new shape for each input in the order they are passed to the Model Optimizer. In particular, for data, set the shape to <code>1,3,227,227</code>. For rois, set the shape to <code>1,6,1,1</code>: <div class="fragment"><div class="line">python3 mo.py --input_model /path-to/your-model.caffemodel --input data,rois --input_shape (1,3,227,227),[1,6,1,1]</div></div><!-- fragment --></li>
</ul>
<h2>Custom Layer Definition</h2>
<p>Internally, when you run the Model Optimizer, it loads the model, goes through the topology, and tries to find each layer type in a list of known layers. Custom layers are layers that are not included in the list of known layers. If your topology contains any layers that are not in this list of known layers, the Model Optimizer classifies them as custom.</p>
<h2>Supported Caffe* Layers</h2>
<p>Refer to <a class="el" href="_docs_MO_DG_prepare_model_Supported_Frameworks_Layers.html">Supported Framework Layers</a> for the list of supported standard layers.</p>
<h2>Frequently Asked Questions (FAQ)</h2>
<p>The Model Optimizer provides explanatory messages if it is unable to run to completion due to issues like typographical errors, incorrectly used options, or other issues. The message describes the potential cause of the problem and gives a link to the <a class="el" href="_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">Model Optimizer FAQ</a>. The FAQ has instructions on how to resolve most issues. The FAQ also includes links to relevant sections in the Model Optimizer Developer Guide to help you understand what went wrong.</p>
<h2>Summary</h2>
<p>In this document, you learned:</p>
<ul>
<li>Basic information about how the Model Optimizer works with Caffe* models</li>
<li>Which Caffe* models are supported</li>
<li>How to convert a trained Caffe* model using the Model Optimizer with both framework-agnostic and Caffe-specific command-line options </li>
</ul>
</div></div><!-- contents -->
  <div class="footer">
  <div id="nav-path" class="navpath"></div>
  <div class="footer-content">
    <div class="footer-column">
      <h4>Support</h4>
      <ul>
        <li>
          <a href="https://software.intel.com/en-us/forums/computer-vision">Intel Developer Zone Forum for Intel Distribution of OpenVINO Toolkit</a></li>
      </ul>
    </div>
  </div>
  <div class="copyright">
    <p>Documentation for OpenVINO Toolkit.<br/>
    For more complete information about compiler optimizations, see our <a href="/<version_placeholder>/_docs_IE_DG_Optimization_notice.html">Optimization Notice</a></p>
  </div>
</div>
</body>
</html>